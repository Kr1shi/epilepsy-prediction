============================================================
BATCH PROCESSING: ALL FOLDS
Processing 10 folds for patient chb06
============================================================

Configuration:
  - Task mode: PREDICTION (preictal vs interictal)
  - LOOCV Mode: ENABLED
  - Sequence length: 30 segments
  - Sequence duration: 150s (2.5 min)
  - Stride: 5 segments (83% overlap)
  - Segment duration: 5s
  - Preictal window: 10 min
  - Interictal buffer: 120 min
  - Channel validation: ENABLED
  - Target channels: 18 channels
============================================================

Extracting sequences from patient chb06...
  Channel validation: 17/18 files valid
Patient chb06: 1146 sequences (162 preictal, 984 interictal)

============================================================
PROCESSING FOLD 0/9
============================================================
Output prefix: chb06_fold0
LOOCV Fold 0: Test seizure=0, Train seizures=[1, 2, 3, 4, 5, 6, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 324
  - Preictal sequences: 162
  - Interictal sequences: 162
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb06: 324 total (162 preictal, 162 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 42 total (21 preictal, 21 interictal)
train: 282 total (141 preictal, 141 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 255.5s (4.3 min)
Class balance: 162/162 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 141 preictal, 141 interictal (dropped 0 preictal, 351 interictal)
test: 21 preictal, 21 interictal (dropped 0 preictal, 471 interictal)

Sequences saved to chb06_fold0_sequences_prediction.json
File size: 0.56 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 18
Files with valid channels: 17
Files with invalid channels: 1

Most common missing channels:
  - C3-P3: missing in 1 files
  - C4-P4: missing in 1 files
  - CZ-PZ: missing in 1 files
  - F3-C3: missing in 1 files
  - F4-C4: missing in 1 files

✅ Fold 0 completed successfully!
✅ Sequences saved to chb06_fold0_sequences_prediction.json

============================================================
PROCESSING FOLD 1/9
============================================================
Output prefix: chb06_fold1
LOOCV Fold 1: Test seizure=1, Train seizures=[0, 2, 3, 4, 5, 6, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 324
  - Preictal sequences: 162
  - Interictal sequences: 162
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb06: 324 total (162 preictal, 162 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 40 total (20 preictal, 20 interictal)
train: 284 total (142 preictal, 142 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 255.5s (4.3 min)
Class balance: 162/162 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 142 preictal, 142 interictal (dropped 0 preictal, 350 interictal)
test: 20 preictal, 20 interictal (dropped 0 preictal, 472 interictal)

Sequences saved to chb06_fold1_sequences_prediction.json
File size: 0.55 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 18
Files with valid channels: 17
Files with invalid channels: 1

Most common missing channels:
  - C3-P3: missing in 1 files
  - C4-P4: missing in 1 files
  - CZ-PZ: missing in 1 files
  - F3-C3: missing in 1 files
  - F4-C4: missing in 1 files

✅ Fold 1 completed successfully!
✅ Sequences saved to chb06_fold1_sequences_prediction.json

============================================================
PROCESSING FOLD 2/9
============================================================
Output prefix: chb06_fold2
LOOCV Fold 2: Test seizure=2, Train seizures=[0, 1, 3, 4, 5, 6, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 324
  - Preictal sequences: 162
  - Interictal sequences: 162
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb06: 324 total (162 preictal, 162 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 40 total (20 preictal, 20 interictal)
train: 284 total (142 preictal, 142 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 255.5s (4.3 min)
Class balance: 162/162 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 142 preictal, 142 interictal (dropped 0 preictal, 350 interictal)
test: 20 preictal, 20 interictal (dropped 0 preictal, 472 interictal)

Sequences saved to chb06_fold2_sequences_prediction.json
File size: 0.55 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 18
Files with valid channels: 17
Files with invalid channels: 1

Most common missing channels:
  - C3-P3: missing in 1 files
  - C4-P4: missing in 1 files
  - CZ-PZ: missing in 1 files
  - F3-C3: missing in 1 files
  - F4-C4: missing in 1 files

✅ Fold 2 completed successfully!
✅ Sequences saved to chb06_fold2_sequences_prediction.json

============================================================
PROCESSING FOLD 3/9
============================================================
Output prefix: chb06_fold3
LOOCV Fold 3: Test seizure=3, Train seizures=[0, 1, 2, 4, 5, 6, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 324
  - Preictal sequences: 162
  - Interictal sequences: 162
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb06: 324 total (162 preictal, 162 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 40 total (20 preictal, 20 interictal)
train: 284 total (142 preictal, 142 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 255.5s (4.3 min)
Class balance: 162/162 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 142 preictal, 142 interictal (dropped 0 preictal, 350 interictal)
test: 20 preictal, 20 interictal (dropped 0 preictal, 472 interictal)

Sequences saved to chb06_fold3_sequences_prediction.json
File size: 0.55 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 18
Files with valid channels: 17
Files with invalid channels: 1

Most common missing channels:
  - C3-P3: missing in 1 files
  - C4-P4: missing in 1 files
  - CZ-PZ: missing in 1 files
  - F3-C3: missing in 1 files
  - F4-C4: missing in 1 files

✅ Fold 3 completed successfully!
✅ Sequences saved to chb06_fold3_sequences_prediction.json

============================================================
PROCESSING FOLD 4/9
============================================================
Output prefix: chb06_fold4
LOOCV Fold 4: Test seizure=4, Train seizures=[0, 1, 2, 3, 5, 6, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 324
  - Preictal sequences: 162
  - Interictal sequences: 162
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb06: 324 total (162 preictal, 162 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 40 total (20 preictal, 20 interictal)
train: 284 total (142 preictal, 142 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 255.5s (4.3 min)
Class balance: 162/162 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 142 preictal, 142 interictal (dropped 0 preictal, 350 interictal)
test: 20 preictal, 20 interictal (dropped 0 preictal, 472 interictal)

Sequences saved to chb06_fold4_sequences_prediction.json
File size: 0.56 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 18
Files with valid channels: 17
Files with invalid channels: 1

Most common missing channels:
  - C3-P3: missing in 1 files
  - C4-P4: missing in 1 files
  - CZ-PZ: missing in 1 files
  - F3-C3: missing in 1 files
  - F4-C4: missing in 1 files

✅ Fold 4 completed successfully!
✅ Sequences saved to chb06_fold4_sequences_prediction.json

============================================================
PROCESSING FOLD 5/9
============================================================
Output prefix: chb06_fold5
LOOCV Fold 5: Test seizure=5, Train seizures=[0, 1, 2, 3, 4, 6, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 324
  - Preictal sequences: 162
  - Interictal sequences: 162
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb06: 324 total (162 preictal, 162 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 30 total (15 preictal, 15 interictal)
train: 294 total (147 preictal, 147 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 255.5s (4.3 min)
Class balance: 162/162 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 147 preictal, 147 interictal (dropped 0 preictal, 345 interictal)
test: 15 preictal, 15 interictal (dropped 0 preictal, 477 interictal)

Sequences saved to chb06_fold5_sequences_prediction.json
File size: 0.55 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 18
Files with valid channels: 17
Files with invalid channels: 1

Most common missing channels:
  - C3-P3: missing in 1 files
  - C4-P4: missing in 1 files
  - CZ-PZ: missing in 1 files
  - F3-C3: missing in 1 files
  - F4-C4: missing in 1 files

✅ Fold 5 completed successfully!
✅ Sequences saved to chb06_fold5_sequences_prediction.json

============================================================
PROCESSING FOLD 6/9
============================================================
Output prefix: chb06_fold6
LOOCV Fold 6: Test seizure=6, Train seizures=[0, 1, 2, 3, 4, 5, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 324
  - Preictal sequences: 162
  - Interictal sequences: 162
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb06: 324 total (162 preictal, 162 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 48 total (24 preictal, 24 interictal)
train: 276 total (138 preictal, 138 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 255.5s (4.3 min)
Class balance: 162/162 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 138 preictal, 138 interictal (dropped 0 preictal, 354 interictal)
test: 24 preictal, 24 interictal (dropped 0 preictal, 468 interictal)

Sequences saved to chb06_fold6_sequences_prediction.json
File size: 0.55 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 18
Files with valid channels: 17
Files with invalid channels: 1

Most common missing channels:
  - C3-P3: missing in 1 files
  - C4-P4: missing in 1 files
  - CZ-PZ: missing in 1 files
  - F3-C3: missing in 1 files
  - F4-C4: missing in 1 files

✅ Fold 6 completed successfully!
✅ Sequences saved to chb06_fold6_sequences_prediction.json

============================================================
PROCESSING FOLD 7/9
============================================================
Output prefix: chb06_fold7
LOOCV Fold 7: Test seizure=7, Train seizures=[0, 1, 2, 3, 4, 5, 6, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 324
  - Preictal sequences: 162
  - Interictal sequences: 162
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb06: 324 total (162 preictal, 162 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 44 total (22 preictal, 22 interictal)
train: 280 total (140 preictal, 140 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 255.5s (4.3 min)
Class balance: 162/162 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 140 preictal, 140 interictal (dropped 0 preictal, 352 interictal)
test: 22 preictal, 22 interictal (dropped 0 preictal, 470 interictal)

Sequences saved to chb06_fold7_sequences_prediction.json
File size: 0.55 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 18
Files with valid channels: 17
Files with invalid channels: 1

Most common missing channels:
  - C3-P3: missing in 1 files
  - C4-P4: missing in 1 files
  - CZ-PZ: missing in 1 files
  - F3-C3: missing in 1 files
  - F4-C4: missing in 1 files

✅ Fold 7 completed successfully!
✅ Sequences saved to chb06_fold7_sequences_prediction.json

============================================================
PROCESSING FOLD 8/9
============================================================
Output prefix: chb06_fold8
LOOCV Fold 8: Test seizure=8, Train seizures=[0, 1, 2, 3, 4, 5, 6, 7, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 816
  - Preictal sequences: 162
  - Interictal sequences: 654
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb06: 816 total (162 preictal, 654 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 492 total (0 preictal, 492 interictal)
train: 324 total (162 preictal, 162 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 255.5s (4.3 min)
Class balance: 162/654 = 0.25

=== SPLIT BALANCING SUMMARY ===
train: 162 preictal, 162 interictal (dropped 0 preictal, 330 interictal)
test: Skipped balancing due to missing class

Sequences saved to chb06_fold8_sequences_prediction.json
File size: 1.38 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 18
Files with valid channels: 17
Files with invalid channels: 1

Most common missing channels:
  - C3-P3: missing in 1 files
  - C4-P4: missing in 1 files
  - CZ-PZ: missing in 1 files
  - F3-C3: missing in 1 files
  - F4-C4: missing in 1 files

✅ Fold 8 completed successfully!
✅ Sequences saved to chb06_fold8_sequences_prediction.json

============================================================
PROCESSING FOLD 9/9
============================================================
Output prefix: chb06_fold9
LOOCV Fold 9: Test seizure=9, Train seizures=[0, 1, 2, 3, 4, 5, 6, 7, 8]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 816
  - Preictal sequences: 162
  - Interictal sequences: 654
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb06: 816 total (162 preictal, 654 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 492 total (0 preictal, 492 interictal)
train: 324 total (162 preictal, 162 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 255.5s (4.3 min)
Class balance: 162/654 = 0.25

=== SPLIT BALANCING SUMMARY ===
train: 162 preictal, 162 interictal (dropped 0 preictal, 330 interictal)
test: Skipped balancing due to missing class

Sequences saved to chb06_fold9_sequences_prediction.json
File size: 1.38 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 18
Files with valid channels: 17
Files with invalid channels: 1

Most common missing channels:
  - C3-P3: missing in 1 files
  - C4-P4: missing in 1 files
  - CZ-PZ: missing in 1 files
  - F3-C3: missing in 1 files
  - F4-C4: missing in 1 files

✅ Fold 9 completed successfully!
✅ Sequences saved to chb06_fold9_sequences_prediction.json

============================================================
✅ BATCH PROCESSING COMPLETED!
✅ Processed 10 folds for patient chb06
============================================================
============================================================
BATCH PROCESSING: ALL FOLDS
Processing 10 folds for patient chb06
============================================================

============================================================
PREPROCESSING FOLD 0/9
============================================================
2025-11-19 21:12:10,125 - INFO - ============================================================
2025-11-19 21:12:10,125 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 21:12:10,125 - INFO - ============================================================
2025-11-19 21:12:10,125 - INFO - Output prefix: chb06_fold0
2025-11-19 21:12:10,125 - INFO - EEG Preprocessor initialized
2025-11-19 21:12:10,125 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 21:12:10,125 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 21:12:10,125 - INFO - Segment duration: 5 seconds
2025-11-19 21:12:10,125 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 21:12:10,125 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 21:12:10,125 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 21:12:10,125 - INFO - Loading segments from chb06_fold0_sequences_prediction.json
2025-11-19 21:12:10,139 - INFO - Loaded 324 total sequences
2025-11-19 21:12:10,139 - INFO - Channel validation (from segmentation): 17/18 files valid
2025-11-19 21:12:10,139 - INFO - Files skipped due to missing channels: 1
2025-11-19 21:12:10,139 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 21:12:10,139 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 21:12:10,139 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 21:12:10,140 - INFO - train: 282 sequences (141 preictal, 141 interictal)
2025-11-19 21:12:10,140 - INFO - test: 42 sequences (21 preictal, 21 interictal)
2025-11-19 21:12:10,157 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 21:12:10,158 - INFO - train: kept 141 preictal and 141 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:12:10,158 - INFO - test: kept 21 preictal and 21 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:12:10,176 - INFO - ============================================================
2025-11-19 21:12:10,176 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 21:12:10,176 - INFO - ============================================================
2025-11-19 21:12:10,176 - INFO - Processing 282 training samples to compute normalization stats...
2025-11-19 21:12:10,176 - INFO - Processing 282 sequences from 17 unique files
Processing training data:   0%|                    | 0/282 [00:00<?, ?it/s]Processing training data:   0%|            | 1/282 [00:08<37:54,  8.09s/it]Processing training data:   5%|5          | 15/282 [00:15<03:51,  1.15it/s]Processing training data:  13%|#4         | 36/282 [00:19<01:41,  2.41it/s]Processing training data:  27%|##9        | 76/282 [00:26<00:54,  3.76it/s]Processing training data:  32%|###5       | 91/282 [00:27<00:41,  4.59it/s]Processing training data:  34%|###7       | 96/282 [00:28<00:40,  4.61it/s]Processing training data:  43%|####2     | 120/282 [00:30<00:24,  6.65it/s]Processing training data:  50%|####9     | 140/282 [00:34<00:23,  5.97it/s]Processing training data:  52%|#####2    | 148/282 [00:41<00:38,  3.49it/s]Processing training data:  59%|#####9    | 167/282 [00:43<00:24,  4.68it/s]Processing training data:  67%|######7   | 189/282 [00:50<00:24,  3.80it/s]Processing training data:  72%|#######1  | 203/282 [00:58<00:26,  3.02it/s]Processing training data:  81%|########1 | 229/282 [01:04<00:15,  3.39it/s]Processing training data:  85%|########5 | 241/282 [01:09<00:12,  3.17it/s]Processing training data:  88%|########7 | 248/282 [01:16<00:14,  2.42it/s]Processing training data:  92%|#########1| 259/282 [01:23<00:10,  2.13it/s]Processing training data:  96%|#########6| 271/282 [01:30<00:05,  1.91it/s]Processing training data: 100%|##########| 282/282 [01:30<00:00,  3.10it/s]
2025-11-19 21:13:41,166 - INFO - Computing normalization statistics from training data...
2025-11-19 21:13:41,767 - INFO - Normalization stats computed:
2025-11-19 21:13:41,768 - INFO -   Mean: 1.245004
2025-11-19 21:13:41,768 - INFO -   Std: 2.536095
2025-11-19 21:13:41,768 - INFO -   Saved to: preprocessing\checkpoints\chb06_fold0\normalization_stats.json
2025-11-19 21:13:41,819 - INFO - Applying normalization and saving 282 training sequences...
Normalizing and saving training data:   0%|        | 0/282 [00:00<?, ?it/s]2025-11-19 21:13:41,830 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold0\train_dataset.h5
Normalizing and saving training data:   4%| | 10/282 [00:00<00:18, 14.38it/Normalizing and saving training data:   7%| | 20/282 [00:01<00:17, 14.86it/Normalizing and saving training data:  11%|1| 30/282 [00:02<00:17, 14.80it/Normalizing and saving training data:  14%|1| 40/282 [00:02<00:16, 14.53it/Normalizing and saving training data:  18%|1| 50/282 [00:03<00:15, 14.72it/Normalizing and saving training data:  21%|2| 60/282 [00:04<00:14, 14.91it/Normalizing and saving training data:  25%|2| 70/282 [00:04<00:14, 15.06it/Normalizing and saving training data:  28%|2| 80/282 [00:05<00:13, 15.08it/Normalizing and saving training data:  32%|3| 90/282 [00:06<00:12, 15.24it/Normalizing and saving training data:  35%|3| 100/282 [00:06<00:11, 15.27itNormalizing and saving training data:  39%|3| 110/282 [00:07<00:11, 15.32itNormalizing and saving training data:  43%|4| 120/282 [00:07<00:10, 15.39itNormalizing and saving training data:  46%|4| 130/282 [00:08<00:09, 15.32itNormalizing and saving training data:  50%|4| 140/282 [00:09<00:09, 15.23itNormalizing and saving training data:  53%|5| 150/282 [00:09<00:08, 14.89itNormalizing and saving training data:  57%|5| 160/282 [00:10<00:08, 14.93itNormalizing and saving training data:  60%|6| 170/282 [00:11<00:07, 14.93itNormalizing and saving training data:  64%|6| 180/282 [00:11<00:06, 14.93itNormalizing and saving training data:  67%|6| 190/282 [00:12<00:06, 14.89itNormalizing and saving training data:  71%|7| 200/282 [00:13<00:05, 14.76itNormalizing and saving training data:  74%|7| 210/282 [00:14<00:04, 14.87itNormalizing and saving training data:  78%|7| 220/282 [00:14<00:04, 14.90itNormalizing and saving training data:  82%|8| 230/282 [00:15<00:03, 14.93itNormalizing and saving training data:  85%|8| 240/282 [00:16<00:02, 15.05itNormalizing and saving training data:  89%|8| 250/282 [00:16<00:02, 15.09itNormalizing and saving training data:  92%|9| 260/282 [00:17<00:01, 14.97itNormalizing and saving training data:  96%|9| 270/282 [00:18<00:00, 14.81itNormalizing and saving training data:  99%|9| 280/282 [00:18<00:00, 14.90itNormalizing and saving training data: 100%|#| 282/282 [00:18<00:00, 15.08it
2025-11-19 21:14:00,694 - INFO - Training data processing completed during stats computation phase
2025-11-19 21:14:00,702 - INFO - Loaded normalization statistics:
2025-11-19 21:14:00,702 - INFO -   Mean: 1.245004
2025-11-19 21:14:00,702 - INFO -   Std: 2.536095
2025-11-19 21:14:00,702 - INFO - Split train already completed, skipping
2025-11-19 21:14:00,702 - INFO - Processing test split...
2025-11-19 21:14:00,702 - INFO - Need to process 42/42 sequences for test
2025-11-19 21:14:00,702 - INFO - Processing 42 sequences from 12 unique files
2025-11-19 21:14:00,702 - INFO - Average 3.5 sequences per file
Processing test:   0%|                              | 0/42 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/42 [00:01<00:49,  1.21s/it]2025-11-19 21:14:01,914 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold0\test_dataset.h5
2025-11-19 21:14:03,205 - INFO - Progress: 303/324 (93.5%) - ETA: 0.1 minutes
Processing test:  52%|###########          | 22/42 [00:06<00:05,  3.36it/s]Processing test:  57%|############         | 24/42 [00:08<00:06,  2.77it/s]Processing test:  62%|#############        | 26/42 [00:10<00:07,  2.09it/s]Processing test:  67%|##############       | 28/42 [00:14<00:10,  1.36it/s]Processing test:  74%|###############5     | 31/42 [00:18<00:09,  1.18it/s]2025-11-19 21:14:19,789 - INFO - Progress: 314/324 (96.9%) - ETA: 0.1 minutes
Processing test:  79%|################5    | 33/42 [00:20<00:07,  1.18it/s]Processing test:  81%|#################    | 34/42 [00:21<00:06,  1.15it/s]Processing test:  83%|#################5   | 35/42 [00:22<00:06,  1.12it/s]Processing test:  88%|##################5  | 37/42 [00:23<00:03,  1.29it/s]Processing test:  90%|###################  | 38/42 [00:24<00:03,  1.12it/s]Processing test:  95%|#################### | 40/42 [00:28<00:02,  1.32s/it]2025-11-19 21:14:30,166 - INFO - Progress: 324/324 (100.0%) - ETA: 0.0 minutes
Processing test: 100%|#####################| 42/42 [00:29<00:00,  1.43it/s]
2025-11-19 21:14:30,183 - INFO - Validating final datasets...
2025-11-19 21:14:30,192 - INFO - train dataset validation:
2025-11-19 21:14:30,192 - INFO -   - Segments: 282
2025-11-19 21:14:30,192 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:14:30,192 - INFO -   - Classes: 141 preictal, 141 interictal
2025-11-19 21:14:30,192 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:14:30,197 - INFO - test dataset validation:
2025-11-19 21:14:30,197 - INFO -   - Segments: 42
2025-11-19 21:14:30,197 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:14:30,197 - INFO -   - Classes: 21 preictal, 21 interictal
2025-11-19 21:14:30,197 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:14:30,198 - INFO - ============================================================
2025-11-19 21:14:30,198 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 21:14:30,198 - INFO - Total time: 2.3 minutes
2025-11-19 21:14:30,198 - INFO - Processed segments: 324
2025-11-19 21:14:30,198 - INFO - Average rate: 2.3 segments/second
2025-11-19 21:14:30,198 - INFO - ============================================================
✅ Fold 0 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 1/9
============================================================
2025-11-19 21:14:30,270 - INFO - ============================================================
2025-11-19 21:14:30,270 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 21:14:30,270 - INFO - ============================================================
2025-11-19 21:14:30,270 - INFO - Output prefix: chb06_fold1
2025-11-19 21:14:30,270 - INFO - EEG Preprocessor initialized
2025-11-19 21:14:30,270 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 21:14:30,270 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 21:14:30,270 - INFO - Segment duration: 5 seconds
2025-11-19 21:14:30,270 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 21:14:30,270 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 21:14:30,270 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 21:14:30,271 - INFO - Loading segments from chb06_fold1_sequences_prediction.json
2025-11-19 21:14:30,282 - INFO - Loaded 324 total sequences
2025-11-19 21:14:30,282 - INFO - Channel validation (from segmentation): 17/18 files valid
2025-11-19 21:14:30,282 - INFO - Files skipped due to missing channels: 1
2025-11-19 21:14:30,282 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 21:14:30,283 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 21:14:30,283 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 21:14:30,283 - INFO - train: 284 sequences (142 preictal, 142 interictal)
2025-11-19 21:14:30,283 - INFO - test: 40 sequences (20 preictal, 20 interictal)
2025-11-19 21:14:30,300 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 21:14:30,300 - INFO - train: kept 142 preictal and 142 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:14:30,300 - INFO - test: kept 20 preictal and 20 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:14:30,317 - INFO - ============================================================
2025-11-19 21:14:30,317 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 21:14:30,317 - INFO - ============================================================
2025-11-19 21:14:30,317 - INFO - Processing 284 training samples to compute normalization stats...
2025-11-19 21:14:30,317 - INFO - Processing 284 sequences from 17 unique files
Processing training data:   0%|                    | 0/284 [00:00<?, ?it/s]Processing training data:   0%|            | 1/284 [00:05<25:19,  5.37s/it]Processing training data:   4%|3          | 10/284 [00:11<04:48,  1.05s/it]Processing training data:  18%|#9         | 51/284 [00:12<00:40,  5.76it/s]Processing training data:  25%|##7        | 71/284 [00:20<00:53,  4.00it/s]Processing training data:  32%|###5       | 91/284 [00:26<00:51,  3.78it/s]Processing training data:  38%|###7      | 107/284 [00:30<00:46,  3.83it/s]Processing training data:  46%|####6     | 132/284 [00:38<00:43,  3.48it/s]Processing training data:  52%|#####1    | 147/284 [00:46<00:48,  2.84it/s]Processing training data:  58%|#####7    | 164/284 [00:54<00:45,  2.66it/s]Processing training data:  62%|######1   | 175/284 [00:55<00:35,  3.10it/s]Processing training data:  69%|######9   | 197/284 [01:02<00:28,  3.11it/s]Processing training data:  75%|#######4  | 212/284 [01:09<00:25,  2.82it/s]Processing training data:  84%|########3 | 238/284 [01:16<00:15,  3.03it/s]Processing training data:  90%|########9 | 255/284 [01:23<00:10,  2.86it/s]Processing training data:  93%|#########2| 264/284 [01:27<00:07,  2.76it/s]Processing training data:  95%|#########5| 271/284 [01:34<00:06,  2.16it/s]Processing training data:  99%|#########9| 282/284 [01:35<00:00,  2.69it/s]Processing training data: 100%|##########| 284/284 [01:35<00:00,  2.96it/s]
2025-11-19 21:16:06,113 - INFO - Computing normalization statistics from training data...
2025-11-19 21:16:06,610 - INFO - Normalization stats computed:
2025-11-19 21:16:06,610 - INFO -   Mean: 1.261427
2025-11-19 21:16:06,610 - INFO -   Std: 2.505855
2025-11-19 21:16:06,610 - INFO -   Saved to: preprocessing\checkpoints\chb06_fold1\normalization_stats.json
2025-11-19 21:16:06,661 - INFO - Applying normalization and saving 284 training sequences...
Normalizing and saving training data:   0%|        | 0/284 [00:00<?, ?it/s]2025-11-19 21:16:06,670 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold1\train_dataset.h5
Normalizing and saving training data:   4%| | 10/284 [00:00<00:19, 14.09it/Normalizing and saving training data:   7%| | 20/284 [00:01<00:17, 14.90it/Normalizing and saving training data:  11%|1| 30/284 [00:02<00:17, 14.92it/Normalizing and saving training data:  14%|1| 40/284 [00:02<00:16, 14.99it/Normalizing and saving training data:  18%|1| 50/284 [00:03<00:15, 15.14it/Normalizing and saving training data:  21%|2| 60/284 [00:03<00:14, 15.23it/Normalizing and saving training data:  25%|2| 70/284 [00:04<00:13, 15.36it/Normalizing and saving training data:  28%|2| 80/284 [00:05<00:13, 15.46it/Normalizing and saving training data:  32%|3| 90/284 [00:05<00:12, 15.46it/Normalizing and saving training data:  35%|3| 100/284 [00:06<00:11, 15.46itNormalizing and saving training data:  39%|3| 110/284 [00:07<00:11, 15.50itNormalizing and saving training data:  42%|4| 120/284 [00:07<00:10, 15.54itNormalizing and saving training data:  46%|4| 130/284 [00:08<00:09, 15.53itNormalizing and saving training data:  49%|4| 140/284 [00:09<00:09, 15.44itNormalizing and saving training data:  53%|5| 150/284 [00:09<00:08, 15.21itNormalizing and saving training data:  56%|5| 160/284 [00:10<00:08, 15.23itNormalizing and saving training data:  60%|5| 170/284 [00:11<00:07, 15.26itNormalizing and saving training data:  63%|6| 180/284 [00:11<00:06, 15.24itNormalizing and saving training data:  67%|6| 190/284 [00:12<00:06, 15.24itNormalizing and saving training data:  70%|7| 200/284 [00:13<00:05, 15.28itNormalizing and saving training data:  74%|7| 210/284 [00:13<00:04, 15.26itNormalizing and saving training data:  77%|7| 220/284 [00:14<00:04, 15.26itNormalizing and saving training data:  81%|8| 230/284 [00:15<00:03, 15.29itNormalizing and saving training data:  85%|8| 240/284 [00:15<00:02, 15.25itNormalizing and saving training data:  88%|8| 250/284 [00:16<00:02, 15.26itNormalizing and saving training data:  92%|9| 260/284 [00:17<00:01, 15.28itNormalizing and saving training data:  95%|9| 270/284 [00:17<00:00, 14.25itNormalizing and saving training data:  99%|9| 280/284 [00:18<00:00, 14.43itNormalizing and saving training data: 100%|#| 284/284 [00:18<00:00, 15.35it
2025-11-19 21:16:25,463 - INFO - Training data processing completed during stats computation phase
2025-11-19 21:16:25,471 - INFO - Loaded normalization statistics:
2025-11-19 21:16:25,471 - INFO -   Mean: 1.261427
2025-11-19 21:16:25,471 - INFO -   Std: 2.505855
2025-11-19 21:16:25,471 - INFO - Split train already completed, skipping
2025-11-19 21:16:25,471 - INFO - Processing test split...
2025-11-19 21:16:25,471 - INFO - Need to process 40/40 sequences for test
2025-11-19 21:16:25,471 - INFO - Processing 40 sequences from 11 unique files
2025-11-19 21:16:25,471 - INFO - Average 3.6 sequences per file
Processing test:   0%|                              | 0/40 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/40 [00:06<03:56,  6.07s/it]Processing test:  10%|##2                   | 4/40 [00:07<00:56,  1.56s/it]2025-11-19 21:16:33,054 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold1\test_dataset.h5
2025-11-19 21:16:34,519 - INFO - Progress: 307/324 (94.8%) - ETA: 0.1 minutes
Processing test:  60%|############6        | 24/40 [00:09<00:04,  3.71it/s]Processing test:  62%|#############1       | 25/40 [00:12<00:06,  2.28it/s]Processing test:  70%|##############7      | 28/40 [00:16<00:07,  1.57it/s]Processing test:  75%|###############7     | 30/40 [00:18<00:06,  1.51it/s]Processing test:  80%|################8    | 32/40 [00:20<00:05,  1.46it/s]2025-11-19 21:16:46,282 - INFO - Progress: 317/324 (97.8%) - ETA: 0.1 minutes
Processing test:  85%|#################8   | 34/40 [00:26<00:07,  1.19s/it]Processing test:  92%|###################4 | 37/40 [00:27<00:02,  1.10it/s]Processing test:  95%|###################9 | 38/40 [00:29<00:02,  1.15s/it]Processing test: 100%|#####################| 40/40 [00:30<00:00,  1.15it/s]Processing test: 100%|#####################| 40/40 [00:30<00:00,  1.33it/s]
2025-11-19 21:16:56,105 - INFO - Validating final datasets...
2025-11-19 21:16:56,114 - INFO - train dataset validation:
2025-11-19 21:16:56,114 - INFO -   - Segments: 284
2025-11-19 21:16:56,114 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:16:56,114 - INFO -   - Classes: 142 preictal, 142 interictal
2025-11-19 21:16:56,114 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:16:56,120 - INFO - test dataset validation:
2025-11-19 21:16:56,120 - INFO -   - Segments: 40
2025-11-19 21:16:56,120 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:16:56,120 - INFO -   - Classes: 20 preictal, 20 interictal
2025-11-19 21:16:56,120 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:16:56,120 - INFO - ============================================================
2025-11-19 21:16:56,120 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 21:16:56,121 - INFO - Total time: 2.4 minutes
2025-11-19 21:16:56,121 - INFO - Processed segments: 324
2025-11-19 21:16:56,121 - INFO - Average rate: 2.2 segments/second
2025-11-19 21:16:56,121 - INFO - ============================================================
✅ Fold 1 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 2/9
============================================================
2025-11-19 21:16:56,193 - INFO - ============================================================
2025-11-19 21:16:56,193 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 21:16:56,193 - INFO - ============================================================
2025-11-19 21:16:56,193 - INFO - Output prefix: chb06_fold2
2025-11-19 21:16:56,193 - INFO - EEG Preprocessor initialized
2025-11-19 21:16:56,193 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 21:16:56,193 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 21:16:56,193 - INFO - Segment duration: 5 seconds
2025-11-19 21:16:56,194 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 21:16:56,194 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 21:16:56,194 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 21:16:56,194 - INFO - Loading segments from chb06_fold2_sequences_prediction.json
2025-11-19 21:16:56,207 - INFO - Loaded 324 total sequences
2025-11-19 21:16:56,207 - INFO - Channel validation (from segmentation): 17/18 files valid
2025-11-19 21:16:56,207 - INFO - Files skipped due to missing channels: 1
2025-11-19 21:16:56,207 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 21:16:56,207 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 21:16:56,207 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 21:16:56,207 - INFO - train: 284 sequences (142 preictal, 142 interictal)
2025-11-19 21:16:56,207 - INFO - test: 40 sequences (20 preictal, 20 interictal)
2025-11-19 21:16:56,224 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 21:16:56,224 - INFO - train: kept 142 preictal and 142 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:16:56,224 - INFO - test: kept 20 preictal and 20 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:16:56,241 - INFO - ============================================================
2025-11-19 21:16:56,241 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 21:16:56,241 - INFO - ============================================================
2025-11-19 21:16:56,241 - INFO - Processing 284 training samples to compute normalization stats...
2025-11-19 21:16:56,241 - INFO - Processing 284 sequences from 17 unique files
Processing training data:   0%|                    | 0/284 [00:00<?, ?it/s]Processing training data:   0%|            | 1/284 [00:01<05:14,  1.11s/it]Processing training data:   8%|8          | 23/284 [00:07<01:25,  3.06it/s]Processing training data:  13%|#4         | 37/284 [00:14<01:39,  2.47it/s]Processing training data:  20%|##1        | 56/284 [00:18<01:08,  3.34it/s]Processing training data:  34%|###7       | 97/284 [00:21<00:32,  5.73it/s]Processing training data:  43%|####2     | 122/284 [00:29<00:35,  4.62it/s]Processing training data:  48%|####7     | 136/284 [00:35<00:39,  3.76it/s]Processing training data:  51%|#####1    | 146/284 [00:42<00:47,  2.91it/s]Processing training data:  56%|#####6    | 160/284 [00:48<00:46,  2.69it/s]Processing training data:  65%|######5   | 185/284 [00:55<00:33,  2.97it/s]Processing training data:  72%|#######1  | 204/284 [00:57<00:20,  3.90it/s]Processing training data:  79%|#######8  | 224/284 [01:00<00:13,  4.48it/s]Processing training data:  81%|########1 | 231/284 [01:05<00:15,  3.37it/s]Processing training data:  85%|########5 | 242/284 [01:13<00:16,  2.56it/s]Processing training data:  92%|#########1| 260/284 [01:19<00:09,  2.62it/s]Processing training data:  95%|#########5| 270/284 [01:26<00:06,  2.21it/s]Processing training data: 100%|##########| 284/284 [01:27<00:00,  3.12it/s]Processing training data: 100%|##########| 284/284 [01:27<00:00,  3.26it/s]
2025-11-19 21:18:23,459 - INFO - Computing normalization statistics from training data...
2025-11-19 21:18:24,014 - INFO - Normalization stats computed:
2025-11-19 21:18:24,014 - INFO -   Mean: 1.206720
2025-11-19 21:18:24,014 - INFO -   Std: 2.530141
2025-11-19 21:18:24,014 - INFO -   Saved to: preprocessing\checkpoints\chb06_fold2\normalization_stats.json
2025-11-19 21:18:24,072 - INFO - Applying normalization and saving 284 training sequences...
Normalizing and saving training data:   0%|        | 0/284 [00:00<?, ?it/s]2025-11-19 21:18:24,082 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold2\train_dataset.h5
Normalizing and saving training data:   4%| | 10/284 [00:00<00:17, 15.52it/Normalizing and saving training data:   7%| | 20/284 [00:01<00:16, 15.54it/Normalizing and saving training data:  11%|1| 30/284 [00:01<00:16, 15.64it/Normalizing and saving training data:  14%|1| 40/284 [00:02<00:15, 15.59it/Normalizing and saving training data:  18%|1| 50/284 [00:03<00:14, 15.66it/Normalizing and saving training data:  21%|2| 60/284 [00:03<00:14, 15.71it/Normalizing and saving training data:  25%|2| 70/284 [00:04<00:13, 15.78it/Normalizing and saving training data:  28%|2| 80/284 [00:05<00:12, 15.83it/Normalizing and saving training data:  32%|3| 90/284 [00:05<00:12, 15.82it/Normalizing and saving training data:  35%|3| 100/284 [00:06<00:11, 15.85itNormalizing and saving training data:  39%|3| 110/284 [00:06<00:10, 15.86itNormalizing and saving training data:  42%|4| 120/284 [00:07<00:10, 15.87itNormalizing and saving training data:  46%|4| 130/284 [00:08<00:09, 15.81itNormalizing and saving training data:  49%|4| 140/284 [00:08<00:09, 15.78itNormalizing and saving training data:  53%|5| 150/284 [00:09<00:08, 15.80itNormalizing and saving training data:  56%|5| 160/284 [00:10<00:07, 15.73itNormalizing and saving training data:  60%|5| 170/284 [00:10<00:07, 15.77itNormalizing and saving training data:  63%|6| 180/284 [00:11<00:06, 15.78itNormalizing and saving training data:  67%|6| 190/284 [00:12<00:05, 15.80itNormalizing and saving training data:  70%|7| 200/284 [00:12<00:05, 15.83itNormalizing and saving training data:  74%|7| 210/284 [00:13<00:04, 15.84itNormalizing and saving training data:  77%|7| 220/284 [00:13<00:04, 15.79itNormalizing and saving training data:  81%|8| 230/284 [00:14<00:03, 15.81itNormalizing and saving training data:  85%|8| 240/284 [00:15<00:02, 15.77itNormalizing and saving training data:  88%|8| 250/284 [00:15<00:02, 15.77itNormalizing and saving training data:  92%|9| 260/284 [00:16<00:01, 15.76itNormalizing and saving training data:  95%|9| 270/284 [00:17<00:00, 15.74itNormalizing and saving training data:  99%|9| 280/284 [00:17<00:00, 15.74itNormalizing and saving training data: 100%|#| 284/284 [00:17<00:00, 15.99it
2025-11-19 21:18:42,122 - INFO - Training data processing completed during stats computation phase
2025-11-19 21:18:42,130 - INFO - Loaded normalization statistics:
2025-11-19 21:18:42,130 - INFO -   Mean: 1.206720
2025-11-19 21:18:42,130 - INFO -   Std: 2.530141
2025-11-19 21:18:42,130 - INFO - Split train already completed, skipping
2025-11-19 21:18:42,130 - INFO - Processing test split...
2025-11-19 21:18:42,130 - INFO - Need to process 40/40 sequences for test
2025-11-19 21:18:42,130 - INFO - Processing 40 sequences from 12 unique files
2025-11-19 21:18:42,130 - INFO - Average 3.3 sequences per file
Processing test:   0%|                              | 0/40 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/40 [00:01<01:05,  1.68s/it]Processing test:   8%|#6                    | 3/40 [00:02<00:29,  1.24it/s]Processing test:  10%|##2                   | 4/40 [00:06<01:09,  1.92s/it]Processing test:  20%|####4                 | 8/40 [00:09<00:35,  1.12s/it]2025-11-19 21:18:51,684 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold2\test_dataset.h5
2025-11-19 21:18:52,627 - INFO - Progress: 296/324 (91.4%) - ETA: 0.2 minutes
Processing test:  32%|######8              | 13/40 [00:11<00:20,  1.31it/s]2025-11-19 21:18:55,243 - INFO - Progress: 316/324 (97.5%) - ETA: 0.1 minutes
Processing test:  82%|#################3   | 33/40 [00:14<00:01,  3.71it/s]Processing test:  85%|#################8   | 34/40 [00:15<00:01,  3.21it/s]Processing test:  88%|##################3  | 35/40 [00:18<00:02,  1.89it/s]Processing test:  92%|###################4 | 37/40 [00:19<00:01,  1.88it/s]Processing test:  95%|###################9 | 38/40 [00:20<00:01,  1.68it/s]Processing test:  98%|####################4| 39/40 [00:22<00:00,  1.49it/s]Processing test: 100%|#####################| 40/40 [00:23<00:00,  1.38it/s]Processing test: 100%|#####################| 40/40 [00:23<00:00,  1.73it/s]
2025-11-19 21:19:05,730 - INFO - Validating final datasets...
2025-11-19 21:19:05,739 - INFO - train dataset validation:
2025-11-19 21:19:05,739 - INFO -   - Segments: 284
2025-11-19 21:19:05,739 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:19:05,739 - INFO -   - Classes: 142 preictal, 142 interictal
2025-11-19 21:19:05,739 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:19:05,745 - INFO - test dataset validation:
2025-11-19 21:19:05,745 - INFO -   - Segments: 40
2025-11-19 21:19:05,745 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:19:05,745 - INFO -   - Classes: 20 preictal, 20 interictal
2025-11-19 21:19:05,745 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:19:05,745 - INFO - ============================================================
2025-11-19 21:19:05,745 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 21:19:05,745 - INFO - Total time: 2.2 minutes
2025-11-19 21:19:05,745 - INFO - Processed segments: 324
2025-11-19 21:19:05,745 - INFO - Average rate: 2.5 segments/second
2025-11-19 21:19:05,745 - INFO - ============================================================
✅ Fold 2 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 3/9
============================================================
2025-11-19 21:19:05,814 - INFO - ============================================================
2025-11-19 21:19:05,815 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 21:19:05,815 - INFO - ============================================================
2025-11-19 21:19:05,815 - INFO - Output prefix: chb06_fold3
2025-11-19 21:19:05,815 - INFO - EEG Preprocessor initialized
2025-11-19 21:19:05,815 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 21:19:05,815 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 21:19:05,815 - INFO - Segment duration: 5 seconds
2025-11-19 21:19:05,815 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 21:19:05,815 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 21:19:05,815 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 21:19:05,815 - INFO - Loading segments from chb06_fold3_sequences_prediction.json
2025-11-19 21:19:05,827 - INFO - Loaded 324 total sequences
2025-11-19 21:19:05,827 - INFO - Channel validation (from segmentation): 17/18 files valid
2025-11-19 21:19:05,827 - INFO - Files skipped due to missing channels: 1
2025-11-19 21:19:05,827 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 21:19:05,827 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 21:19:05,827 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 21:19:05,827 - INFO - train: 284 sequences (142 preictal, 142 interictal)
2025-11-19 21:19:05,827 - INFO - test: 40 sequences (20 preictal, 20 interictal)
2025-11-19 21:19:05,844 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 21:19:05,845 - INFO - train: kept 142 preictal and 142 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:19:05,845 - INFO - test: kept 20 preictal and 20 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:19:05,861 - INFO - ============================================================
2025-11-19 21:19:05,862 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 21:19:05,862 - INFO - ============================================================
2025-11-19 21:19:05,862 - INFO - Processing 284 training samples to compute normalization stats...
2025-11-19 21:19:05,862 - INFO - Processing 284 sequences from 17 unique files
Processing training data:   0%|                    | 0/284 [00:00<?, ?it/s]Processing training data:   0%|            | 1/284 [00:06<31:39,  6.71s/it]Processing training data:  22%|##4        | 62/284 [00:10<00:31,  7.15it/s]Processing training data:  25%|##7        | 71/284 [00:16<00:49,  4.29it/s]Processing training data:  29%|###2       | 83/284 [00:24<01:07,  2.98it/s]Processing training data:  35%|###7       | 98/284 [00:25<00:48,  3.84it/s]Processing training data:  42%|####2     | 120/284 [00:33<00:47,  3.44it/s]Processing training data:  48%|####7     | 135/284 [00:34<00:35,  4.22it/s]Processing training data:  55%|#####4    | 155/284 [00:42<00:38,  3.39it/s]Processing training data:  62%|######1   | 176/284 [00:49<00:32,  3.34it/s]Processing training data:  66%|######5   | 187/284 [00:57<00:37,  2.59it/s]Processing training data:  71%|#######1  | 202/284 [01:04<00:33,  2.43it/s]Processing training data:  78%|#######7  | 221/284 [01:12<00:25,  2.45it/s]Processing training data:  83%|########3 | 236/284 [01:16<00:17,  2.71it/s]Processing training data:  92%|#########1| 261/284 [01:20<00:06,  3.49it/s]Processing training data:  96%|#########5| 272/284 [01:26<00:04,  2.95it/s]Processing training data:  98%|#########7| 278/284 [01:28<00:02,  2.91it/s]Processing training data: 100%|##########| 284/284 [01:28<00:00,  3.39it/s]Processing training data: 100%|##########| 284/284 [01:28<00:00,  3.20it/s]
2025-11-19 21:20:34,521 - INFO - Computing normalization statistics from training data...
2025-11-19 21:20:34,971 - INFO - Normalization stats computed:
2025-11-19 21:20:34,971 - INFO -   Mean: 1.191714
2025-11-19 21:20:34,971 - INFO -   Std: 2.546207
2025-11-19 21:20:34,971 - INFO -   Saved to: preprocessing\checkpoints\chb06_fold3\normalization_stats.json
2025-11-19 21:20:35,023 - INFO - Applying normalization and saving 284 training sequences...
Normalizing and saving training data:   0%|        | 0/284 [00:00<?, ?it/s]2025-11-19 21:20:35,031 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold3\train_dataset.h5
Normalizing and saving training data:   4%| | 10/284 [00:00<00:17, 15.99it/Normalizing and saving training data:   7%| | 20/284 [00:01<00:16, 15.86it/Normalizing and saving training data:  11%|1| 30/284 [00:01<00:15, 15.93it/Normalizing and saving training data:  14%|1| 40/284 [00:02<00:15, 15.98it/Normalizing and saving training data:  18%|1| 50/284 [00:03<00:14, 16.00it/Normalizing and saving training data:  21%|2| 60/284 [00:03<00:13, 16.01it/Normalizing and saving training data:  25%|2| 70/284 [00:04<00:13, 16.01it/Normalizing and saving training data:  28%|2| 80/284 [00:05<00:12, 16.02it/Normalizing and saving training data:  32%|3| 90/284 [00:05<00:12, 15.99it/Normalizing and saving training data:  35%|3| 100/284 [00:06<00:11, 16.00itNormalizing and saving training data:  39%|3| 110/284 [00:06<00:10, 15.99itNormalizing and saving training data:  42%|4| 120/284 [00:07<00:10, 15.98itNormalizing and saving training data:  46%|4| 130/284 [00:08<00:09, 15.95itNormalizing and saving training data:  49%|4| 140/284 [00:08<00:09, 15.88itNormalizing and saving training data:  53%|5| 150/284 [00:09<00:08, 15.87itNormalizing and saving training data:  56%|5| 160/284 [00:10<00:07, 15.87itNormalizing and saving training data:  60%|5| 170/284 [00:10<00:07, 15.87itNormalizing and saving training data:  63%|6| 180/284 [00:11<00:06, 15.86itNormalizing and saving training data:  67%|6| 190/284 [00:11<00:05, 15.86itNormalizing and saving training data:  70%|7| 200/284 [00:12<00:05, 15.86itNormalizing and saving training data:  74%|7| 210/284 [00:13<00:04, 15.87itNormalizing and saving training data:  77%|7| 220/284 [00:13<00:04, 15.84itNormalizing and saving training data:  81%|8| 230/284 [00:14<00:03, 15.84itNormalizing and saving training data:  85%|8| 240/284 [00:15<00:02, 15.85itNormalizing and saving training data:  88%|8| 250/284 [00:15<00:02, 15.83itNormalizing and saving training data:  92%|9| 260/284 [00:16<00:01, 15.83itNormalizing and saving training data:  95%|9| 270/284 [00:16<00:00, 15.79itNormalizing and saving training data:  99%|9| 280/284 [00:17<00:00, 15.80itNormalizing and saving training data: 100%|#| 284/284 [00:17<00:00, 16.12it
2025-11-19 21:20:52,928 - INFO - Training data processing completed during stats computation phase
2025-11-19 21:20:52,935 - INFO - Loaded normalization statistics:
2025-11-19 21:20:52,935 - INFO -   Mean: 1.191714
2025-11-19 21:20:52,935 - INFO -   Std: 2.546207
2025-11-19 21:20:52,935 - INFO - Split train already completed, skipping
2025-11-19 21:20:52,935 - INFO - Processing test split...
2025-11-19 21:20:52,935 - INFO - Need to process 40/40 sequences for test
2025-11-19 21:20:52,935 - INFO - Processing 40 sequences from 10 unique files
2025-11-19 21:20:52,935 - INFO - Average 4.0 sequences per file
Processing test:   0%|                              | 0/40 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/40 [00:00<00:38,  1.00it/s]Processing test:   5%|#1                    | 2/40 [00:06<02:13,  3.51s/it]2025-11-19 21:20:59,211 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold3\test_dataset.h5
2025-11-19 21:21:00,546 - INFO - Progress: 306/324 (94.4%) - ETA: 0.1 minutes
Processing test:  57%|############         | 23/40 [00:11<00:07,  2.29it/s]Processing test:  62%|#############1       | 25/40 [00:15<00:09,  1.64it/s]Processing test:  72%|###############2     | 29/40 [00:18<00:07,  1.53it/s]2025-11-19 21:21:12,401 - INFO - Progress: 316/324 (97.5%) - ETA: 0.1 minutes
Processing test:  82%|#################3   | 33/40 [00:22<00:05,  1.35it/s]Processing test:  88%|##################3  | 35/40 [00:23<00:03,  1.44it/s]Processing test:  90%|##################9  | 36/40 [00:27<00:03,  1.04it/s]Processing test:  98%|####################4| 39/40 [00:27<00:00,  1.32it/s]Processing test: 100%|#####################| 40/40 [00:28<00:00,  1.30it/s]Processing test: 100%|#####################| 40/40 [00:28<00:00,  1.39it/s]
2025-11-19 21:21:22,228 - INFO - Validating final datasets...
2025-11-19 21:21:22,236 - INFO - train dataset validation:
2025-11-19 21:21:22,236 - INFO -   - Segments: 284
2025-11-19 21:21:22,237 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:21:22,237 - INFO -   - Classes: 142 preictal, 142 interictal
2025-11-19 21:21:22,237 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:21:22,242 - INFO - test dataset validation:
2025-11-19 21:21:22,242 - INFO -   - Segments: 40
2025-11-19 21:21:22,242 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:21:22,242 - INFO -   - Classes: 20 preictal, 20 interictal
2025-11-19 21:21:22,242 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:21:22,242 - INFO - ============================================================
2025-11-19 21:21:22,242 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 21:21:22,242 - INFO - Total time: 2.3 minutes
2025-11-19 21:21:22,242 - INFO - Processed segments: 324
2025-11-19 21:21:22,242 - INFO - Average rate: 2.4 segments/second
2025-11-19 21:21:22,242 - INFO - ============================================================
✅ Fold 3 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 4/9
============================================================
2025-11-19 21:21:22,311 - INFO - ============================================================
2025-11-19 21:21:22,311 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 21:21:22,311 - INFO - ============================================================
2025-11-19 21:21:22,311 - INFO - Output prefix: chb06_fold4
2025-11-19 21:21:22,311 - INFO - EEG Preprocessor initialized
2025-11-19 21:21:22,311 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 21:21:22,311 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 21:21:22,311 - INFO - Segment duration: 5 seconds
2025-11-19 21:21:22,311 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 21:21:22,311 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 21:21:22,311 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 21:21:22,312 - INFO - Loading segments from chb06_fold4_sequences_prediction.json
2025-11-19 21:21:22,323 - INFO - Loaded 324 total sequences
2025-11-19 21:21:22,323 - INFO - Channel validation (from segmentation): 17/18 files valid
2025-11-19 21:21:22,323 - INFO - Files skipped due to missing channels: 1
2025-11-19 21:21:22,323 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 21:21:22,323 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 21:21:22,323 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 21:21:22,323 - INFO - train: 284 sequences (142 preictal, 142 interictal)
2025-11-19 21:21:22,323 - INFO - test: 40 sequences (20 preictal, 20 interictal)
2025-11-19 21:21:22,340 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 21:21:22,340 - INFO - train: kept 142 preictal and 142 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:21:22,340 - INFO - test: kept 20 preictal and 20 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:21:22,357 - INFO - ============================================================
2025-11-19 21:21:22,357 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 21:21:22,357 - INFO - ============================================================
2025-11-19 21:21:22,357 - INFO - Processing 284 training samples to compute normalization stats...
2025-11-19 21:21:22,357 - INFO - Processing 284 sequences from 16 unique files
Processing training data:   0%|                    | 0/284 [00:00<?, ?it/s]Processing training data:   0%|            | 1/284 [00:00<03:33,  1.33it/s]Processing training data:   9%|9          | 25/284 [00:06<01:09,  3.70it/s]Processing training data:  14%|#5         | 39/284 [00:14<01:32,  2.65it/s]Processing training data:  21%|##3        | 60/284 [00:20<01:14,  2.99it/s]Processing training data:  31%|###4       | 88/284 [00:26<00:56,  3.49it/s]Processing training data:  52%|#####2    | 149/284 [00:33<00:25,  5.39it/s]Processing training data:  56%|#####6    | 160/284 [00:35<00:22,  5.58it/s]Processing training data:  64%|######4   | 182/284 [00:41<00:20,  4.92it/s]Processing training data:  68%|######7   | 192/284 [00:48<00:26,  3.50it/s]Processing training data:  75%|#######5  | 213/284 [00:55<00:21,  3.33it/s]Processing training data:  80%|#######9  | 227/284 [01:01<00:18,  3.04it/s]Processing training data:  84%|########4 | 239/284 [01:08<00:17,  2.59it/s]Processing training data:  89%|########9 | 253/284 [01:15<00:12,  2.39it/s]Processing training data:  92%|#########1| 261/284 [01:20<00:10,  2.19it/s]Processing training data:  96%|#########6| 274/284 [01:22<00:03,  2.82it/s]Processing training data:  98%|#########8| 279/284 [01:25<00:02,  2.47it/s]Processing training data: 100%|##########| 284/284 [01:25<00:00,  3.31it/s]
2025-11-19 21:22:48,236 - INFO - Computing normalization statistics from training data...
2025-11-19 21:22:48,675 - INFO - Normalization stats computed:
2025-11-19 21:22:48,675 - INFO -   Mean: 1.254635
2025-11-19 21:22:48,675 - INFO -   Std: 2.504804
2025-11-19 21:22:48,675 - INFO -   Saved to: preprocessing\checkpoints\chb06_fold4\normalization_stats.json
2025-11-19 21:22:48,729 - INFO - Applying normalization and saving 284 training sequences...
Normalizing and saving training data:   0%|        | 0/284 [00:00<?, ?it/s]2025-11-19 21:22:48,738 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold4\train_dataset.h5
Normalizing and saving training data:   4%| | 10/284 [00:00<00:17, 15.58it/Normalizing and saving training data:   7%| | 20/284 [00:01<00:17, 15.46it/Normalizing and saving training data:  11%|1| 30/284 [00:01<00:16, 15.55it/Normalizing and saving training data:  14%|1| 40/284 [00:02<00:15, 15.60it/Normalizing and saving training data:  18%|1| 50/284 [00:03<00:14, 15.62it/Normalizing and saving training data:  21%|2| 60/284 [00:03<00:14, 15.65it/Normalizing and saving training data:  25%|2| 70/284 [00:04<00:13, 15.64it/Normalizing and saving training data:  28%|2| 80/284 [00:05<00:13, 15.68it/Normalizing and saving training data:  32%|3| 90/284 [00:05<00:12, 15.57it/Normalizing and saving training data:  35%|3| 100/284 [00:06<00:11, 15.59itNormalizing and saving training data:  39%|3| 110/284 [00:07<00:11, 15.53itNormalizing and saving training data:  42%|4| 120/284 [00:07<00:10, 15.49itNormalizing and saving training data:  46%|4| 130/284 [00:08<00:09, 15.43itNormalizing and saving training data:  49%|4| 140/284 [00:09<00:09, 15.48itNormalizing and saving training data:  53%|5| 150/284 [00:09<00:08, 15.48itNormalizing and saving training data:  56%|5| 160/284 [00:10<00:08, 15.46itNormalizing and saving training data:  60%|5| 170/284 [00:10<00:07, 15.39itNormalizing and saving training data:  63%|6| 180/284 [00:11<00:06, 15.38itNormalizing and saving training data:  67%|6| 190/284 [00:12<00:06, 15.44itNormalizing and saving training data:  70%|7| 200/284 [00:12<00:05, 15.38itNormalizing and saving training data:  74%|7| 210/284 [00:13<00:04, 15.43itNormalizing and saving training data:  77%|7| 220/284 [00:14<00:04, 15.44itNormalizing and saving training data:  81%|8| 230/284 [00:14<00:03, 15.51itNormalizing and saving training data:  85%|8| 240/284 [00:15<00:02, 15.53itNormalizing and saving training data:  88%|8| 250/284 [00:16<00:02, 15.55itNormalizing and saving training data:  92%|9| 260/284 [00:16<00:01, 15.55itNormalizing and saving training data:  95%|9| 270/284 [00:17<00:00, 15.53itNormalizing and saving training data:  99%|9| 280/284 [00:18<00:00, 15.46itNormalizing and saving training data: 100%|#| 284/284 [00:18<00:00, 15.72it
2025-11-19 21:23:07,082 - INFO - Training data processing completed during stats computation phase
2025-11-19 21:23:07,089 - INFO - Loaded normalization statistics:
2025-11-19 21:23:07,089 - INFO -   Mean: 1.254635
2025-11-19 21:23:07,089 - INFO -   Std: 2.504804
2025-11-19 21:23:07,089 - INFO - Split train already completed, skipping
2025-11-19 21:23:07,089 - INFO - Processing test split...
2025-11-19 21:23:07,089 - INFO - Need to process 40/40 sequences for test
2025-11-19 21:23:07,090 - INFO - Processing 40 sequences from 11 unique files
2025-11-19 21:23:07,090 - INFO - Average 3.6 sequences per file
Processing test:   0%|                              | 0/40 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/40 [00:01<00:50,  1.31s/it]2025-11-19 21:23:08,397 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold4\test_dataset.h5
2025-11-19 21:23:09,751 - INFO - Progress: 304/324 (93.8%) - ETA: 0.1 minutes
Processing test:  52%|###########          | 21/40 [00:03<00:03,  6.17it/s]Processing test:  55%|###########5         | 22/40 [00:10<00:10,  1.71it/s]Processing test:  65%|#############6       | 26/40 [00:11<00:07,  1.92it/s]Processing test:  70%|##############7      | 28/40 [00:15<00:08,  1.34it/s]Processing test:  75%|###############7     | 30/40 [00:16<00:06,  1.45it/s]2025-11-19 21:23:24,324 - INFO - Progress: 314/324 (96.9%) - ETA: 0.1 minutes
Processing test:  78%|################2    | 31/40 [00:22<00:12,  1.34s/it]Processing test:  90%|##################9  | 36/40 [00:23<00:03,  1.24it/s]Processing test:  92%|###################4 | 37/40 [00:25<00:02,  1.11it/s]Processing test:  98%|####################4| 39/40 [00:26<00:00,  1.28it/s]Processing test: 100%|#####################| 40/40 [00:27<00:00,  1.26it/s]2025-11-19 21:23:34,733 - INFO - Progress: 324/324 (100.0%) - ETA: 0.0 minutes
Processing test: 100%|#####################| 40/40 [00:27<00:00,  1.45it/s]
2025-11-19 21:23:34,750 - INFO - Validating final datasets...
2025-11-19 21:23:34,759 - INFO - train dataset validation:
2025-11-19 21:23:34,759 - INFO -   - Segments: 284
2025-11-19 21:23:34,759 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:23:34,759 - INFO -   - Classes: 142 preictal, 142 interictal
2025-11-19 21:23:34,759 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:23:34,765 - INFO - test dataset validation:
2025-11-19 21:23:34,765 - INFO -   - Segments: 40
2025-11-19 21:23:34,765 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:23:34,766 - INFO -   - Classes: 20 preictal, 20 interictal
2025-11-19 21:23:34,766 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:23:34,766 - INFO - ============================================================
2025-11-19 21:23:34,766 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 21:23:34,766 - INFO - Total time: 2.2 minutes
2025-11-19 21:23:34,766 - INFO - Processed segments: 324
2025-11-19 21:23:34,766 - INFO - Average rate: 2.4 segments/second
2025-11-19 21:23:34,766 - INFO - ============================================================
✅ Fold 4 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 5/9
============================================================
2025-11-19 21:23:34,832 - INFO - ============================================================
2025-11-19 21:23:34,832 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 21:23:34,832 - INFO - ============================================================
2025-11-19 21:23:34,832 - INFO - Output prefix: chb06_fold5
2025-11-19 21:23:34,832 - INFO - EEG Preprocessor initialized
2025-11-19 21:23:34,832 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 21:23:34,832 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 21:23:34,832 - INFO - Segment duration: 5 seconds
2025-11-19 21:23:34,832 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 21:23:34,832 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 21:23:34,832 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 21:23:34,833 - INFO - Loading segments from chb06_fold5_sequences_prediction.json
2025-11-19 21:23:34,845 - INFO - Loaded 324 total sequences
2025-11-19 21:23:34,845 - INFO - Channel validation (from segmentation): 17/18 files valid
2025-11-19 21:23:34,845 - INFO - Files skipped due to missing channels: 1
2025-11-19 21:23:34,845 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 21:23:34,845 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 21:23:34,845 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 21:23:34,845 - INFO - train: 294 sequences (147 preictal, 147 interictal)
2025-11-19 21:23:34,845 - INFO - test: 30 sequences (15 preictal, 15 interictal)
2025-11-19 21:23:34,863 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 21:23:34,863 - INFO - train: kept 147 preictal and 147 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:23:34,863 - INFO - test: kept 15 preictal and 15 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:23:34,880 - INFO - ============================================================
2025-11-19 21:23:34,880 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 21:23:34,880 - INFO - ============================================================
2025-11-19 21:23:34,880 - INFO - Processing 294 training samples to compute normalization stats...
2025-11-19 21:23:34,880 - INFO - Processing 294 sequences from 17 unique files
Processing training data:   0%|                    | 0/294 [00:00<?, ?it/s]Processing training data:   0%|            | 1/294 [00:05<28:27,  5.83s/it]Processing training data:   6%|6          | 18/294 [00:11<02:35,  1.77it/s]Processing training data:  15%|#6         | 43/294 [00:18<01:31,  2.76it/s]Processing training data:  21%|##3        | 63/294 [00:24<01:16,  3.02it/s]Processing training data:  24%|##6        | 72/294 [00:30<01:33,  2.37it/s]Processing training data:  29%|###2       | 86/294 [00:37<01:32,  2.25it/s]Processing training data:  50%|#####     | 147/294 [00:44<00:32,  4.49it/s]Processing training data:  54%|#####4    | 159/294 [00:48<00:31,  4.28it/s]Processing training data:  56%|#####6    | 166/294 [00:51<00:33,  3.78it/s]Processing training data:  60%|######    | 177/294 [00:59<00:41,  2.81it/s]Processing training data:  66%|######5   | 193/294 [01:02<00:31,  3.17it/s]Processing training data:  68%|######8   | 200/294 [01:04<00:27,  3.41it/s]Processing training data:  76%|#######5  | 222/294 [01:11<00:22,  3.19it/s]Processing training data:  82%|########1 | 240/294 [01:13<00:12,  4.25it/s]Processing training data:  88%|########8 | 260/294 [01:13<00:05,  5.93it/s]Processing training data:  97%|#########6| 284/294 [01:15<00:01,  8.02it/s]Processing training data:  98%|#########7| 287/294 [01:20<00:01,  4.45it/s]Processing training data: 100%|##########| 294/294 [01:20<00:00,  3.67it/s]
2025-11-19 21:24:55,097 - INFO - Computing normalization statistics from training data...
2025-11-19 21:24:55,600 - INFO - Normalization stats computed:
2025-11-19 21:24:55,600 - INFO -   Mean: 1.279081
2025-11-19 21:24:55,600 - INFO -   Std: 2.526186
2025-11-19 21:24:55,600 - INFO -   Saved to: preprocessing\checkpoints\chb06_fold5\normalization_stats.json
2025-11-19 21:24:55,653 - INFO - Applying normalization and saving 294 training sequences...
Normalizing and saving training data:   0%|        | 0/294 [00:00<?, ?it/s]2025-11-19 21:24:55,664 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold5\train_dataset.h5
Normalizing and saving training data:   3%| | 10/294 [00:00<00:18, 15.66it/Normalizing and saving training data:   7%| | 20/294 [00:01<00:17, 15.59it/Normalizing and saving training data:  10%|1| 30/294 [00:01<00:16, 15.64it/Normalizing and saving training data:  14%|1| 40/294 [00:02<00:16, 15.55it/Normalizing and saving training data:  17%|1| 50/294 [00:03<00:15, 15.54it/Normalizing and saving training data:  20%|2| 60/294 [00:03<00:15, 15.58it/Normalizing and saving training data:  24%|2| 70/294 [00:04<00:14, 15.57it/Normalizing and saving training data:  27%|2| 80/294 [00:05<00:13, 15.62it/Normalizing and saving training data:  31%|3| 90/294 [00:05<00:13, 15.63it/Normalizing and saving training data:  34%|3| 100/294 [00:06<00:12, 15.66itNormalizing and saving training data:  37%|3| 110/294 [00:07<00:11, 15.67itNormalizing and saving training data:  41%|4| 120/294 [00:07<00:11, 15.71itNormalizing and saving training data:  44%|4| 130/294 [00:08<00:10, 15.74itNormalizing and saving training data:  48%|4| 140/294 [00:08<00:09, 15.69itNormalizing and saving training data:  51%|5| 150/294 [00:09<00:09, 15.60itNormalizing and saving training data:  54%|5| 160/294 [00:10<00:08, 15.56itNormalizing and saving training data:  58%|5| 170/294 [00:10<00:07, 15.54itNormalizing and saving training data:  61%|6| 180/294 [00:11<00:07, 15.49itNormalizing and saving training data:  65%|6| 190/294 [00:12<00:06, 15.52itNormalizing and saving training data:  68%|6| 200/294 [00:12<00:06, 15.50itNormalizing and saving training data:  71%|7| 210/294 [00:13<00:05, 15.54itNormalizing and saving training data:  75%|7| 220/294 [00:14<00:04, 15.52itNormalizing and saving training data:  78%|7| 230/294 [00:14<00:04, 15.55itNormalizing and saving training data:  82%|8| 240/294 [00:15<00:03, 15.51itNormalizing and saving training data:  85%|8| 250/294 [00:16<00:02, 15.35itNormalizing and saving training data:  88%|8| 260/294 [00:16<00:02, 15.35itNormalizing and saving training data:  92%|9| 270/294 [00:17<00:01, 15.39itNormalizing and saving training data:  95%|9| 280/294 [00:18<00:00, 15.32itNormalizing and saving training data:  99%|9| 290/294 [00:18<00:00, 15.26itNormalizing and saving training data: 100%|#| 294/294 [00:18<00:00, 15.73it
2025-11-19 21:25:14,650 - INFO - Training data processing completed during stats computation phase
2025-11-19 21:25:14,657 - INFO - Loaded normalization statistics:
2025-11-19 21:25:14,657 - INFO -   Mean: 1.279081
2025-11-19 21:25:14,657 - INFO -   Std: 2.526186
2025-11-19 21:25:14,657 - INFO - Split train already completed, skipping
2025-11-19 21:25:14,657 - INFO - Processing test split...
2025-11-19 21:25:14,657 - INFO - Need to process 30/30 sequences for test
2025-11-19 21:25:14,658 - INFO - Processing 30 sequences from 10 unique files
2025-11-19 21:25:14,658 - INFO - Average 3.0 sequences per file
Processing test:   0%|                              | 0/30 [00:00<?, ?it/s]Processing test:   3%|7                     | 1/30 [00:01<00:45,  1.57s/it]Processing test:  10%|##2                   | 3/30 [00:02<00:21,  1.26it/s]Processing test:  13%|##9                   | 4/30 [00:03<00:23,  1.10it/s]2025-11-19 21:25:18,389 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold5\test_dataset.h5
2025-11-19 21:25:19,489 - INFO - Progress: 312/324 (96.3%) - ETA: 0.1 minutes
Processing test:  63%|#############3       | 19/30 [00:05<00:02,  4.44it/s]Processing test:  67%|##############       | 20/30 [00:08<00:04,  2.32it/s]Processing test:  77%|################1    | 23/30 [00:11<00:04,  1.68it/s]Processing test:  87%|##################2  | 26/30 [00:16<00:03,  1.15it/s]Processing test:  93%|###################6 | 28/30 [00:17<00:01,  1.25it/s]2025-11-19 21:25:33,103 - INFO - Progress: 322/324 (99.4%) - ETA: 0.0 minutes
Processing test:  97%|####################3| 29/30 [00:19<00:00,  1.12it/s]Processing test: 100%|#####################| 30/30 [00:20<00:00,  1.11it/s]Processing test: 100%|#####################| 30/30 [00:20<00:00,  1.48it/s]
2025-11-19 21:25:35,157 - INFO - Validating final datasets...
2025-11-19 21:25:35,166 - INFO - train dataset validation:
2025-11-19 21:25:35,166 - INFO -   - Segments: 294
2025-11-19 21:25:35,166 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:25:35,166 - INFO -   - Classes: 147 preictal, 147 interictal
2025-11-19 21:25:35,166 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:25:35,172 - INFO - test dataset validation:
2025-11-19 21:25:35,172 - INFO -   - Segments: 30
2025-11-19 21:25:35,172 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:25:35,172 - INFO -   - Classes: 15 preictal, 15 interictal
2025-11-19 21:25:35,172 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:25:35,173 - INFO - ============================================================
2025-11-19 21:25:35,173 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 21:25:35,173 - INFO - Total time: 2.0 minutes
2025-11-19 21:25:35,173 - INFO - Processed segments: 324
2025-11-19 21:25:35,173 - INFO - Average rate: 2.7 segments/second
2025-11-19 21:25:35,173 - INFO - ============================================================
✅ Fold 5 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 6/9
============================================================
2025-11-19 21:25:35,238 - INFO - ============================================================
2025-11-19 21:25:35,238 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 21:25:35,238 - INFO - ============================================================
2025-11-19 21:25:35,238 - INFO - Output prefix: chb06_fold6
2025-11-19 21:25:35,238 - INFO - EEG Preprocessor initialized
2025-11-19 21:25:35,238 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 21:25:35,238 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 21:25:35,238 - INFO - Segment duration: 5 seconds
2025-11-19 21:25:35,238 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 21:25:35,239 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 21:25:35,239 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 21:25:35,239 - INFO - Loading segments from chb06_fold6_sequences_prediction.json
2025-11-19 21:25:35,251 - INFO - Loaded 324 total sequences
2025-11-19 21:25:35,251 - INFO - Channel validation (from segmentation): 17/18 files valid
2025-11-19 21:25:35,251 - INFO - Files skipped due to missing channels: 1
2025-11-19 21:25:35,251 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 21:25:35,251 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 21:25:35,251 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 21:25:35,251 - INFO - train: 276 sequences (138 preictal, 138 interictal)
2025-11-19 21:25:35,251 - INFO - test: 48 sequences (24 preictal, 24 interictal)
2025-11-19 21:25:35,269 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 21:25:35,269 - INFO - train: kept 138 preictal and 138 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:25:35,269 - INFO - test: kept 24 preictal and 24 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:25:35,286 - INFO - ============================================================
2025-11-19 21:25:35,286 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 21:25:35,286 - INFO - ============================================================
2025-11-19 21:25:35,286 - INFO - Processing 276 training samples to compute normalization stats...
2025-11-19 21:25:35,286 - INFO - Processing 276 sequences from 16 unique files
Processing training data:   0%|                    | 0/276 [00:00<?, ?it/s]Processing training data:   0%|            | 1/276 [00:06<28:54,  6.31s/it]Processing training data:  22%|##4        | 62/276 [00:12<00:35,  5.99it/s]Processing training data:  31%|###4       | 86/276 [00:18<00:38,  4.90it/s]Processing training data:  37%|###7      | 103/276 [00:25<00:43,  4.00it/s]Processing training data:  43%|####3     | 120/276 [00:31<00:44,  3.53it/s]Processing training data:  51%|#####     | 140/276 [00:32<00:28,  4.73it/s]Processing training data:  58%|#####7    | 160/276 [00:33<00:18,  6.11it/s]Processing training data:  66%|######5   | 182/276 [00:40<00:19,  4.74it/s]Processing training data:  71%|#######1  | 197/276 [00:45<00:19,  4.10it/s]Processing training data:  75%|#######5  | 207/276 [00:51<00:21,  3.25it/s]Processing training data:  80%|########  | 221/276 [00:58<00:19,  2.85it/s]Processing training data:  85%|########5 | 235/276 [01:06<00:16,  2.42it/s]Processing training data:  88%|########8 | 244/276 [01:12<00:15,  2.12it/s]Processing training data:  93%|#########2| 256/276 [01:17<00:09,  2.22it/s]Processing training data:  96%|#########6| 266/276 [01:21<00:04,  2.28it/s]Processing training data: 100%|#########9| 275/276 [01:21<00:00,  2.93it/s]Processing training data: 100%|##########| 276/276 [01:21<00:00,  3.39it/s]
2025-11-19 21:26:56,780 - INFO - Computing normalization statistics from training data...
2025-11-19 21:26:57,309 - INFO - Normalization stats computed:
2025-11-19 21:26:57,309 - INFO -   Mean: 1.229926
2025-11-19 21:26:57,309 - INFO -   Std: 2.547800
2025-11-19 21:26:57,309 - INFO -   Saved to: preprocessing\checkpoints\chb06_fold6\normalization_stats.json
2025-11-19 21:26:57,360 - INFO - Applying normalization and saving 276 training sequences...
Normalizing and saving training data:   0%|        | 0/276 [00:00<?, ?it/s]2025-11-19 21:26:57,368 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold6\train_dataset.h5
Normalizing and saving training data:   4%| | 10/276 [00:00<00:16, 16.00it/Normalizing and saving training data:   7%| | 20/276 [00:01<00:16, 15.81it/Normalizing and saving training data:  11%|1| 30/276 [00:01<00:15, 15.82it/Normalizing and saving training data:  14%|1| 40/276 [00:02<00:14, 15.84it/Normalizing and saving training data:  18%|1| 50/276 [00:03<00:14, 15.82it/Normalizing and saving training data:  22%|2| 60/276 [00:03<00:13, 15.84it/Normalizing and saving training data:  25%|2| 70/276 [00:04<00:13, 15.71it/Normalizing and saving training data:  29%|2| 80/276 [00:05<00:12, 15.56it/Normalizing and saving training data:  33%|3| 90/276 [00:05<00:11, 15.60it/Normalizing and saving training data:  36%|3| 100/276 [00:06<00:11, 15.60itNormalizing and saving training data:  40%|3| 110/276 [00:07<00:10, 15.62itNormalizing and saving training data:  43%|4| 120/276 [00:07<00:09, 15.68itNormalizing and saving training data:  47%|4| 130/276 [00:08<00:09, 15.69itNormalizing and saving training data:  51%|5| 140/276 [00:08<00:08, 15.56itNormalizing and saving training data:  54%|5| 150/276 [00:09<00:08, 15.55itNormalizing and saving training data:  58%|5| 160/276 [00:10<00:07, 15.52itNormalizing and saving training data:  62%|6| 170/276 [00:10<00:06, 15.55itNormalizing and saving training data:  65%|6| 180/276 [00:11<00:06, 15.55itNormalizing and saving training data:  69%|6| 190/276 [00:12<00:05, 15.54itNormalizing and saving training data:  72%|7| 200/276 [00:12<00:04, 15.50itNormalizing and saving training data:  76%|7| 210/276 [00:13<00:04, 15.51itNormalizing and saving training data:  80%|7| 220/276 [00:14<00:03, 15.53itNormalizing and saving training data:  83%|8| 230/276 [00:14<00:02, 15.49itNormalizing and saving training data:  87%|8| 240/276 [00:15<00:02, 15.44itNormalizing and saving training data:  91%|9| 250/276 [00:16<00:01, 15.48itNormalizing and saving training data:  94%|9| 260/276 [00:16<00:01, 15.49itNormalizing and saving training data:  98%|9| 270/276 [00:17<00:00, 15.48itNormalizing and saving training data: 100%|#| 276/276 [00:17<00:00, 15.93it
2025-11-19 21:27:15,107 - INFO - Training data processing completed during stats computation phase
2025-11-19 21:27:15,115 - INFO - Loaded normalization statistics:
2025-11-19 21:27:15,115 - INFO -   Mean: 1.229926
2025-11-19 21:27:15,115 - INFO -   Std: 2.547800
2025-11-19 21:27:15,115 - INFO - Split train already completed, skipping
2025-11-19 21:27:15,115 - INFO - Processing test split...
2025-11-19 21:27:15,115 - INFO - Need to process 48/48 sequences for test
2025-11-19 21:27:15,115 - INFO - Processing 48 sequences from 10 unique files
2025-11-19 21:27:15,115 - INFO - Average 4.8 sequences per file
Processing test:   0%|                              | 0/48 [00:00<?, ?it/s]Processing test:   2%|4                     | 1/48 [00:05<04:11,  5.35s/it]Processing test:  10%|##2                   | 5/48 [00:10<01:19,  1.84s/it]Processing test:  19%|####1                 | 9/48 [00:11<00:36,  1.05it/s]2025-11-19 21:27:26,237 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold6\test_dataset.h5
2025-11-19 21:27:28,190 - INFO - Progress: 308/324 (95.1%) - ETA: 0.1 minutes
Processing test:  69%|##############4      | 33/48 [00:14<00:04,  3.38it/s]Processing test:  73%|###############3     | 35/48 [00:15<00:04,  3.22it/s]Processing test:  77%|################1    | 37/48 [00:17<00:04,  2.60it/s]Processing test:  81%|#################    | 39/48 [00:24<00:07,  1.27it/s]2025-11-19 21:27:40,021 - INFO - Progress: 318/324 (98.1%) - ETA: 0.0 minutes
Processing test:  90%|##################8  | 43/48 [00:28<00:04,  1.15it/s]Processing test:  98%|####################5| 47/48 [00:29<00:00,  1.46it/s]Processing test: 100%|#####################| 48/48 [00:30<00:00,  1.43it/s]Processing test: 100%|#####################| 48/48 [00:30<00:00,  1.58it/s]
2025-11-19 21:27:45,895 - INFO - Validating final datasets...
2025-11-19 21:27:45,903 - INFO - train dataset validation:
2025-11-19 21:27:45,903 - INFO -   - Segments: 276
2025-11-19 21:27:45,903 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:27:45,903 - INFO -   - Classes: 138 preictal, 138 interictal
2025-11-19 21:27:45,903 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:27:45,909 - INFO - test dataset validation:
2025-11-19 21:27:45,909 - INFO -   - Segments: 48
2025-11-19 21:27:45,909 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:27:45,910 - INFO -   - Classes: 24 preictal, 24 interictal
2025-11-19 21:27:45,910 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:27:45,910 - INFO - ============================================================
2025-11-19 21:27:45,910 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 21:27:45,910 - INFO - Total time: 2.2 minutes
2025-11-19 21:27:45,910 - INFO - Processed segments: 324
2025-11-19 21:27:45,910 - INFO - Average rate: 2.5 segments/second
2025-11-19 21:27:45,910 - INFO - ============================================================
✅ Fold 6 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 7/9
============================================================
2025-11-19 21:27:45,970 - INFO - ============================================================
2025-11-19 21:27:45,970 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 21:27:45,970 - INFO - ============================================================
2025-11-19 21:27:45,970 - INFO - Output prefix: chb06_fold7
2025-11-19 21:27:45,970 - INFO - EEG Preprocessor initialized
2025-11-19 21:27:45,970 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 21:27:45,970 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 21:27:45,970 - INFO - Segment duration: 5 seconds
2025-11-19 21:27:45,971 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 21:27:45,971 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 21:27:45,971 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 21:27:45,971 - INFO - Loading segments from chb06_fold7_sequences_prediction.json
2025-11-19 21:27:45,983 - INFO - Loaded 324 total sequences
2025-11-19 21:27:45,983 - INFO - Channel validation (from segmentation): 17/18 files valid
2025-11-19 21:27:45,983 - INFO - Files skipped due to missing channels: 1
2025-11-19 21:27:45,983 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 21:27:45,983 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 21:27:45,983 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 21:27:45,983 - INFO - train: 280 sequences (140 preictal, 140 interictal)
2025-11-19 21:27:45,983 - INFO - test: 44 sequences (22 preictal, 22 interictal)
2025-11-19 21:27:46,000 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 21:27:46,001 - INFO - train: kept 140 preictal and 140 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:27:46,001 - INFO - test: kept 22 preictal and 22 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:27:46,017 - INFO - ============================================================
2025-11-19 21:27:46,017 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 21:27:46,018 - INFO - ============================================================
2025-11-19 21:27:46,018 - INFO - Processing 280 training samples to compute normalization stats...
2025-11-19 21:27:46,018 - INFO - Processing 280 sequences from 15 unique files
Processing training data:   0%|                    | 0/280 [00:00<?, ?it/s]Processing training data:   0%|            | 1/280 [00:04<21:39,  4.66s/it]Processing training data:   8%|9          | 23/280 [00:10<01:47,  2.39it/s]Processing training data:  30%|###3       | 84/280 [00:14<00:25,  7.79it/s]Processing training data:  33%|###6       | 93/280 [00:17<00:31,  6.02it/s]Processing training data:  42%|####2     | 118/280 [00:23<00:30,  5.30it/s]Processing training data:  46%|####6     | 130/280 [00:30<00:39,  3.81it/s]Processing training data:  52%|#####2    | 147/280 [00:36<00:38,  3.42it/s]Processing training data:  57%|#####7    | 160/280 [00:43<00:42,  2.85it/s]Processing training data:  64%|######4   | 180/280 [00:44<00:24,  4.00it/s]Processing training data:  71%|#######1  | 200/280 [00:51<00:22,  3.59it/s]Processing training data:  78%|#######7  | 217/280 [00:58<00:20,  3.15it/s]Processing training data:  83%|########2 | 232/280 [01:05<00:17,  2.76it/s]Processing training data:  88%|########8 | 247/280 [01:12<00:12,  2.57it/s]Processing training data:  93%|#########2| 260/280 [01:19<00:08,  2.34it/s]Processing training data:  97%|#########6| 271/280 [01:23<00:03,  2.37it/s]Processing training data: 100%|##########| 280/280 [01:23<00:00,  3.34it/s]
2025-11-19 21:29:09,913 - INFO - Computing normalization statistics from training data...
2025-11-19 21:29:10,442 - INFO - Normalization stats computed:
2025-11-19 21:29:10,442 - INFO -   Mean: 1.292349
2025-11-19 21:29:10,442 - INFO -   Std: 2.500834
2025-11-19 21:29:10,442 - INFO -   Saved to: preprocessing\checkpoints\chb06_fold7\normalization_stats.json
2025-11-19 21:29:10,493 - INFO - Applying normalization and saving 280 training sequences...
Normalizing and saving training data:   0%|        | 0/280 [00:00<?, ?it/s]2025-11-19 21:29:10,501 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold7\train_dataset.h5
Normalizing and saving training data:   4%| | 10/280 [00:00<00:17, 15.70it/Normalizing and saving training data:   7%| | 20/280 [00:01<00:16, 15.51it/Normalizing and saving training data:  11%|1| 30/280 [00:01<00:16, 15.57it/Normalizing and saving training data:  14%|1| 40/280 [00:02<00:15, 15.62it/Normalizing and saving training data:  18%|1| 50/280 [00:03<00:14, 15.67it/Normalizing and saving training data:  21%|2| 60/280 [00:03<00:14, 15.66it/Normalizing and saving training data:  25%|2| 70/280 [00:04<00:13, 15.68it/Normalizing and saving training data:  29%|2| 80/280 [00:05<00:12, 15.72it/Normalizing and saving training data:  32%|3| 90/280 [00:05<00:12, 15.71it/Normalizing and saving training data:  36%|3| 100/280 [00:06<00:11, 15.68itNormalizing and saving training data:  39%|3| 110/280 [00:07<00:10, 15.54itNormalizing and saving training data:  43%|4| 120/280 [00:07<00:10, 15.58itNormalizing and saving training data:  46%|4| 130/280 [00:08<00:09, 15.65itNormalizing and saving training data:  50%|5| 140/280 [00:08<00:08, 15.64itNormalizing and saving training data:  54%|5| 150/280 [00:09<00:08, 15.60itNormalizing and saving training data:  57%|5| 160/280 [00:10<00:07, 15.59itNormalizing and saving training data:  61%|6| 170/280 [00:10<00:07, 15.60itNormalizing and saving training data:  64%|6| 180/280 [00:11<00:06, 15.59itNormalizing and saving training data:  68%|6| 190/280 [00:12<00:05, 15.59itNormalizing and saving training data:  71%|7| 200/280 [00:12<00:05, 15.51itNormalizing and saving training data:  75%|7| 210/280 [00:13<00:04, 15.47itNormalizing and saving training data:  79%|7| 220/280 [00:14<00:03, 15.51itNormalizing and saving training data:  82%|8| 230/280 [00:14<00:03, 15.51itNormalizing and saving training data:  86%|8| 240/280 [00:15<00:02, 15.52itNormalizing and saving training data:  89%|8| 250/280 [00:16<00:01, 15.52itNormalizing and saving training data:  93%|9| 260/280 [00:16<00:01, 15.50itNormalizing and saving training data:  96%|9| 270/280 [00:17<00:00, 15.49itNormalizing and saving training data: 100%|#| 280/280 [00:17<00:00, 15.49itNormalizing and saving training data: 100%|#| 280/280 [00:17<00:00, 15.57it
2025-11-19 21:29:28,490 - INFO - Training data processing completed during stats computation phase
2025-11-19 21:29:28,497 - INFO - Loaded normalization statistics:
2025-11-19 21:29:28,497 - INFO -   Mean: 1.292349
2025-11-19 21:29:28,497 - INFO -   Std: 2.500834
2025-11-19 21:29:28,497 - INFO - Split train already completed, skipping
2025-11-19 21:29:28,497 - INFO - Processing test split...
2025-11-19 21:29:28,497 - INFO - Need to process 44/44 sequences for test
2025-11-19 21:29:28,497 - INFO - Processing 44 sequences from 10 unique files
2025-11-19 21:29:28,497 - INFO - Average 4.4 sequences per file
Processing test:   0%|                              | 0/44 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/44 [00:05<04:03,  5.66s/it]Processing test:  16%|###5                  | 7/44 [00:08<00:36,  1.02it/s]Processing test:  23%|####7                | 10/44 [00:09<00:25,  1.32it/s]2025-11-19 21:29:37,990 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold7\test_dataset.h5
2025-11-19 21:29:39,932 - INFO - Progress: 311/324 (96.0%) - ETA: 0.1 minutes
Processing test:  73%|###############2     | 32/44 [00:12<00:03,  3.94it/s]Processing test:  75%|###############7     | 33/44 [00:15<00:04,  2.54it/s]Processing test:  84%|#################6   | 37/44 [00:17<00:03,  2.33it/s]Processing test:  89%|##################6  | 39/44 [00:19<00:02,  1.96it/s]Processing test:  93%|###################5 | 41/44 [00:23<00:02,  1.34it/s]2025-11-19 21:29:52,836 - INFO - Progress: 322/324 (99.4%) - ETA: 0.0 minutes
Processing test:  98%|####################5| 43/44 [00:25<00:00,  1.32it/s]Processing test: 100%|#####################| 44/44 [00:26<00:00,  1.30it/s]Processing test: 100%|#####################| 44/44 [00:26<00:00,  1.68it/s]
2025-11-19 21:29:54,783 - INFO - Validating final datasets...
2025-11-19 21:29:54,792 - INFO - train dataset validation:
2025-11-19 21:29:54,792 - INFO -   - Segments: 280
2025-11-19 21:29:54,792 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:29:54,792 - INFO -   - Classes: 140 preictal, 140 interictal
2025-11-19 21:29:54,792 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:29:54,798 - INFO - test dataset validation:
2025-11-19 21:29:54,798 - INFO -   - Segments: 44
2025-11-19 21:29:54,798 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:29:54,798 - INFO -   - Classes: 22 preictal, 22 interictal
2025-11-19 21:29:54,798 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:29:54,798 - INFO - ============================================================
2025-11-19 21:29:54,798 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 21:29:54,798 - INFO - Total time: 2.1 minutes
2025-11-19 21:29:54,798 - INFO - Processed segments: 324
2025-11-19 21:29:54,798 - INFO - Average rate: 2.5 segments/second
2025-11-19 21:29:54,798 - INFO - ============================================================
✅ Fold 7 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 8/9
============================================================
2025-11-19 21:29:54,862 - INFO - ============================================================
2025-11-19 21:29:54,862 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 21:29:54,862 - INFO - ============================================================
2025-11-19 21:29:54,862 - INFO - Output prefix: chb06_fold8
2025-11-19 21:29:54,862 - INFO - EEG Preprocessor initialized
2025-11-19 21:29:54,862 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 21:29:54,862 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 21:29:54,862 - INFO - Segment duration: 5 seconds
2025-11-19 21:29:54,862 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 21:29:54,862 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 21:29:54,862 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 21:29:54,862 - INFO - Loading segments from chb06_fold8_sequences_prediction.json
2025-11-19 21:29:54,884 - INFO - Loaded 816 total sequences
2025-11-19 21:29:54,884 - INFO - Channel validation (from segmentation): 17/18 files valid
2025-11-19 21:29:54,884 - INFO - Files skipped due to missing channels: 1
2025-11-19 21:29:54,884 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 21:29:54,884 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 21:29:54,884 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 21:29:54,884 - INFO - train: 324 sequences (162 preictal, 162 interictal)
2025-11-19 21:29:54,884 - INFO - test: 492 sequences (0 preictal, 492 interictal)
2025-11-19 21:29:54,926 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 21:29:54,926 - INFO - train: kept 162 preictal and 162 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:29:54,926 - WARNING - test: Skipped balancing due to missing class
2025-11-19 21:29:54,968 - INFO - ============================================================
2025-11-19 21:29:54,968 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 21:29:54,968 - INFO - ============================================================
2025-11-19 21:29:54,968 - INFO - Processing 324 training samples to compute normalization stats...
2025-11-19 21:29:54,968 - INFO - Processing 324 sequences from 17 unique files
Processing training data:   0%|                    | 0/324 [00:00<?, ?it/s]Processing training data:   0%|            | 1/324 [00:05<27:08,  5.04s/it]Processing training data:   5%|5          | 16/324 [00:11<03:08,  1.63it/s]Processing training data:  24%|##6        | 77/324 [00:17<00:46,  5.30it/s]Processing training data:  29%|###2       | 95/324 [00:18<00:34,  6.62it/s]Processing training data:  37%|###6      | 119/324 [00:25<00:40,  5.02it/s]Processing training data:  43%|####3     | 140/324 [00:31<00:40,  4.55it/s]Processing training data:  51%|#####     | 164/324 [00:32<00:26,  6.10it/s]Processing training data:  57%|#####7    | 186/324 [00:39<00:28,  4.85it/s]Processing training data:  63%|######3   | 205/324 [00:42<00:23,  4.99it/s]Processing training data:  65%|######5   | 211/324 [00:49<00:32,  3.43it/s]Processing training data:  71%|#######   | 230/324 [00:50<00:20,  4.61it/s]Processing training data:  77%|#######7  | 250/324 [00:58<00:20,  3.62it/s]Processing training data:  84%|########3 | 272/324 [01:06<00:15,  3.27it/s]Processing training data:  88%|########7 | 284/324 [01:07<00:10,  3.89it/s]Processing training data:  88%|########8 | 286/324 [01:14<00:16,  2.37it/s]Processing training data:  94%|#########3| 303/324 [01:19<00:08,  2.61it/s]Processing training data:  98%|#########7| 316/324 [01:27<00:03,  2.31it/s]Processing training data: 100%|##########| 324/324 [01:27<00:00,  3.72it/s]
2025-11-19 21:31:22,162 - INFO - Computing normalization statistics from training data...
2025-11-19 21:31:22,779 - INFO - Normalization stats computed:
2025-11-19 21:31:22,779 - INFO -   Mean: 1.210384
2025-11-19 21:31:22,779 - INFO -   Std: 2.532819
2025-11-19 21:31:22,779 - INFO -   Saved to: preprocessing\checkpoints\chb06_fold8\normalization_stats.json
2025-11-19 21:31:22,863 - INFO - Applying normalization and saving 324 training sequences...
Normalizing and saving training data:   0%|        | 0/324 [00:00<?, ?it/s]2025-11-19 21:31:22,874 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold8\train_dataset.h5
Normalizing and saving training data:   3%| | 10/324 [00:00<00:21, 14.86it/Normalizing and saving training data:   6%| | 20/324 [00:01<00:20, 14.64it/Normalizing and saving training data:   9%| | 30/324 [00:02<00:19, 14.77it/Normalizing and saving training data:  12%|1| 40/324 [00:02<00:19, 14.72it/Normalizing and saving training data:  15%|1| 50/324 [00:03<00:18, 14.72it/Normalizing and saving training data:  19%|1| 60/324 [00:04<00:17, 14.85it/Normalizing and saving training data:  22%|2| 70/324 [00:04<00:17, 14.90it/Normalizing and saving training data:  25%|2| 80/324 [00:05<00:16, 14.97it/Normalizing and saving training data:  28%|2| 90/324 [00:06<00:15, 15.00it/Normalizing and saving training data:  31%|3| 100/324 [00:06<00:14, 15.02itNormalizing and saving training data:  34%|3| 110/324 [00:07<00:14, 15.07itNormalizing and saving training data:  37%|3| 120/324 [00:08<00:13, 15.11itNormalizing and saving training data:  40%|4| 130/324 [00:08<00:12, 15.12itNormalizing and saving training data:  43%|4| 140/324 [00:09<00:12, 15.07itNormalizing and saving training data:  46%|4| 150/324 [00:10<00:11, 15.06itNormalizing and saving training data:  49%|4| 160/324 [00:10<00:10, 15.02itNormalizing and saving training data:  52%|5| 170/324 [00:11<00:10, 15.01itNormalizing and saving training data:  56%|5| 180/324 [00:12<00:09, 14.97itNormalizing and saving training data:  59%|5| 190/324 [00:12<00:08, 14.92itNormalizing and saving training data:  62%|6| 200/324 [00:13<00:08, 14.87itNormalizing and saving training data:  65%|6| 210/324 [00:14<00:07, 14.80itNormalizing and saving training data:  68%|6| 220/324 [00:14<00:07, 13.93itNormalizing and saving training data:  71%|7| 230/324 [00:15<00:06, 13.94itNormalizing and saving training data:  74%|7| 240/324 [00:16<00:06, 13.89itNormalizing and saving training data:  77%|7| 250/324 [00:17<00:05, 14.08itNormalizing and saving training data:  80%|8| 260/324 [00:17<00:04, 14.03itNormalizing and saving training data:  83%|8| 270/324 [00:18<00:03, 14.10itNormalizing and saving training data:  86%|8| 280/324 [00:19<00:03, 14.20itNormalizing and saving training data:  90%|8| 290/324 [00:19<00:02, 14.31itNormalizing and saving training data:  93%|9| 300/324 [00:20<00:01, 14.25itNormalizing and saving training data:  96%|9| 310/324 [00:21<00:00, 14.23itNormalizing and saving training data:  99%|9| 320/324 [00:21<00:00, 14.19itNormalizing and saving training data: 100%|#| 324/324 [00:21<00:00, 14.77it
2025-11-19 21:31:45,152 - INFO - Training data processing completed during stats computation phase
2025-11-19 21:31:45,159 - INFO - Loaded normalization statistics:
2025-11-19 21:31:45,159 - INFO -   Mean: 1.210384
2025-11-19 21:31:45,159 - INFO -   Std: 2.532819
2025-11-19 21:31:45,159 - INFO - Split train already completed, skipping
2025-11-19 21:31:45,159 - INFO - Processing test split...
2025-11-19 21:31:45,159 - INFO - Need to process 492/492 sequences for test
2025-11-19 21:31:45,160 - INFO - Processing 492 sequences from 14 unique files
2025-11-19 21:31:45,160 - INFO - Average 35.1 sequences per file
Processing test:   0%|                             | 0/492 [00:00<?, ?it/s]Processing test:   0%|                     | 1/492 [00:05<47:16,  5.78s/it]2025-11-19 21:31:50,938 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold8\test_dataset.h5
2025-11-19 21:31:52,954 - INFO - Progress: 356/816 (43.6%) - ETA: 2.5 minutes
Processing test:   7%|#3                  | 33/492 [00:15<03:16,  2.34it/s]2025-11-19 21:32:04,412 - INFO - Progress: 412/816 (50.5%) - ETA: 2.1 minutes
Processing test:  18%|###6                | 89/492 [00:26<01:43,  3.88it/s]2025-11-19 21:32:13,816 - INFO - Progress: 450/816 (55.1%) - ETA: 1.9 minutes
Processing test:  26%|####9              | 127/492 [00:36<01:35,  3.84it/s]2025-11-19 21:32:24,372 - INFO - Progress: 495/816 (60.7%) - ETA: 1.6 minutes
Processing test:  35%|######6            | 172/492 [00:47<01:20,  3.95it/s]2025-11-19 21:32:35,656 - INFO - Progress: 547/816 (67.0%) - ETA: 1.3 minutes
Processing test:  46%|########6          | 224/492 [00:58<01:03,  4.25it/s]2025-11-19 21:32:46,209 - INFO - Progress: 594/816 (72.8%) - ETA: 1.1 minutes
Processing test:  55%|##########4        | 271/492 [01:08<00:50,  4.35it/s]2025-11-19 21:32:56,873 - INFO - Progress: 647/816 (79.3%) - ETA: 0.8 minutes
Processing test:  66%|############5      | 324/492 [01:19<00:37,  4.50it/s]2025-11-19 21:33:07,552 - INFO - Progress: 694/816 (85.0%) - ETA: 0.6 minutes
Processing test:  75%|##############3    | 371/492 [01:23<00:22,  5.49it/s]2025-11-19 21:33:09,700 - INFO - Progress: 705/816 (86.4%) - ETA: 0.5 minutes
Processing test:  78%|##############7    | 382/492 [01:31<00:25,  4.28it/s]2025-11-19 21:33:19,448 - INFO - Progress: 743/816 (91.1%) - ETA: 0.3 minutes
Processing test:  85%|################2  | 420/492 [01:38<00:15,  4.63it/s]2025-11-19 21:33:25,584 - INFO - Progress: 771/816 (94.5%) - ETA: 0.2 minutes
Processing test:  91%|#################3 | 448/492 [01:43<00:08,  4.92it/s]2025-11-19 21:33:29,885 - INFO - Progress: 794/816 (97.3%) - ETA: 0.1 minutes
Processing test:  96%|##################1| 471/492 [01:48<00:04,  4.81it/s]2025-11-19 21:33:34,819 - INFO - Progress: 814/816 (99.8%) - ETA: 0.0 minutes
Processing test: 100%|##################9| 491/492 [01:50<00:00,  5.47it/s]Processing test: 100%|###################| 492/492 [01:50<00:00,  4.46it/s]
2025-11-19 21:33:35,658 - INFO - Validating final datasets...
2025-11-19 21:33:35,666 - INFO - train dataset validation:
2025-11-19 21:33:35,666 - INFO -   - Segments: 324
2025-11-19 21:33:35,666 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:33:35,666 - INFO -   - Classes: 162 preictal, 162 interictal
2025-11-19 21:33:35,666 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:33:35,672 - INFO - test dataset validation:
2025-11-19 21:33:35,672 - INFO -   - Segments: 492
2025-11-19 21:33:35,672 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:33:35,672 - INFO -   - Classes: 0 preictal, 492 interictal
2025-11-19 21:33:35,672 - INFO -   - Balance: 0.0% preictal
2025-11-19 21:33:35,673 - INFO - ============================================================
2025-11-19 21:33:35,673 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 21:33:35,673 - INFO - Total time: 3.7 minutes
2025-11-19 21:33:35,673 - INFO - Processed segments: 816
2025-11-19 21:33:35,673 - INFO - Average rate: 3.7 segments/second
2025-11-19 21:33:35,673 - INFO - ============================================================
✅ Fold 8 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 9/9
============================================================
2025-11-19 21:33:35,739 - INFO - ============================================================
2025-11-19 21:33:35,739 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 21:33:35,739 - INFO - ============================================================
2025-11-19 21:33:35,739 - INFO - Output prefix: chb06_fold9
2025-11-19 21:33:35,739 - INFO - EEG Preprocessor initialized
2025-11-19 21:33:35,739 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 21:33:35,740 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 21:33:35,740 - INFO - Segment duration: 5 seconds
2025-11-19 21:33:35,740 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 21:33:35,740 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 21:33:35,740 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 21:33:35,740 - INFO - Loading segments from chb06_fold9_sequences_prediction.json
2025-11-19 21:33:35,761 - INFO - Loaded 816 total sequences
2025-11-19 21:33:35,761 - INFO - Channel validation (from segmentation): 17/18 files valid
2025-11-19 21:33:35,761 - INFO - Files skipped due to missing channels: 1
2025-11-19 21:33:35,761 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 21:33:35,761 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 21:33:35,761 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 21:33:35,761 - INFO - train: 324 sequences (162 preictal, 162 interictal)
2025-11-19 21:33:35,761 - INFO - test: 492 sequences (0 preictal, 492 interictal)
2025-11-19 21:33:35,802 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 21:33:35,803 - INFO - train: kept 162 preictal and 162 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 21:33:35,803 - WARNING - test: Skipped balancing due to missing class
2025-11-19 21:33:35,845 - INFO - ============================================================
2025-11-19 21:33:35,845 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 21:33:35,845 - INFO - ============================================================
2025-11-19 21:33:35,845 - INFO - Processing 324 training samples to compute normalization stats...
2025-11-19 21:33:35,845 - INFO - Processing 324 sequences from 17 unique files
Processing training data:   0%|                    | 0/324 [00:00<?, ?it/s]Processing training data:   0%|            | 1/324 [00:05<30:38,  5.69s/it]Processing training data:   8%|8          | 25/324 [00:10<01:40,  2.96it/s]Processing training data:  12%|#3         | 40/324 [00:16<01:47,  2.63it/s]Processing training data:  18%|##         | 59/324 [00:22<01:32,  2.87it/s]Processing training data:  24%|##6        | 79/324 [00:28<01:22,  2.97it/s]Processing training data:  30%|###2       | 97/324 [00:35<01:20,  2.82it/s]Processing training data:  35%|###4      | 113/324 [00:39<01:07,  3.14it/s]Processing training data:  43%|####2     | 138/324 [00:40<00:38,  4.81it/s]Processing training data:  49%|####9     | 160/324 [00:41<00:25,  6.47it/s]Processing training data:  56%|#####5    | 180/324 [00:48<00:29,  4.81it/s]Processing training data:  74%|#######4  | 241/324 [00:55<00:13,  6.28it/s]Processing training data:  77%|#######7  | 251/324 [01:02<00:15,  4.66it/s]Processing training data:  81%|########1 | 263/324 [01:09<00:17,  3.57it/s]Processing training data:  85%|########5 | 276/324 [01:15<00:15,  3.06it/s]Processing training data:  92%|#########1| 298/324 [01:20<00:07,  3.54it/s]Processing training data:  94%|#########4| 306/324 [01:27<00:06,  2.62it/s]Processing training data:  99%|#########9| 322/324 [01:29<00:00,  3.39it/s]Processing training data: 100%|##########| 324/324 [01:29<00:00,  3.63it/s]
2025-11-19 21:35:05,138 - INFO - Computing normalization statistics from training data...
2025-11-19 21:35:05,647 - INFO - Normalization stats computed:
2025-11-19 21:35:05,648 - INFO -   Mean: 1.252037
2025-11-19 21:35:05,648 - INFO -   Std: 2.501487
2025-11-19 21:35:05,648 - INFO -   Saved to: preprocessing\checkpoints\chb06_fold9\normalization_stats.json
2025-11-19 21:35:05,731 - INFO - Applying normalization and saving 324 training sequences...
Normalizing and saving training data:   0%|        | 0/324 [00:00<?, ?it/s]2025-11-19 21:35:05,740 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold9\train_dataset.h5
Normalizing and saving training data:   3%| | 10/324 [00:00<00:21, 14.55it/Normalizing and saving training data:   6%| | 20/324 [00:01<00:20, 14.79it/Normalizing and saving training data:   9%| | 30/324 [00:02<00:19, 14.88it/Normalizing and saving training data:  12%|1| 40/324 [00:02<00:18, 14.96it/Normalizing and saving training data:  15%|1| 50/324 [00:03<00:18, 15.00it/Normalizing and saving training data:  19%|1| 60/324 [00:04<00:17, 15.00it/Normalizing and saving training data:  22%|2| 70/324 [00:04<00:16, 14.97it/Normalizing and saving training data:  25%|2| 80/324 [00:05<00:16, 15.04it/Normalizing and saving training data:  28%|2| 90/324 [00:06<00:15, 15.05it/Normalizing and saving training data:  31%|3| 100/324 [00:06<00:14, 14.98itNormalizing and saving training data:  34%|3| 110/324 [00:07<00:14, 15.00itNormalizing and saving training data:  37%|3| 120/324 [00:08<00:13, 14.94itNormalizing and saving training data:  40%|4| 130/324 [00:08<00:13, 14.91itNormalizing and saving training data:  43%|4| 140/324 [00:09<00:12, 14.92itNormalizing and saving training data:  46%|4| 150/324 [00:10<00:11, 14.91itNormalizing and saving training data:  49%|4| 160/324 [00:10<00:11, 14.89itNormalizing and saving training data:  52%|5| 170/324 [00:11<00:10, 14.77itNormalizing and saving training data:  56%|5| 180/324 [00:12<00:09, 14.85itNormalizing and saving training data:  59%|5| 190/324 [00:12<00:09, 14.88itNormalizing and saving training data:  62%|6| 200/324 [00:13<00:08, 14.90itNormalizing and saving training data:  65%|6| 210/324 [00:14<00:07, 14.94itNormalizing and saving training data:  68%|6| 220/324 [00:14<00:06, 14.90itNormalizing and saving training data:  71%|7| 230/324 [00:15<00:06, 14.91itNormalizing and saving training data:  74%|7| 240/324 [00:16<00:05, 14.85itNormalizing and saving training data:  77%|7| 250/324 [00:16<00:04, 14.91itNormalizing and saving training data:  80%|8| 260/324 [00:17<00:04, 14.87itNormalizing and saving training data:  83%|8| 270/324 [00:18<00:03, 14.86itNormalizing and saving training data:  86%|8| 280/324 [00:18<00:02, 14.88itNormalizing and saving training data:  90%|8| 290/324 [00:19<00:02, 14.89itNormalizing and saving training data:  93%|9| 300/324 [00:20<00:01, 14.90itNormalizing and saving training data:  96%|9| 310/324 [00:20<00:00, 14.62itNormalizing and saving training data:  99%|9| 320/324 [00:21<00:00, 14.60itNormalizing and saving training data: 100%|#| 324/324 [00:21<00:00, 15.05it
2025-11-19 21:35:27,600 - INFO - Training data processing completed during stats computation phase
2025-11-19 21:35:27,610 - INFO - Loaded normalization statistics:
2025-11-19 21:35:27,610 - INFO -   Mean: 1.252037
2025-11-19 21:35:27,610 - INFO -   Std: 2.501487
2025-11-19 21:35:27,610 - INFO - Split train already completed, skipping
2025-11-19 21:35:27,610 - INFO - Processing test split...
2025-11-19 21:35:27,611 - INFO - Need to process 492/492 sequences for test
2025-11-19 21:35:27,611 - INFO - Processing 492 sequences from 13 unique files
2025-11-19 21:35:27,611 - INFO - Average 37.8 sequences per file
Processing test:   0%|                             | 0/492 [00:00<?, ?it/s]Processing test:   0%|                   | 1/492 [00:08<1:06:14,  8.10s/it]2025-11-19 21:35:35,708 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb06_fold9\test_dataset.h5
2025-11-19 21:35:38,541 - INFO - Progress: 369/816 (45.2%) - ETA: 2.5 minutes
Processing test:   9%|#8                  | 46/492 [00:18<02:39,  2.80it/s]2025-11-19 21:35:50,044 - INFO - Progress: 428/816 (52.5%) - ETA: 2.0 minutes
Processing test:  21%|####               | 105/492 [00:25<01:16,  5.03it/s]2025-11-19 21:35:54,240 - INFO - Progress: 447/816 (54.8%) - ETA: 1.9 minutes
Processing test:  25%|####7              | 124/492 [00:34<01:35,  3.85it/s]2025-11-19 21:36:04,441 - INFO - Progress: 488/816 (59.8%) - ETA: 1.7 minutes
Processing test:  34%|######3            | 165/492 [00:42<01:17,  4.21it/s]2025-11-19 21:36:12,428 - INFO - Progress: 522/816 (64.0%) - ETA: 1.5 minutes
Processing test:  40%|#######6           | 199/492 [00:52<01:15,  3.90it/s]2025-11-19 21:36:23,116 - INFO - Progress: 567/816 (69.5%) - ETA: 1.2 minutes
Processing test:  50%|#########4         | 244/492 [01:03<01:01,  4.04it/s]2025-11-19 21:36:33,856 - INFO - Progress: 616/816 (75.5%) - ETA: 1.0 minutes
Processing test:  60%|###########3       | 293/492 [01:13<00:47,  4.21it/s]2025-11-19 21:36:44,560 - INFO - Progress: 660/816 (80.9%) - ETA: 0.7 minutes
Processing test:  68%|#############      | 337/492 [01:24<00:37,  4.19it/s]2025-11-19 21:36:55,058 - INFO - Progress: 705/816 (86.4%) - ETA: 0.5 minutes
Processing test:  78%|##############7    | 382/492 [01:35<00:26,  4.20it/s]2025-11-19 21:37:06,103 - INFO - Progress: 756/816 (92.6%) - ETA: 0.3 minutes
Processing test:  88%|################7  | 433/492 [01:39<00:11,  5.33it/s]Processing test:  90%|#################  | 442/492 [01:44<00:10,  4.74it/s]2025-11-19 21:37:14,213 - INFO - Progress: 794/816 (97.3%) - ETA: 0.1 minutes
Processing test:  96%|##################1| 471/492 [01:50<00:04,  4.69it/s]2025-11-19 21:37:19,613 - INFO - Progress: 816/816 (100.0%) - ETA: 0.0 minutes
Processing test: 100%|###################| 492/492 [01:52<00:00,  4.39it/s]
2025-11-19 21:37:19,655 - INFO - Validating final datasets...
2025-11-19 21:37:19,663 - INFO - train dataset validation:
2025-11-19 21:37:19,663 - INFO -   - Segments: 324
2025-11-19 21:37:19,663 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:37:19,663 - INFO -   - Classes: 162 preictal, 162 interictal
2025-11-19 21:37:19,664 - INFO -   - Balance: 50.0% preictal
2025-11-19 21:37:19,669 - INFO - test dataset validation:
2025-11-19 21:37:19,669 - INFO -   - Segments: 492
2025-11-19 21:37:19,669 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 21:37:19,669 - INFO -   - Classes: 0 preictal, 492 interictal
2025-11-19 21:37:19,670 - INFO -   - Balance: 0.0% preictal
2025-11-19 21:37:19,670 - INFO - ============================================================
2025-11-19 21:37:19,670 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 21:37:19,670 - INFO - Total time: 3.7 minutes
2025-11-19 21:37:19,670 - INFO - Processed segments: 816
2025-11-19 21:37:19,670 - INFO - Average rate: 3.6 segments/second
2025-11-19 21:37:19,670 - INFO - ============================================================
✅ Fold 9 preprocessing completed successfully!

============================================================
✅ BATCH PREPROCESSING COMPLETED!
✅ Processed 10 folds for patient chb06
============================================================
============================================================
BATCH PROCESSING: ALL FOLDS
Processing 10 folds for patient chb06
============================================================

============================================================
TRAINING FOLD 0/9
============================================================
Using dataset prefix: chb06_fold0
Loading datasets from: preprocessing\data\chb06_fold0
Saving models to: model\chb06_fold0
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=1.2450, std=2.5361
Loaded train dataset: 282 samples
  - Spectrogram shape: torch.Size([282, 30, 18, 50, 10])
  - Value range: [-5.2226, 3.2138]
  - Class distribution: tensor([141, 141])
LOOCV Mode (Fold 0): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6851, grad_norm=1.Training Epoch 1/5:   6%| | 1/18 [00:04<01:11,  4.23s/it, loss=0.6851, gradTraining Epoch 1/5:   6%| | 1/18 [00:04<01:11,  4.23s/it, loss=0.6928, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:29,  1.82s/it, loss=0.6928, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:29,  1.82s/it, loss=0.6810, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.04s/it, loss=0.6810, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.04s/it, loss=0.6959, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.48it/s, loss=0.6959, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.48it/s, loss=0.6781, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:06,  2.09it/s, loss=0.6781, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:06,  2.09it/s, loss=0.7051, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.74it/s, loss=0.7051, gradTraining Epoch 1/5:  33%|3| 6/18 [00:05<00:04,  2.74it/s, loss=0.6854, gradTraining Epoch 1/5:  39%|3| 7/18 [00:05<00:03,  3.47it/s, loss=0.6854, gradTraining Epoch 1/5:  39%|3| 7/18 [00:05<00:03,  3.47it/s, loss=0.6875, gradTraining Epoch 1/5:  44%|4| 8/18 [00:05<00:02,  4.20it/s, loss=0.6875, gradTraining Epoch 1/5:  44%|4| 8/18 [00:05<00:02,  4.20it/s, loss=0.6847, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  4.77it/s, loss=0.6847, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  4.77it/s, loss=0.7022, gradTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  5.55it/s, loss=0.7022, graTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  5.55it/s, loss=0.6702, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  6.24it/s, loss=0.6702, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  6.24it/s, loss=0.6836, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:00,  6.43it/s, loss=0.6836, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:00,  6.43it/s, loss=0.6716, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  6.90it/s, loss=0.6716, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  6.90it/s, loss=0.6683, graTraining Epoch 1/5:  78%|7| 14/18 [00:05<00:00,  7.35it/s, loss=0.6683, graTraining Epoch 1/5:  78%|7| 14/18 [00:06<00:00,  7.35it/s, loss=0.6805, graTraining Epoch 1/5:  83%|8| 15/18 [00:06<00:00,  7.68it/s, loss=0.6805, graTraining Epoch 1/5:  83%|8| 15/18 [00:06<00:00,  7.68it/s, loss=0.6707, graTraining Epoch 1/5:  89%|8| 16/18 [00:06<00:00,  7.95it/s, loss=0.6707, graTraining Epoch 1/5:  89%|8| 16/18 [00:06<00:00,  7.95it/s, loss=0.6646, graTraining Epoch 1/5:  94%|9| 17/18 [00:06<00:00,  7.99it/s, loss=0.6646, graTraining Epoch 1/5:  94%|9| 17/18 [00:06<00:00,  7.99it/s, loss=0.6565, graTraining Epoch 1/5: 100%|#| 18/18 [00:06<00:00,  8.17it/s, loss=0.6565, graTraining Epoch 1/5: 100%|#| 18/18 [00:06<00:00,  2.59it/s, loss=0.6565, gra

Epoch 1/5 Complete (7.4s) [LR: 0.000010]
Train - Loss: 0.6813, Acc: 0.6277, Precision: 0.6169, Recall: 0.6738, F1: 0.6441, AUC: 0.6508
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/18 [00:03<?, ?it/s, loss=0.6440, grad_norm=1.Training Epoch 2/5:   6%| | 1/18 [00:03<01:07,  3.95s/it, loss=0.6440, gradTraining Epoch 2/5:   6%| | 1/18 [00:04<01:07,  3.95s/it, loss=0.6586, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:27,  1.70s/it, loss=0.6586, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:27,  1.70s/it, loss=0.6358, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:14,  1.03it/s, loss=0.6358, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:14,  1.03it/s, loss=0.6437, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:08,  1.56it/s, loss=0.6437, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:08,  1.56it/s, loss=0.6452, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.6452, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.7253, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.93it/s, loss=0.7253, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.93it/s, loss=0.6441, gradTraining Epoch 2/5:  39%|3| 7/18 [00:04<00:02,  3.71it/s, loss=0.6441, gradTraining Epoch 2/5:  39%|3| 7/18 [00:04<00:02,  3.71it/s, loss=0.6099, gradTraining Epoch 2/5:  44%|4| 8/18 [00:04<00:02,  4.39it/s, loss=0.6099, gradTraining Epoch 2/5:  44%|4| 8/18 [00:04<00:02,  4.39it/s, loss=0.6399, gradTraining Epoch 2/5:  50%|5| 9/18 [00:04<00:01,  5.19it/s, loss=0.6399, gradTraining Epoch 2/5:  50%|5| 9/18 [00:05<00:01,  5.19it/s, loss=0.6044, gradTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  5.85it/s, loss=0.6044, graTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  5.85it/s, loss=0.6480, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.41it/s, loss=0.6480, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.41it/s, loss=0.5833, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  6.94it/s, loss=0.5833, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  6.94it/s, loss=0.6235, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  7.35it/s, loss=0.6235, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  7.35it/s, loss=0.6115, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  7.38it/s, loss=0.6115, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  7.38it/s, loss=0.6861, graTraining Epoch 2/5:  83%|8| 15/18 [00:05<00:00,  7.30it/s, loss=0.6861, graTraining Epoch 2/5:  83%|8| 15/18 [00:05<00:00,  7.30it/s, loss=0.6590, graTraining Epoch 2/5:  89%|8| 16/18 [00:05<00:00,  7.38it/s, loss=0.6590, graTraining Epoch 2/5:  89%|8| 16/18 [00:05<00:00,  7.38it/s, loss=0.5676, graTraining Epoch 2/5:  94%|9| 17/18 [00:05<00:00,  7.73it/s, loss=0.5676, graTraining Epoch 2/5:  94%|9| 17/18 [00:06<00:00,  7.73it/s, loss=0.5717, graTraining Epoch 2/5: 100%|#| 18/18 [00:06<00:00,  2.70it/s, loss=0.5717, gra

Epoch 2/5 Complete (7.1s) [LR: 0.000010]
Train - Loss: 0.6334, Acc: 0.7199, Precision: 0.6802, Recall: 0.8298, F1: 0.7476, AUC: 0.7885
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.5524, grad_norm=1.Training Epoch 3/5:   6%| | 1/18 [00:04<01:12,  4.27s/it, loss=0.5524, gradTraining Epoch 3/5:   6%| | 1/18 [00:04<01:12,  4.27s/it, loss=0.5453, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:29,  1.83s/it, loss=0.5453, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:29,  1.83s/it, loss=0.5552, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:15,  1.05s/it, loss=0.5552, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:15,  1.05s/it, loss=0.6230, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:09,  1.44it/s, loss=0.6230, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:09,  1.44it/s, loss=0.5987, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:06,  2.03it/s, loss=0.5987, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:06,  2.03it/s, loss=0.5410, gradTraining Epoch 3/5:  33%|3| 6/18 [00:04<00:04,  2.69it/s, loss=0.5410, gradTraining Epoch 3/5:  33%|3| 6/18 [00:05<00:04,  2.69it/s, loss=0.5530, gradTraining Epoch 3/5:  39%|3| 7/18 [00:05<00:03,  3.44it/s, loss=0.5530, gradTraining Epoch 3/5:  39%|3| 7/18 [00:05<00:03,  3.44it/s, loss=0.6602, gradTraining Epoch 3/5:  44%|4| 8/18 [00:05<00:02,  4.04it/s, loss=0.6602, gradTraining Epoch 3/5:  44%|4| 8/18 [00:05<00:02,  4.04it/s, loss=0.6276, gradTraining Epoch 3/5:  50%|5| 9/18 [00:05<00:01,  4.58it/s, loss=0.6276, gradTraining Epoch 3/5:  50%|5| 9/18 [00:05<00:01,  4.58it/s, loss=0.5940, gradTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  4.99it/s, loss=0.5940, graTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  4.99it/s, loss=0.5157, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  5.39it/s, loss=0.5157, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  5.39it/s, loss=0.5760, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:01,  5.77it/s, loss=0.5760, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:01,  5.77it/s, loss=0.4881, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  6.03it/s, loss=0.4881, graTraining Epoch 3/5:  72%|7| 13/18 [00:06<00:00,  6.03it/s, loss=0.5464, graTraining Epoch 3/5:  78%|7| 14/18 [00:06<00:00,  6.31it/s, loss=0.5464, graTraining Epoch 3/5:  78%|7| 14/18 [00:06<00:00,  6.31it/s, loss=0.6499, graTraining Epoch 3/5:  83%|8| 15/18 [00:06<00:00,  6.70it/s, loss=0.6499, graTraining Epoch 3/5:  83%|8| 15/18 [00:06<00:00,  6.70it/s, loss=0.6823, graTraining Epoch 3/5:  89%|8| 16/18 [00:06<00:00,  6.79it/s, loss=0.6823, graTraining Epoch 3/5:  89%|8| 16/18 [00:06<00:00,  6.79it/s, loss=0.5255, graTraining Epoch 3/5:  94%|9| 17/18 [00:06<00:00,  6.96it/s, loss=0.5255, graTraining Epoch 3/5:  94%|9| 17/18 [00:06<00:00,  6.96it/s, loss=0.5394, graTraining Epoch 3/5: 100%|#| 18/18 [00:07<00:00,  2.50it/s, loss=0.5394, gra

Epoch 3/5 Complete (7.6s) [LR: 0.000010]
Train - Loss: 0.5763, Acc: 0.7270, Precision: 0.6720, Recall: 0.8865, F1: 0.7645, AUC: 0.7822
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.4900, grad_norm=1.Training Epoch 4/5:   6%| | 1/18 [00:04<01:12,  4.28s/it, loss=0.4900, gradTraining Epoch 4/5:   6%| | 1/18 [00:04<01:12,  4.28s/it, loss=0.5917, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:29,  1.83s/it, loss=0.5917, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:29,  1.83s/it, loss=0.5427, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:15,  1.05s/it, loss=0.5427, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:15,  1.05s/it, loss=0.4985, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.47it/s, loss=0.4985, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.47it/s, loss=0.6409, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:06,  2.10it/s, loss=0.6409, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:06,  2.10it/s, loss=0.4947, gradTraining Epoch 4/5:  33%|3| 6/18 [00:04<00:04,  2.84it/s, loss=0.4947, gradTraining Epoch 4/5:  33%|3| 6/18 [00:04<00:04,  2.84it/s, loss=0.4523, gradTraining Epoch 4/5:  39%|3| 7/18 [00:04<00:03,  3.63it/s, loss=0.4523, gradTraining Epoch 4/5:  39%|3| 7/18 [00:05<00:03,  3.63it/s, loss=0.5037, gradTraining Epoch 4/5:  44%|4| 8/18 [00:05<00:02,  4.37it/s, loss=0.5037, gradTraining Epoch 4/5:  44%|4| 8/18 [00:05<00:02,  4.37it/s, loss=0.5228, gradTraining Epoch 4/5:  50%|5| 9/18 [00:05<00:01,  5.12it/s, loss=0.5228, gradTraining Epoch 4/5:  50%|5| 9/18 [00:05<00:01,  5.12it/s, loss=0.4399, gradTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  5.91it/s, loss=0.4399, graTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  5.91it/s, loss=0.5547, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.21it/s, loss=0.5547, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.21it/s, loss=0.4482, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  6.84it/s, loss=0.4482, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  6.84it/s, loss=0.5618, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  7.27it/s, loss=0.5618, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  7.27it/s, loss=0.5174, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  7.17it/s, loss=0.5174, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  7.17it/s, loss=0.5291, graTraining Epoch 4/5:  83%|8| 15/18 [00:05<00:00,  7.41it/s, loss=0.5291, graTraining Epoch 4/5:  83%|8| 15/18 [00:06<00:00,  7.41it/s, loss=0.3974, graTraining Epoch 4/5:  89%|8| 16/18 [00:06<00:00,  7.81it/s, loss=0.3974, graTraining Epoch 4/5:  89%|8| 16/18 [00:06<00:00,  7.81it/s, loss=0.5611, graTraining Epoch 4/5:  94%|9| 17/18 [00:06<00:00,  8.11it/s, loss=0.5611, graTraining Epoch 4/5:  94%|9| 17/18 [00:06<00:00,  8.11it/s, loss=0.4515, graTraining Epoch 4/5: 100%|#| 18/18 [00:06<00:00,  2.61it/s, loss=0.4515, gra

Epoch 4/5 Complete (7.3s) [LR: 0.000010]
Train - Loss: 0.5110, Acc: 0.7660, Precision: 0.7027, Recall: 0.9220, F1: 0.7975, AUC: 0.8145
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.4561, grad_norm=1.Training Epoch 5/5:   6%| | 1/18 [00:04<01:08,  4.01s/it, loss=0.4561, gradTraining Epoch 5/5:   6%| | 1/18 [00:04<01:08,  4.01s/it, loss=0.4334, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:27,  1.73s/it, loss=0.4334, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:27,  1.73s/it, loss=0.4340, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:14,  1.01it/s, loss=0.4340, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:14,  1.01it/s, loss=0.5075, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:09,  1.54it/s, loss=0.5075, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:09,  1.54it/s, loss=0.3972, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.3972, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.5686, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.92it/s, loss=0.5686, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.92it/s, loss=0.4494, gradTraining Epoch 5/5:  39%|3| 7/18 [00:04<00:02,  3.71it/s, loss=0.4494, gradTraining Epoch 5/5:  39%|3| 7/18 [00:04<00:02,  3.71it/s, loss=0.4059, gradTraining Epoch 5/5:  44%|4| 8/18 [00:04<00:02,  4.56it/s, loss=0.4059, gradTraining Epoch 5/5:  44%|4| 8/18 [00:04<00:02,  4.56it/s, loss=0.5272, gradTraining Epoch 5/5:  50%|5| 9/18 [00:04<00:01,  5.37it/s, loss=0.5272, gradTraining Epoch 5/5:  50%|5| 9/18 [00:05<00:01,  5.37it/s, loss=0.3915, gradTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  6.14it/s, loss=0.3915, graTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  6.14it/s, loss=0.4729, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  6.77it/s, loss=0.4729, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  6.77it/s, loss=0.3837, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  6.87it/s, loss=0.3837, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  6.87it/s, loss=0.4037, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  6.97it/s, loss=0.4037, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  6.97it/s, loss=0.5051, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  7.35it/s, loss=0.5051, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  7.35it/s, loss=0.4304, graTraining Epoch 5/5:  83%|8| 15/18 [00:05<00:00,  7.72it/s, loss=0.4304, graTraining Epoch 5/5:  83%|8| 15/18 [00:05<00:00,  7.72it/s, loss=0.5304, graTraining Epoch 5/5:  89%|8| 16/18 [00:05<00:00,  7.97it/s, loss=0.5304, graTraining Epoch 5/5:  89%|8| 16/18 [00:05<00:00,  7.97it/s, loss=0.4887, graTraining Epoch 5/5:  94%|9| 17/18 [00:05<00:00,  8.08it/s, loss=0.4887, graTraining Epoch 5/5:  94%|9| 17/18 [00:06<00:00,  8.08it/s, loss=0.4772, graTraining Epoch 5/5: 100%|#| 18/18 [00:06<00:00,  2.65it/s, loss=0.4772, gra

Epoch 5/5 Complete (7.2s) [LR: 0.000005]
Train - Loss: 0.4591, Acc: 0.7943, Precision: 0.7345, Recall: 0.9220, F1: 0.8176, AUC: 0.8725
------------------------------------------------------------
Training curves saved to model\chb06_fold0\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.6 minutes
Models saved in: model\chb06_fold0
============================================================
✅ Fold 0 training completed successfully!

============================================================
TRAINING FOLD 1/9
============================================================
Using dataset prefix: chb06_fold1
Loading datasets from: preprocessing\data\chb06_fold1
Saving models to: model\chb06_fold1
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=1.2614, std=2.5059
Loaded train dataset: 284 samples
  - Spectrogram shape: torch.Size([284, 30, 18, 50, 10])
  - Value range: [-5.2922, 3.2503]
  - Class distribution: tensor([142, 142])
LOOCV Mode (Fold 1): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6893, grad_norm=1.Training Epoch 1/5:   6%| | 1/18 [00:04<01:10,  4.14s/it, loss=0.6893, gradTraining Epoch 1/5:   6%| | 1/18 [00:04<01:10,  4.14s/it, loss=0.6908, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:28,  1.78s/it, loss=0.6908, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:28,  1.78s/it, loss=0.7028, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.02s/it, loss=0.7028, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.02s/it, loss=0.6947, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.51it/s, loss=0.6947, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.51it/s, loss=0.6848, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:06,  2.15it/s, loss=0.6848, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:06,  2.15it/s, loss=0.6886, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.90it/s, loss=0.6886, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.90it/s, loss=0.6831, gradTraining Epoch 1/5:  39%|3| 7/18 [00:04<00:02,  3.71it/s, loss=0.6831, gradTraining Epoch 1/5:  39%|3| 7/18 [00:04<00:02,  3.71it/s, loss=0.6826, gradTraining Epoch 1/5:  44%|4| 8/18 [00:04<00:02,  4.57it/s, loss=0.6826, gradTraining Epoch 1/5:  44%|4| 8/18 [00:05<00:02,  4.57it/s, loss=0.6782, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  5.32it/s, loss=0.6782, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  5.32it/s, loss=0.6877, gradTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  6.04it/s, loss=0.6877, graTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  6.04it/s, loss=0.6798, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  6.68it/s, loss=0.6798, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  6.68it/s, loss=0.6757, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:00,  7.16it/s, loss=0.6757, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:00,  7.16it/s, loss=0.6772, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  7.59it/s, loss=0.6772, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  7.59it/s, loss=0.6915, graTraining Epoch 1/5:  78%|7| 14/18 [00:05<00:00,  7.95it/s, loss=0.6915, graTraining Epoch 1/5:  78%|7| 14/18 [00:05<00:00,  7.95it/s, loss=0.6699, graTraining Epoch 1/5:  83%|8| 15/18 [00:05<00:00,  8.05it/s, loss=0.6699, graTraining Epoch 1/5:  83%|8| 15/18 [00:05<00:00,  8.05it/s, loss=0.6512, graTraining Epoch 1/5:  89%|8| 16/18 [00:05<00:00,  8.26it/s, loss=0.6512, graTraining Epoch 1/5:  89%|8| 16/18 [00:05<00:00,  8.26it/s, loss=0.6488, graTraining Epoch 1/5:  94%|9| 17/18 [00:05<00:00,  8.47it/s, loss=0.6488, graTraining Epoch 1/5:  94%|9| 17/18 [00:06<00:00,  8.47it/s, loss=0.6735, graTraining Epoch 1/5: 100%|#| 18/18 [00:06<00:00,  8.74it/s, loss=0.6735, graTraining Epoch 1/5: 100%|#| 18/18 [00:06<00:00,  2.69it/s, loss=0.6735, gra

Epoch 1/5 Complete (7.1s) [LR: 0.000010]
Train - Loss: 0.6806, Acc: 0.5810, Precision: 0.5920, Recall: 0.5211, F1: 0.5543, AUC: 0.6582
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6650, grad_norm=1.Training Epoch 2/5:   6%| | 1/18 [00:04<01:11,  4.19s/it, loss=0.6650, gradTraining Epoch 2/5:   6%| | 1/18 [00:04<01:11,  4.19s/it, loss=0.6859, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:28,  1.80s/it, loss=0.6859, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:28,  1.80s/it, loss=0.6403, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:15,  1.03s/it, loss=0.6403, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:15,  1.03s/it, loss=0.6684, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:09,  1.49it/s, loss=0.6684, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:09,  1.49it/s, loss=0.6398, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:06,  2.11it/s, loss=0.6398, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:06,  2.11it/s, loss=0.7021, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.84it/s, loss=0.7021, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.84it/s, loss=0.6354, gradTraining Epoch 2/5:  39%|3| 7/18 [00:04<00:03,  3.62it/s, loss=0.6354, gradTraining Epoch 2/5:  39%|3| 7/18 [00:05<00:03,  3.62it/s, loss=0.6020, gradTraining Epoch 2/5:  44%|4| 8/18 [00:05<00:02,  4.47it/s, loss=0.6020, gradTraining Epoch 2/5:  44%|4| 8/18 [00:05<00:02,  4.47it/s, loss=0.6158, gradTraining Epoch 2/5:  50%|5| 9/18 [00:05<00:01,  5.22it/s, loss=0.6158, gradTraining Epoch 2/5:  50%|5| 9/18 [00:05<00:01,  5.22it/s, loss=0.6117, gradTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  5.78it/s, loss=0.6117, graTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  5.78it/s, loss=0.6733, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.33it/s, loss=0.6733, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.33it/s, loss=0.6652, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  6.85it/s, loss=0.6652, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  6.85it/s, loss=0.6494, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  7.24it/s, loss=0.6494, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  7.24it/s, loss=0.5615, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  7.49it/s, loss=0.5615, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  7.49it/s, loss=0.6616, graTraining Epoch 2/5:  83%|8| 15/18 [00:05<00:00,  7.71it/s, loss=0.6616, graTraining Epoch 2/5:  83%|8| 15/18 [00:06<00:00,  7.71it/s, loss=0.6447, graTraining Epoch 2/5:  89%|8| 16/18 [00:06<00:00,  7.85it/s, loss=0.6447, graTraining Epoch 2/5:  89%|8| 16/18 [00:06<00:00,  7.85it/s, loss=0.5762, graTraining Epoch 2/5:  94%|9| 17/18 [00:06<00:00,  7.92it/s, loss=0.5762, graTraining Epoch 2/5:  94%|9| 17/18 [00:06<00:00,  7.92it/s, loss=0.6212, graTraining Epoch 2/5: 100%|#| 18/18 [00:06<00:00,  2.57it/s, loss=0.6212, gra

Epoch 2/5 Complete (7.4s) [LR: 0.000010]
Train - Loss: 0.6400, Acc: 0.6761, Precision: 0.6289, Recall: 0.8592, F1: 0.7262, AUC: 0.7373
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6154, grad_norm=0.Training Epoch 3/5:   6%| | 1/18 [00:04<01:14,  4.37s/it, loss=0.6154, gradTraining Epoch 3/5:   6%| | 1/18 [00:04<01:14,  4.37s/it, loss=0.6225, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:29,  1.87s/it, loss=0.6225, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:29,  1.87s/it, loss=0.6290, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:16,  1.08s/it, loss=0.6290, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:16,  1.08s/it, loss=0.6189, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:09,  1.41it/s, loss=0.6189, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:09,  1.41it/s, loss=0.6733, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:06,  2.00it/s, loss=0.6733, gradTraining Epoch 3/5:  28%|2| 5/18 [00:05<00:06,  2.00it/s, loss=0.6771, gradTraining Epoch 3/5:  33%|3| 6/18 [00:05<00:04,  2.67it/s, loss=0.6771, gradTraining Epoch 3/5:  33%|3| 6/18 [00:05<00:04,  2.67it/s, loss=0.5672, gradTraining Epoch 3/5:  39%|3| 7/18 [00:05<00:03,  3.46it/s, loss=0.5672, gradTraining Epoch 3/5:  39%|3| 7/18 [00:05<00:03,  3.46it/s, loss=0.7449, gradTraining Epoch 3/5:  44%|4| 8/18 [00:05<00:02,  4.30it/s, loss=0.7449, gradTraining Epoch 3/5:  44%|4| 8/18 [00:05<00:02,  4.30it/s, loss=0.6218, gradTraining Epoch 3/5:  50%|5| 9/18 [00:05<00:01,  5.08it/s, loss=0.6218, gradTraining Epoch 3/5:  50%|5| 9/18 [00:05<00:01,  5.08it/s, loss=0.5074, gradTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  5.80it/s, loss=0.5074, graTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  5.80it/s, loss=0.5564, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  6.43it/s, loss=0.5564, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  6.43it/s, loss=0.5471, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:00,  6.94it/s, loss=0.5471, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:00,  6.94it/s, loss=0.5897, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  7.36it/s, loss=0.5897, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  7.36it/s, loss=0.6180, graTraining Epoch 3/5:  78%|7| 14/18 [00:05<00:00,  7.72it/s, loss=0.6180, graTraining Epoch 3/5:  78%|7| 14/18 [00:06<00:00,  7.72it/s, loss=0.5826, graTraining Epoch 3/5:  83%|8| 15/18 [00:06<00:00,  8.01it/s, loss=0.5826, graTraining Epoch 3/5:  83%|8| 15/18 [00:06<00:00,  8.01it/s, loss=0.5598, graTraining Epoch 3/5:  89%|8| 16/18 [00:06<00:00,  8.14it/s, loss=0.5598, graTraining Epoch 3/5:  89%|8| 16/18 [00:06<00:00,  8.14it/s, loss=0.5758, graTraining Epoch 3/5:  94%|9| 17/18 [00:06<00:00,  8.30it/s, loss=0.5758, graTraining Epoch 3/5:  94%|9| 17/18 [00:06<00:00,  8.30it/s, loss=0.7399, graTraining Epoch 3/5: 100%|#| 18/18 [00:06<00:00,  2.58it/s, loss=0.7399, gra

Epoch 3/5 Complete (7.4s) [LR: 0.000010]
Train - Loss: 0.6137, Acc: 0.6655, Precision: 0.6181, Recall: 0.8662, F1: 0.7214, AUC: 0.7235
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.5754, grad_norm=1.Training Epoch 4/5:   6%| | 1/18 [00:04<01:15,  4.42s/it, loss=0.5754, gradTraining Epoch 4/5:   6%| | 1/18 [00:04<01:15,  4.42s/it, loss=0.5315, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:30,  1.89s/it, loss=0.5315, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:30,  1.89s/it, loss=0.4861, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:16,  1.08s/it, loss=0.4861, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:16,  1.08s/it, loss=0.5067, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.42it/s, loss=0.5067, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.42it/s, loss=0.5635, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:06,  2.04it/s, loss=0.5635, gradTraining Epoch 4/5:  28%|2| 5/18 [00:05<00:06,  2.04it/s, loss=0.4933, gradTraining Epoch 4/5:  33%|3| 6/18 [00:05<00:04,  2.75it/s, loss=0.4933, gradTraining Epoch 4/5:  33%|3| 6/18 [00:05<00:04,  2.75it/s, loss=0.4782, gradTraining Epoch 4/5:  39%|3| 7/18 [00:05<00:03,  3.55it/s, loss=0.4782, gradTraining Epoch 4/5:  39%|3| 7/18 [00:05<00:03,  3.55it/s, loss=0.5374, gradTraining Epoch 4/5:  44%|4| 8/18 [00:05<00:02,  4.38it/s, loss=0.5374, gradTraining Epoch 4/5:  44%|4| 8/18 [00:05<00:02,  4.38it/s, loss=0.5143, gradTraining Epoch 4/5:  50%|5| 9/18 [00:05<00:01,  5.18it/s, loss=0.5143, gradTraining Epoch 4/5:  50%|5| 9/18 [00:05<00:01,  5.18it/s, loss=0.5667, gradTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  5.92it/s, loss=0.5667, graTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  5.92it/s, loss=0.6753, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.57it/s, loss=0.6753, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.57it/s, loss=0.7524, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  7.09it/s, loss=0.7524, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  7.09it/s, loss=0.5593, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  7.55it/s, loss=0.5593, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  7.55it/s, loss=0.4511, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  7.87it/s, loss=0.4511, graTraining Epoch 4/5:  78%|7| 14/18 [00:06<00:00,  7.87it/s, loss=0.6763, graTraining Epoch 4/5:  83%|8| 15/18 [00:06<00:00,  8.15it/s, loss=0.6763, graTraining Epoch 4/5:  83%|8| 15/18 [00:06<00:00,  8.15it/s, loss=0.6469, graTraining Epoch 4/5:  89%|8| 16/18 [00:06<00:00,  8.33it/s, loss=0.6469, graTraining Epoch 4/5:  89%|8| 16/18 [00:06<00:00,  8.33it/s, loss=0.6349, graTraining Epoch 4/5:  94%|9| 17/18 [00:06<00:00,  8.43it/s, loss=0.6349, graTraining Epoch 4/5:  94%|9| 17/18 [00:06<00:00,  8.43it/s, loss=0.6395, graTraining Epoch 4/5: 100%|#| 18/18 [00:06<00:00,  2.58it/s, loss=0.6395, gra

Epoch 4/5 Complete (7.4s) [LR: 0.000010]
Train - Loss: 0.5716, Acc: 0.6866, Precision: 0.6332, Recall: 0.8873, F1: 0.7390, AUC: 0.7720
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.5348, grad_norm=1.Training Epoch 5/5:   6%| | 1/18 [00:04<01:09,  4.09s/it, loss=0.5348, gradTraining Epoch 5/5:   6%| | 1/18 [00:04<01:09,  4.09s/it, loss=0.5241, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:28,  1.77s/it, loss=0.5241, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:28,  1.77s/it, loss=0.6250, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:15,  1.03s/it, loss=0.6250, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:15,  1.03s/it, loss=0.5571, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:09,  1.48it/s, loss=0.5571, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:09,  1.48it/s, loss=0.4503, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:06,  2.06it/s, loss=0.4503, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:06,  2.06it/s, loss=0.4537, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.75it/s, loss=0.4537, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.75it/s, loss=0.4969, gradTraining Epoch 5/5:  39%|3| 7/18 [00:04<00:03,  3.38it/s, loss=0.4969, gradTraining Epoch 5/5:  39%|3| 7/18 [00:05<00:03,  3.38it/s, loss=0.5873, gradTraining Epoch 5/5:  44%|4| 8/18 [00:05<00:02,  4.20it/s, loss=0.5873, gradTraining Epoch 5/5:  44%|4| 8/18 [00:05<00:02,  4.20it/s, loss=0.4789, gradTraining Epoch 5/5:  50%|5| 9/18 [00:05<00:01,  5.00it/s, loss=0.4789, gradTraining Epoch 5/5:  50%|5| 9/18 [00:05<00:01,  5.00it/s, loss=0.8058, gradTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  5.75it/s, loss=0.8058, graTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  5.75it/s, loss=0.5341, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  6.44it/s, loss=0.5341, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  6.44it/s, loss=0.4991, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  6.72it/s, loss=0.4991, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  6.72it/s, loss=0.5091, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  6.88it/s, loss=0.5091, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  6.88it/s, loss=0.6132, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  7.34it/s, loss=0.6132, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  7.34it/s, loss=0.4740, graTraining Epoch 5/5:  83%|8| 15/18 [00:05<00:00,  7.62it/s, loss=0.4740, graTraining Epoch 5/5:  83%|8| 15/18 [00:06<00:00,  7.62it/s, loss=0.4351, graTraining Epoch 5/5:  89%|8| 16/18 [00:06<00:00,  7.29it/s, loss=0.4351, graTraining Epoch 5/5:  89%|8| 16/18 [00:06<00:00,  7.29it/s, loss=0.4808, graTraining Epoch 5/5:  94%|9| 17/18 [00:06<00:00,  7.57it/s, loss=0.4808, graTraining Epoch 5/5:  94%|9| 17/18 [00:06<00:00,  7.57it/s, loss=0.6372, graTraining Epoch 5/5: 100%|#| 18/18 [00:06<00:00,  2.61it/s, loss=0.6372, gra

Epoch 5/5 Complete (7.3s) [LR: 0.000005]
Train - Loss: 0.5387, Acc: 0.7289, Precision: 0.6857, Recall: 0.8451, F1: 0.7571, AUC: 0.8295
------------------------------------------------------------
Training curves saved to model\chb06_fold1\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.6 minutes
Models saved in: model\chb06_fold1
============================================================
✅ Fold 1 training completed successfully!

============================================================
TRAINING FOLD 2/9
============================================================
Using dataset prefix: chb06_fold2
Loading datasets from: preprocessing\data\chb06_fold2
Saving models to: model\chb06_fold2
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=1.2067, std=2.5301
Loaded train dataset: 284 samples
  - Spectrogram shape: torch.Size([284, 30, 18, 50, 10])
  - Value range: [-5.2198, 3.2770]
  - Class distribution: tensor([142, 142])
LOOCV Mode (Fold 2): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.7002, grad_norm=1.Training Epoch 1/5:   6%| | 1/18 [00:04<01:10,  4.13s/it, loss=0.7002, gradTraining Epoch 1/5:   6%| | 1/18 [00:04<01:10,  4.13s/it, loss=0.6819, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:28,  1.79s/it, loss=0.6819, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:28,  1.79s/it, loss=0.6767, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.03s/it, loss=0.6767, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.03s/it, loss=0.6865, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.50it/s, loss=0.6865, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.50it/s, loss=0.6801, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:06,  2.15it/s, loss=0.6801, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:06,  2.15it/s, loss=0.6747, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.88it/s, loss=0.6747, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.88it/s, loss=0.6952, gradTraining Epoch 1/5:  39%|3| 7/18 [00:04<00:03,  3.66it/s, loss=0.6952, gradTraining Epoch 1/5:  39%|3| 7/18 [00:04<00:03,  3.66it/s, loss=0.6805, gradTraining Epoch 1/5:  44%|4| 8/18 [00:04<00:02,  4.44it/s, loss=0.6805, gradTraining Epoch 1/5:  44%|4| 8/18 [00:05<00:02,  4.44it/s, loss=0.6684, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  5.05it/s, loss=0.6684, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  5.05it/s, loss=0.6906, gradTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  5.57it/s, loss=0.6906, graTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  5.57it/s, loss=0.6639, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  6.07it/s, loss=0.6639, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  6.07it/s, loss=0.6708, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:00,  6.33it/s, loss=0.6708, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:00,  6.33it/s, loss=0.6787, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  6.75it/s, loss=0.6787, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  6.75it/s, loss=0.6671, graTraining Epoch 1/5:  78%|7| 14/18 [00:05<00:00,  7.27it/s, loss=0.6671, graTraining Epoch 1/5:  78%|7| 14/18 [00:05<00:00,  7.27it/s, loss=0.6895, graTraining Epoch 1/5:  83%|8| 15/18 [00:05<00:00,  7.62it/s, loss=0.6895, graTraining Epoch 1/5:  83%|8| 15/18 [00:06<00:00,  7.62it/s, loss=0.6529, graTraining Epoch 1/5:  89%|8| 16/18 [00:06<00:00,  7.29it/s, loss=0.6529, graTraining Epoch 1/5:  89%|8| 16/18 [00:06<00:00,  7.29it/s, loss=0.6692, graTraining Epoch 1/5:  94%|9| 17/18 [00:06<00:00,  7.55it/s, loss=0.6692, graTraining Epoch 1/5:  94%|9| 17/18 [00:06<00:00,  7.55it/s, loss=0.7158, graTraining Epoch 1/5: 100%|#| 18/18 [00:06<00:00,  7.84it/s, loss=0.7158, graTraining Epoch 1/5: 100%|#| 18/18 [00:06<00:00,  2.62it/s, loss=0.7158, gra

Epoch 1/5 Complete (7.3s) [LR: 0.000010]
Train - Loss: 0.6801, Acc: 0.5317, Precision: 0.7143, Recall: 0.1056, F1: 0.1840, AUC: 0.6707
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/18 [00:03<?, ?it/s, loss=0.6470, grad_norm=1.Training Epoch 2/5:   6%| | 1/18 [00:03<01:07,  4.00s/it, loss=0.6470, gradTraining Epoch 2/5:   6%| | 1/18 [00:04<01:07,  4.00s/it, loss=0.6497, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:27,  1.72s/it, loss=0.6497, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:27,  1.72s/it, loss=0.6908, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:14,  1.02it/s, loss=0.6908, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:14,  1.02it/s, loss=0.6351, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:08,  1.56it/s, loss=0.6351, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:08,  1.56it/s, loss=0.6457, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:05,  2.21it/s, loss=0.6457, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:05,  2.21it/s, loss=0.6435, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.96it/s, loss=0.6435, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.96it/s, loss=0.6556, gradTraining Epoch 2/5:  39%|3| 7/18 [00:04<00:02,  3.78it/s, loss=0.6556, gradTraining Epoch 2/5:  39%|3| 7/18 [00:04<00:02,  3.78it/s, loss=0.6210, gradTraining Epoch 2/5:  44%|4| 8/18 [00:04<00:02,  4.62it/s, loss=0.6210, gradTraining Epoch 2/5:  44%|4| 8/18 [00:04<00:02,  4.62it/s, loss=0.6922, gradTraining Epoch 2/5:  50%|5| 9/18 [00:04<00:01,  5.45it/s, loss=0.6922, gradTraining Epoch 2/5:  50%|5| 9/18 [00:05<00:01,  5.45it/s, loss=0.6302, gradTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  6.20it/s, loss=0.6302, graTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  6.20it/s, loss=0.6222, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.74it/s, loss=0.6222, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.74it/s, loss=0.6271, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  7.18it/s, loss=0.6271, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  7.18it/s, loss=0.6542, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  7.60it/s, loss=0.6542, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  7.60it/s, loss=0.6130, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  7.90it/s, loss=0.6130, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  7.90it/s, loss=0.6513, graTraining Epoch 2/5:  83%|8| 15/18 [00:05<00:00,  8.11it/s, loss=0.6513, graTraining Epoch 2/5:  83%|8| 15/18 [00:05<00:00,  8.11it/s, loss=0.5896, graTraining Epoch 2/5:  89%|8| 16/18 [00:05<00:00,  8.35it/s, loss=0.5896, graTraining Epoch 2/5:  89%|8| 16/18 [00:05<00:00,  8.35it/s, loss=0.6164, graTraining Epoch 2/5:  94%|9| 17/18 [00:05<00:00,  8.45it/s, loss=0.6164, graTraining Epoch 2/5:  94%|9| 17/18 [00:05<00:00,  8.45it/s, loss=0.5546, graTraining Epoch 2/5: 100%|#| 18/18 [00:06<00:00,  2.77it/s, loss=0.5546, gra

Epoch 2/5 Complete (6.9s) [LR: 0.000010]
Train - Loss: 0.6355, Acc: 0.6690, Precision: 0.6667, Recall: 0.6761, F1: 0.6713, AUC: 0.7504
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/18 [00:03<?, ?it/s, loss=0.5747, grad_norm=0.Training Epoch 3/5:   6%| | 1/18 [00:03<01:07,  3.98s/it, loss=0.5747, gradTraining Epoch 3/5:   6%| | 1/18 [00:04<01:07,  3.98s/it, loss=0.5475, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:27,  1.71s/it, loss=0.5475, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:27,  1.71s/it, loss=0.6174, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:15,  1.00s/it, loss=0.6174, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:15,  1.00s/it, loss=0.5714, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:09,  1.51it/s, loss=0.5714, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:09,  1.51it/s, loss=0.5039, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:06,  2.09it/s, loss=0.5039, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:06,  2.09it/s, loss=0.7779, gradTraining Epoch 3/5:  33%|3| 6/18 [00:04<00:04,  2.77it/s, loss=0.7779, gradTraining Epoch 3/5:  33%|3| 6/18 [00:04<00:04,  2.77it/s, loss=0.5385, gradTraining Epoch 3/5:  39%|3| 7/18 [00:04<00:03,  3.43it/s, loss=0.5385, gradTraining Epoch 3/5:  39%|3| 7/18 [00:04<00:03,  3.43it/s, loss=0.5683, gradTraining Epoch 3/5:  44%|4| 8/18 [00:04<00:02,  4.23it/s, loss=0.5683, gradTraining Epoch 3/5:  44%|4| 8/18 [00:05<00:02,  4.23it/s, loss=0.5674, gradTraining Epoch 3/5:  50%|5| 9/18 [00:05<00:01,  4.94it/s, loss=0.5674, gradTraining Epoch 3/5:  50%|5| 9/18 [00:05<00:01,  4.94it/s, loss=0.7875, gradTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  5.31it/s, loss=0.7875, graTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  5.31it/s, loss=0.5591, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  6.03it/s, loss=0.5591, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  6.03it/s, loss=0.6370, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:00,  6.65it/s, loss=0.6370, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:00,  6.65it/s, loss=0.5201, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  6.78it/s, loss=0.5201, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  6.78it/s, loss=0.6348, graTraining Epoch 3/5:  78%|7| 14/18 [00:05<00:00,  7.03it/s, loss=0.6348, graTraining Epoch 3/5:  78%|7| 14/18 [00:05<00:00,  7.03it/s, loss=0.5471, graTraining Epoch 3/5:  83%|8| 15/18 [00:05<00:00,  7.49it/s, loss=0.5471, graTraining Epoch 3/5:  83%|8| 15/18 [00:05<00:00,  7.49it/s, loss=0.6230, graTraining Epoch 3/5:  89%|8| 16/18 [00:05<00:00,  7.80it/s, loss=0.6230, graTraining Epoch 3/5:  89%|8| 16/18 [00:06<00:00,  7.80it/s, loss=0.5899, graTraining Epoch 3/5:  94%|9| 17/18 [00:06<00:00,  7.48it/s, loss=0.5899, graTraining Epoch 3/5:  94%|9| 17/18 [00:06<00:00,  7.48it/s, loss=0.5142, graTraining Epoch 3/5: 100%|#| 18/18 [00:06<00:00,  7.91it/s, loss=0.5142, graTraining Epoch 3/5: 100%|#| 18/18 [00:06<00:00,  2.64it/s, loss=0.5142, gra

Epoch 3/5 Complete (7.2s) [LR: 0.000010]
Train - Loss: 0.5933, Acc: 0.7113, Precision: 0.6546, Recall: 0.8944, F1: 0.7560, AUC: 0.7398
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/18 [00:03<?, ?it/s, loss=0.5530, grad_norm=0.Training Epoch 4/5:   6%| | 1/18 [00:03<01:07,  3.99s/it, loss=0.5530, gradTraining Epoch 4/5:   6%| | 1/18 [00:04<01:07,  3.99s/it, loss=0.4793, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:27,  1.71s/it, loss=0.4793, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:27,  1.71s/it, loss=0.5098, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:14,  1.01it/s, loss=0.5098, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:14,  1.01it/s, loss=0.5224, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.53it/s, loss=0.5224, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.53it/s, loss=0.4954, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.4954, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.5230, gradTraining Epoch 4/5:  33%|3| 6/18 [00:04<00:04,  2.90it/s, loss=0.5230, gradTraining Epoch 4/5:  33%|3| 6/18 [00:04<00:04,  2.90it/s, loss=0.5569, gradTraining Epoch 4/5:  39%|3| 7/18 [00:04<00:03,  3.56it/s, loss=0.5569, gradTraining Epoch 4/5:  39%|3| 7/18 [00:04<00:03,  3.56it/s, loss=0.7200, gradTraining Epoch 4/5:  44%|4| 8/18 [00:04<00:02,  4.39it/s, loss=0.7200, gradTraining Epoch 4/5:  44%|4| 8/18 [00:04<00:02,  4.39it/s, loss=0.5734, gradTraining Epoch 4/5:  50%|5| 9/18 [00:04<00:01,  5.22it/s, loss=0.5734, gradTraining Epoch 4/5:  50%|5| 9/18 [00:05<00:01,  5.22it/s, loss=0.5488, gradTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  5.98it/s, loss=0.5488, graTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  5.98it/s, loss=0.5401, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.64it/s, loss=0.5401, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.64it/s, loss=0.5323, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  7.12it/s, loss=0.5323, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  7.12it/s, loss=0.4265, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  6.85it/s, loss=0.4265, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  6.85it/s, loss=0.5586, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  7.38it/s, loss=0.5586, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  7.38it/s, loss=0.4961, graTraining Epoch 4/5:  83%|8| 15/18 [00:05<00:00,  7.80it/s, loss=0.4961, graTraining Epoch 4/5:  83%|8| 15/18 [00:05<00:00,  7.80it/s, loss=0.5858, graTraining Epoch 4/5:  89%|8| 16/18 [00:05<00:00,  8.11it/s, loss=0.5858, graTraining Epoch 4/5:  89%|8| 16/18 [00:05<00:00,  8.11it/s, loss=0.5429, graTraining Epoch 4/5:  94%|9| 17/18 [00:05<00:00,  8.33it/s, loss=0.5429, graTraining Epoch 4/5:  94%|9| 17/18 [00:06<00:00,  8.33it/s, loss=0.4426, graTraining Epoch 4/5: 100%|#| 18/18 [00:06<00:00,  2.72it/s, loss=0.4426, gra

Epoch 4/5 Complete (7.0s) [LR: 0.000010]
Train - Loss: 0.5337, Acc: 0.7394, Precision: 0.6717, Recall: 0.9366, F1: 0.7824, AUC: 0.7828
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.4522, grad_norm=1.Training Epoch 5/5:   6%| | 1/18 [00:04<01:10,  4.12s/it, loss=0.4522, gradTraining Epoch 5/5:   6%| | 1/18 [00:04<01:10,  4.12s/it, loss=0.5076, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:28,  1.79s/it, loss=0.5076, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:28,  1.79s/it, loss=0.4528, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:15,  1.04s/it, loss=0.4528, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:15,  1.04s/it, loss=0.5236, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:09,  1.46it/s, loss=0.5236, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:09,  1.46it/s, loss=0.5683, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:06,  2.10it/s, loss=0.5683, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:06,  2.10it/s, loss=0.4720, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.83it/s, loss=0.4720, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.83it/s, loss=0.4815, gradTraining Epoch 5/5:  39%|3| 7/18 [00:04<00:03,  3.63it/s, loss=0.4815, gradTraining Epoch 5/5:  39%|3| 7/18 [00:05<00:03,  3.63it/s, loss=0.4022, gradTraining Epoch 5/5:  44%|4| 8/18 [00:05<00:02,  4.23it/s, loss=0.4022, gradTraining Epoch 5/5:  44%|4| 8/18 [00:05<00:02,  4.23it/s, loss=0.4860, gradTraining Epoch 5/5:  50%|5| 9/18 [00:05<00:01,  4.73it/s, loss=0.4860, gradTraining Epoch 5/5:  50%|5| 9/18 [00:05<00:01,  4.73it/s, loss=0.3855, gradTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  5.19it/s, loss=0.3855, graTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  5.19it/s, loss=0.6606, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  5.72it/s, loss=0.6606, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  5.72it/s, loss=0.4732, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  6.09it/s, loss=0.4732, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  6.09it/s, loss=0.4304, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  6.25it/s, loss=0.4304, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  6.25it/s, loss=0.6546, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  6.34it/s, loss=0.6546, graTraining Epoch 5/5:  78%|7| 14/18 [00:06<00:00,  6.34it/s, loss=0.3688, graTraining Epoch 5/5:  83%|8| 15/18 [00:06<00:00,  6.44it/s, loss=0.3688, graTraining Epoch 5/5:  83%|8| 15/18 [00:06<00:00,  6.44it/s, loss=0.4676, graTraining Epoch 5/5:  89%|8| 16/18 [00:06<00:00,  6.46it/s, loss=0.4676, graTraining Epoch 5/5:  89%|8| 16/18 [00:06<00:00,  6.46it/s, loss=0.4434, graTraining Epoch 5/5:  94%|9| 17/18 [00:06<00:00,  6.49it/s, loss=0.4434, graTraining Epoch 5/5:  94%|9| 17/18 [00:06<00:00,  6.49it/s, loss=0.5833, graTraining Epoch 5/5: 100%|#| 18/18 [00:06<00:00,  6.88it/s, loss=0.5833, graTraining Epoch 5/5: 100%|#| 18/18 [00:07<00:00,  2.53it/s, loss=0.5833, gra

Epoch 5/5 Complete (7.5s) [LR: 0.000005]
Train - Loss: 0.4896, Acc: 0.7817, Precision: 0.7273, Recall: 0.9014, F1: 0.8050, AUC: 0.8554
------------------------------------------------------------
Training curves saved to model\chb06_fold2\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.6 minutes
Models saved in: model\chb06_fold2
============================================================
✅ Fold 2 training completed successfully!

============================================================
TRAINING FOLD 3/9
============================================================
Using dataset prefix: chb06_fold3
Loading datasets from: preprocessing\data\chb06_fold3
Saving models to: model\chb06_fold3
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=1.1917, std=2.5462
Loaded train dataset: 284 samples
  - Spectrogram shape: torch.Size([284, 30, 18, 50, 10])
  - Value range: [-5.1809, 3.2381]
  - Class distribution: tensor([142, 142])
LOOCV Mode (Fold 3): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.7009, grad_norm=1.Training Epoch 1/5:   6%| | 1/18 [00:04<01:09,  4.12s/it, loss=0.7009, gradTraining Epoch 1/5:   6%| | 1/18 [00:04<01:09,  4.12s/it, loss=0.6935, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:28,  1.78s/it, loss=0.6935, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:28,  1.78s/it, loss=0.6829, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.03s/it, loss=0.6829, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.03s/it, loss=0.6875, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.47it/s, loss=0.6875, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.47it/s, loss=0.6921, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:06,  2.05it/s, loss=0.6921, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:06,  2.05it/s, loss=0.6869, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.71it/s, loss=0.6869, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.71it/s, loss=0.6833, gradTraining Epoch 1/5:  39%|3| 7/18 [00:04<00:03,  3.47it/s, loss=0.6833, gradTraining Epoch 1/5:  39%|3| 7/18 [00:05<00:03,  3.47it/s, loss=0.7038, gradTraining Epoch 1/5:  44%|4| 8/18 [00:05<00:02,  4.26it/s, loss=0.7038, gradTraining Epoch 1/5:  44%|4| 8/18 [00:05<00:02,  4.26it/s, loss=0.6971, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  5.04it/s, loss=0.6971, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  5.04it/s, loss=0.6887, gradTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  5.38it/s, loss=0.6887, graTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  5.38it/s, loss=0.6893, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  5.71it/s, loss=0.6893, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  5.71it/s, loss=0.6943, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:01,  5.94it/s, loss=0.6943, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:01,  5.94it/s, loss=0.6706, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  6.07it/s, loss=0.6706, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  6.07it/s, loss=0.6902, graTraining Epoch 1/5:  78%|7| 14/18 [00:05<00:00,  6.68it/s, loss=0.6902, graTraining Epoch 1/5:  78%|7| 14/18 [00:06<00:00,  6.68it/s, loss=0.6844, graTraining Epoch 1/5:  83%|8| 15/18 [00:06<00:00,  6.93it/s, loss=0.6844, graTraining Epoch 1/5:  83%|8| 15/18 [00:06<00:00,  6.93it/s, loss=0.7096, graTraining Epoch 1/5:  89%|8| 16/18 [00:06<00:00,  6.78it/s, loss=0.7096, graTraining Epoch 1/5:  89%|8| 16/18 [00:06<00:00,  6.78it/s, loss=0.6991, graTraining Epoch 1/5:  94%|9| 17/18 [00:06<00:00,  6.65it/s, loss=0.6991, graTraining Epoch 1/5:  94%|9| 17/18 [00:06<00:00,  6.65it/s, loss=0.6925, graTraining Epoch 1/5: 100%|#| 18/18 [00:06<00:00,  6.97it/s, loss=0.6925, graTraining Epoch 1/5: 100%|#| 18/18 [00:07<00:00,  2.54it/s, loss=0.6925, gra

Epoch 1/5 Complete (7.5s) [LR: 0.000010]
Train - Loss: 0.6915, Acc: 0.5211, Precision: 0.5183, Recall: 0.5986, F1: 0.5556, AUC: 0.5321
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6800, grad_norm=1.Training Epoch 2/5:   6%| | 1/18 [00:04<01:11,  4.21s/it, loss=0.6800, gradTraining Epoch 2/5:   6%| | 1/18 [00:04<01:11,  4.21s/it, loss=0.6726, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:28,  1.80s/it, loss=0.6726, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:28,  1.80s/it, loss=0.6668, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:15,  1.03s/it, loss=0.6668, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:15,  1.03s/it, loss=0.6683, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:09,  1.49it/s, loss=0.6683, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:09,  1.49it/s, loss=0.6833, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:06,  2.13it/s, loss=0.6833, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:06,  2.13it/s, loss=0.6467, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.88it/s, loss=0.6467, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.88it/s, loss=0.6851, gradTraining Epoch 2/5:  39%|3| 7/18 [00:04<00:02,  3.69it/s, loss=0.6851, gradTraining Epoch 2/5:  39%|3| 7/18 [00:05<00:02,  3.69it/s, loss=0.6642, gradTraining Epoch 2/5:  44%|4| 8/18 [00:05<00:02,  4.52it/s, loss=0.6642, gradTraining Epoch 2/5:  44%|4| 8/18 [00:05<00:02,  4.52it/s, loss=0.6428, gradTraining Epoch 2/5:  50%|5| 9/18 [00:05<00:01,  5.35it/s, loss=0.6428, gradTraining Epoch 2/5:  50%|5| 9/18 [00:05<00:01,  5.35it/s, loss=0.6561, gradTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  6.08it/s, loss=0.6561, graTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  6.08it/s, loss=0.6530, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.73it/s, loss=0.6530, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.73it/s, loss=0.6585, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  7.25it/s, loss=0.6585, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  7.25it/s, loss=0.6499, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  7.68it/s, loss=0.6499, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  7.68it/s, loss=0.6365, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  8.00it/s, loss=0.6365, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  8.00it/s, loss=0.6673, graTraining Epoch 2/5:  83%|8| 15/18 [00:05<00:00,  8.25it/s, loss=0.6673, graTraining Epoch 2/5:  83%|8| 15/18 [00:05<00:00,  8.25it/s, loss=0.6460, graTraining Epoch 2/5:  89%|8| 16/18 [00:05<00:00,  8.38it/s, loss=0.6460, graTraining Epoch 2/5:  89%|8| 16/18 [00:06<00:00,  8.38it/s, loss=0.6376, graTraining Epoch 2/5:  94%|9| 17/18 [00:06<00:00,  8.47it/s, loss=0.6376, graTraining Epoch 2/5:  94%|9| 17/18 [00:06<00:00,  8.47it/s, loss=0.7029, graTraining Epoch 2/5: 100%|#| 18/18 [00:06<00:00,  2.69it/s, loss=0.7029, gra

Epoch 2/5 Complete (7.1s) [LR: 0.000010]
Train - Loss: 0.6621, Acc: 0.7218, Precision: 0.6886, Recall: 0.8099, F1: 0.7443, AUC: 0.7773
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/18 [00:03<?, ?it/s, loss=0.5904, grad_norm=1.Training Epoch 3/5:   6%| | 1/18 [00:03<01:07,  3.98s/it, loss=0.5904, gradTraining Epoch 3/5:   6%| | 1/18 [00:04<01:07,  3.98s/it, loss=0.7051, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:27,  1.71s/it, loss=0.7051, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:27,  1.71s/it, loss=0.6320, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:14,  1.02it/s, loss=0.6320, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:14,  1.02it/s, loss=0.6188, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:08,  1.57it/s, loss=0.6188, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:08,  1.57it/s, loss=0.6118, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:05,  2.23it/s, loss=0.6118, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:05,  2.23it/s, loss=0.6210, gradTraining Epoch 3/5:  33%|3| 6/18 [00:04<00:04,  2.98it/s, loss=0.6210, gradTraining Epoch 3/5:  33%|3| 6/18 [00:04<00:04,  2.98it/s, loss=0.5951, gradTraining Epoch 3/5:  39%|3| 7/18 [00:04<00:02,  3.80it/s, loss=0.5951, gradTraining Epoch 3/5:  39%|3| 7/18 [00:04<00:02,  3.80it/s, loss=0.5813, gradTraining Epoch 3/5:  44%|4| 8/18 [00:04<00:02,  4.65it/s, loss=0.5813, gradTraining Epoch 3/5:  44%|4| 8/18 [00:04<00:02,  4.65it/s, loss=0.6047, gradTraining Epoch 3/5:  50%|5| 9/18 [00:04<00:01,  5.42it/s, loss=0.6047, gradTraining Epoch 3/5:  50%|5| 9/18 [00:05<00:01,  5.42it/s, loss=0.5519, gradTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  6.16it/s, loss=0.5519, graTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  6.16it/s, loss=0.5665, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  6.79it/s, loss=0.5665, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  6.79it/s, loss=0.6088, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:00,  7.29it/s, loss=0.6088, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:00,  7.29it/s, loss=0.5990, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  7.64it/s, loss=0.5990, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  7.64it/s, loss=0.5897, graTraining Epoch 3/5:  78%|7| 14/18 [00:05<00:00,  7.98it/s, loss=0.5897, graTraining Epoch 3/5:  78%|7| 14/18 [00:05<00:00,  7.98it/s, loss=0.5242, graTraining Epoch 3/5:  83%|8| 15/18 [00:05<00:00,  8.25it/s, loss=0.5242, graTraining Epoch 3/5:  83%|8| 15/18 [00:05<00:00,  8.25it/s, loss=0.6473, graTraining Epoch 3/5:  89%|8| 16/18 [00:05<00:00,  8.46it/s, loss=0.6473, graTraining Epoch 3/5:  89%|8| 16/18 [00:05<00:00,  8.46it/s, loss=0.5373, graTraining Epoch 3/5:  94%|9| 17/18 [00:05<00:00,  8.48it/s, loss=0.5373, graTraining Epoch 3/5:  94%|9| 17/18 [00:05<00:00,  8.48it/s, loss=0.5348, graTraining Epoch 3/5: 100%|#| 18/18 [00:06<00:00,  2.78it/s, loss=0.5348, gra

Epoch 3/5 Complete (6.9s) [LR: 0.000010]
Train - Loss: 0.5955, Acc: 0.7641, Precision: 0.6984, Recall: 0.9296, F1: 0.7976, AUC: 0.8204
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.5536, grad_norm=1.Training Epoch 4/5:   6%| | 1/18 [00:04<01:09,  4.09s/it, loss=0.5536, gradTraining Epoch 4/5:   6%| | 1/18 [00:04<01:09,  4.09s/it, loss=0.6281, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:28,  1.76s/it, loss=0.6281, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:28,  1.76s/it, loss=0.5202, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:15,  1.01s/it, loss=0.5202, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:15,  1.01s/it, loss=0.5506, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.53it/s, loss=0.5506, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.53it/s, loss=0.6147, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:05,  2.19it/s, loss=0.6147, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:05,  2.19it/s, loss=0.4202, gradTraining Epoch 4/5:  33%|3| 6/18 [00:04<00:04,  2.93it/s, loss=0.4202, gradTraining Epoch 4/5:  33%|3| 6/18 [00:04<00:04,  2.93it/s, loss=0.6185, gradTraining Epoch 4/5:  39%|3| 7/18 [00:04<00:02,  3.74it/s, loss=0.6185, gradTraining Epoch 4/5:  39%|3| 7/18 [00:04<00:02,  3.74it/s, loss=0.5366, gradTraining Epoch 4/5:  44%|4| 8/18 [00:04<00:02,  4.59it/s, loss=0.5366, gradTraining Epoch 4/5:  44%|4| 8/18 [00:05<00:02,  4.59it/s, loss=0.4890, gradTraining Epoch 4/5:  50%|5| 9/18 [00:05<00:01,  5.35it/s, loss=0.4890, gradTraining Epoch 4/5:  50%|5| 9/18 [00:05<00:01,  5.35it/s, loss=0.5564, gradTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  6.08it/s, loss=0.5564, graTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  6.08it/s, loss=0.4551, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.69it/s, loss=0.4551, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.69it/s, loss=0.4690, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  7.22it/s, loss=0.4690, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  7.22it/s, loss=0.4725, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  7.63it/s, loss=0.4725, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  7.63it/s, loss=0.5521, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  7.97it/s, loss=0.5521, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  7.97it/s, loss=0.4744, graTraining Epoch 4/5:  83%|8| 15/18 [00:05<00:00,  8.12it/s, loss=0.4744, graTraining Epoch 4/5:  83%|8| 15/18 [00:05<00:00,  8.12it/s, loss=0.4129, graTraining Epoch 4/5:  89%|8| 16/18 [00:05<00:00,  8.25it/s, loss=0.4129, graTraining Epoch 4/5:  89%|8| 16/18 [00:05<00:00,  8.25it/s, loss=0.4920, graTraining Epoch 4/5:  94%|9| 17/18 [00:05<00:00,  8.35it/s, loss=0.4920, graTraining Epoch 4/5:  94%|9| 17/18 [00:06<00:00,  8.35it/s, loss=0.7383, graTraining Epoch 4/5: 100%|#| 18/18 [00:06<00:00,  2.73it/s, loss=0.7383, gra

Epoch 4/5 Complete (7.0s) [LR: 0.000010]
Train - Loss: 0.5308, Acc: 0.7606, Precision: 0.6968, Recall: 0.9225, F1: 0.7939, AUC: 0.8362
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.5020, grad_norm=1.Training Epoch 5/5:   6%| | 1/18 [00:04<01:09,  4.10s/it, loss=0.5020, gradTraining Epoch 5/5:   6%| | 1/18 [00:04<01:09,  4.10s/it, loss=0.5612, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:28,  1.76s/it, loss=0.5612, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:28,  1.76s/it, loss=0.3790, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:15,  1.01s/it, loss=0.3790, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:15,  1.01s/it, loss=0.5538, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:09,  1.52it/s, loss=0.5538, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:09,  1.52it/s, loss=0.5266, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.5266, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.4820, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.92it/s, loss=0.4820, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.92it/s, loss=0.4596, gradTraining Epoch 5/5:  39%|3| 7/18 [00:04<00:02,  3.73it/s, loss=0.4596, gradTraining Epoch 5/5:  39%|3| 7/18 [00:04<00:02,  3.73it/s, loss=0.3956, gradTraining Epoch 5/5:  44%|4| 8/18 [00:04<00:02,  4.58it/s, loss=0.3956, gradTraining Epoch 5/5:  44%|4| 8/18 [00:05<00:02,  4.58it/s, loss=0.5412, gradTraining Epoch 5/5:  50%|5| 9/18 [00:05<00:01,  5.34it/s, loss=0.5412, gradTraining Epoch 5/5:  50%|5| 9/18 [00:05<00:01,  5.34it/s, loss=0.3741, gradTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  6.04it/s, loss=0.3741, graTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  6.04it/s, loss=0.7131, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  6.70it/s, loss=0.7131, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  6.70it/s, loss=0.4590, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  7.23it/s, loss=0.4590, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  7.23it/s, loss=0.4103, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  7.62it/s, loss=0.4103, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  7.62it/s, loss=0.4459, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  7.99it/s, loss=0.4459, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  7.99it/s, loss=0.4095, graTraining Epoch 5/5:  83%|8| 15/18 [00:05<00:00,  8.29it/s, loss=0.4095, graTraining Epoch 5/5:  83%|8| 15/18 [00:05<00:00,  8.29it/s, loss=0.4068, graTraining Epoch 5/5:  89%|8| 16/18 [00:05<00:00,  8.42it/s, loss=0.4068, graTraining Epoch 5/5:  89%|8| 16/18 [00:05<00:00,  8.42it/s, loss=0.4247, graTraining Epoch 5/5:  94%|9| 17/18 [00:05<00:00,  8.49it/s, loss=0.4247, graTraining Epoch 5/5:  94%|9| 17/18 [00:06<00:00,  8.49it/s, loss=0.3997, graTraining Epoch 5/5: 100%|#| 18/18 [00:06<00:00,  8.89it/s, loss=0.3997, graTraining Epoch 5/5: 100%|#| 18/18 [00:06<00:00,  2.72it/s, loss=0.3997, gra

Epoch 5/5 Complete (7.0s) [LR: 0.000005]
Train - Loss: 0.4691, Acc: 0.7923, Precision: 0.7399, Recall: 0.9014, F1: 0.8127, AUC: 0.8690
------------------------------------------------------------
Training curves saved to model\chb06_fold3\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.6 minutes
Models saved in: model\chb06_fold3
============================================================
✅ Fold 3 training completed successfully!

============================================================
TRAINING FOLD 4/9
============================================================
Using dataset prefix: chb06_fold4
Loading datasets from: preprocessing\data\chb06_fold4
Saving models to: model\chb06_fold4
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=1.2546, std=2.5048
Loaded train dataset: 284 samples
  - Spectrogram shape: torch.Size([284, 30, 18, 50, 10])
  - Value range: [-5.2917, 3.2045]
  - Class distribution: tensor([142, 142])
LOOCV Mode (Fold 4): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6798, grad_norm=0.Training Epoch 1/5:   6%| | 1/18 [00:04<01:10,  4.16s/it, loss=0.6798, gradTraining Epoch 1/5:   6%| | 1/18 [00:04<01:10,  4.16s/it, loss=0.7102, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:28,  1.78s/it, loss=0.7102, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:28,  1.78s/it, loss=0.7049, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.02s/it, loss=0.7049, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.02s/it, loss=0.6903, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.51it/s, loss=0.6903, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.51it/s, loss=0.6834, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:06,  2.16it/s, loss=0.6834, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:06,  2.16it/s, loss=0.6830, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.91it/s, loss=0.6830, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.91it/s, loss=0.6895, gradTraining Epoch 1/5:  39%|3| 7/18 [00:04<00:02,  3.72it/s, loss=0.6895, gradTraining Epoch 1/5:  39%|3| 7/18 [00:04<00:02,  3.72it/s, loss=0.6710, gradTraining Epoch 1/5:  44%|4| 8/18 [00:04<00:02,  4.57it/s, loss=0.6710, gradTraining Epoch 1/5:  44%|4| 8/18 [00:05<00:02,  4.57it/s, loss=0.7057, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  5.40it/s, loss=0.7057, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  5.40it/s, loss=0.6828, gradTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  6.15it/s, loss=0.6828, graTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  6.15it/s, loss=0.6805, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  6.80it/s, loss=0.6805, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  6.80it/s, loss=0.6860, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:00,  7.37it/s, loss=0.6860, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:00,  7.37it/s, loss=0.6752, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  7.81it/s, loss=0.6752, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  7.81it/s, loss=0.6919, graTraining Epoch 1/5:  78%|7| 14/18 [00:05<00:00,  8.00it/s, loss=0.6919, graTraining Epoch 1/5:  78%|7| 14/18 [00:05<00:00,  8.00it/s, loss=0.6998, graTraining Epoch 1/5:  83%|8| 15/18 [00:05<00:00,  8.16it/s, loss=0.6998, graTraining Epoch 1/5:  83%|8| 15/18 [00:05<00:00,  8.16it/s, loss=0.6839, graTraining Epoch 1/5:  89%|8| 16/18 [00:05<00:00,  8.20it/s, loss=0.6839, graTraining Epoch 1/5:  89%|8| 16/18 [00:05<00:00,  8.20it/s, loss=0.6916, graTraining Epoch 1/5:  94%|9| 17/18 [00:05<00:00,  8.24it/s, loss=0.6916, graTraining Epoch 1/5:  94%|9| 17/18 [00:06<00:00,  8.24it/s, loss=0.6682, graTraining Epoch 1/5: 100%|#| 18/18 [00:06<00:00,  2.70it/s, loss=0.6682, gra

Epoch 1/5 Complete (7.1s) [LR: 0.000010]
Train - Loss: 0.6877, Acc: 0.5915, Precision: 0.6161, Recall: 0.4859, F1: 0.5433, AUC: 0.5908
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6721, grad_norm=1.Training Epoch 2/5:   6%| | 1/18 [00:04<01:10,  4.13s/it, loss=0.6721, gradTraining Epoch 2/5:   6%| | 1/18 [00:04<01:10,  4.13s/it, loss=0.6605, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:28,  1.78s/it, loss=0.6605, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:28,  1.78s/it, loss=0.6761, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:15,  1.03s/it, loss=0.6761, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:15,  1.03s/it, loss=0.6741, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:09,  1.48it/s, loss=0.6741, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:09,  1.48it/s, loss=0.6694, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:06,  2.10it/s, loss=0.6694, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:06,  2.10it/s, loss=0.6663, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.83it/s, loss=0.6663, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.83it/s, loss=0.6581, gradTraining Epoch 2/5:  39%|3| 7/18 [00:04<00:03,  3.61it/s, loss=0.6581, gradTraining Epoch 2/5:  39%|3| 7/18 [00:05<00:03,  3.61it/s, loss=0.6511, gradTraining Epoch 2/5:  44%|4| 8/18 [00:05<00:02,  4.43it/s, loss=0.6511, gradTraining Epoch 2/5:  44%|4| 8/18 [00:05<00:02,  4.43it/s, loss=0.6538, gradTraining Epoch 2/5:  50%|5| 9/18 [00:05<00:01,  5.23it/s, loss=0.6538, gradTraining Epoch 2/5:  50%|5| 9/18 [00:05<00:01,  5.23it/s, loss=0.6332, gradTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  5.90it/s, loss=0.6332, graTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  5.90it/s, loss=0.6408, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.33it/s, loss=0.6408, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.33it/s, loss=0.6540, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  6.68it/s, loss=0.6540, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  6.68it/s, loss=0.6356, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  6.94it/s, loss=0.6356, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  6.94it/s, loss=0.6457, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  7.09it/s, loss=0.6457, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  7.09it/s, loss=0.6187, graTraining Epoch 2/5:  83%|8| 15/18 [00:05<00:00,  7.30it/s, loss=0.6187, graTraining Epoch 2/5:  83%|8| 15/18 [00:06<00:00,  7.30it/s, loss=0.6418, graTraining Epoch 2/5:  89%|8| 16/18 [00:06<00:00,  7.35it/s, loss=0.6418, graTraining Epoch 2/5:  89%|8| 16/18 [00:06<00:00,  7.35it/s, loss=0.6283, graTraining Epoch 2/5:  94%|9| 17/18 [00:06<00:00,  7.46it/s, loss=0.6283, graTraining Epoch 2/5:  94%|9| 17/18 [00:06<00:00,  7.46it/s, loss=0.6190, graTraining Epoch 2/5: 100%|#| 18/18 [00:06<00:00,  7.90it/s, loss=0.6190, graTraining Epoch 2/5: 100%|#| 18/18 [00:06<00:00,  2.61it/s, loss=0.6190, gra

Epoch 2/5 Complete (7.3s) [LR: 0.000010]
Train - Loss: 0.6499, Acc: 0.7359, Precision: 0.7134, Recall: 0.7887, F1: 0.7492, AUC: 0.7742
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/18 [00:03<?, ?it/s, loss=0.6353, grad_norm=0.Training Epoch 3/5:   6%| | 1/18 [00:03<01:07,  3.99s/it, loss=0.6353, gradTraining Epoch 3/5:   6%| | 1/18 [00:04<01:07,  3.99s/it, loss=0.6049, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:27,  1.71s/it, loss=0.6049, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:27,  1.71s/it, loss=0.5836, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:14,  1.02it/s, loss=0.5836, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:14,  1.02it/s, loss=0.5789, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:08,  1.56it/s, loss=0.5789, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:08,  1.56it/s, loss=0.5954, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:05,  2.22it/s, loss=0.5954, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:05,  2.22it/s, loss=0.5717, gradTraining Epoch 3/5:  33%|3| 6/18 [00:04<00:04,  2.96it/s, loss=0.5717, gradTraining Epoch 3/5:  33%|3| 6/18 [00:04<00:04,  2.96it/s, loss=0.5720, gradTraining Epoch 3/5:  39%|3| 7/18 [00:04<00:02,  3.78it/s, loss=0.5720, gradTraining Epoch 3/5:  39%|3| 7/18 [00:04<00:02,  3.78it/s, loss=0.5910, gradTraining Epoch 3/5:  44%|4| 8/18 [00:04<00:02,  4.62it/s, loss=0.5910, gradTraining Epoch 3/5:  44%|4| 8/18 [00:04<00:02,  4.62it/s, loss=0.5543, gradTraining Epoch 3/5:  50%|5| 9/18 [00:04<00:01,  5.40it/s, loss=0.5543, gradTraining Epoch 3/5:  50%|5| 9/18 [00:05<00:01,  5.40it/s, loss=0.6016, gradTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  6.12it/s, loss=0.6016, graTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  6.12it/s, loss=0.5788, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  6.74it/s, loss=0.5788, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  6.74it/s, loss=0.5581, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:00,  7.25it/s, loss=0.5581, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:00,  7.25it/s, loss=0.5761, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  7.64it/s, loss=0.5761, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  7.64it/s, loss=0.5844, graTraining Epoch 3/5:  78%|7| 14/18 [00:05<00:00,  7.92it/s, loss=0.5844, graTraining Epoch 3/5:  78%|7| 14/18 [00:05<00:00,  7.92it/s, loss=0.5931, graTraining Epoch 3/5:  83%|8| 15/18 [00:05<00:00,  8.13it/s, loss=0.5931, graTraining Epoch 3/5:  83%|8| 15/18 [00:05<00:00,  8.13it/s, loss=0.5364, graTraining Epoch 3/5:  89%|8| 16/18 [00:05<00:00,  8.32it/s, loss=0.5364, graTraining Epoch 3/5:  89%|8| 16/18 [00:05<00:00,  8.32it/s, loss=0.5377, graTraining Epoch 3/5:  94%|9| 17/18 [00:05<00:00,  8.49it/s, loss=0.5377, graTraining Epoch 3/5:  94%|9| 17/18 [00:05<00:00,  8.49it/s, loss=0.6079, graTraining Epoch 3/5: 100%|#| 18/18 [00:06<00:00,  2.77it/s, loss=0.6079, gra

Epoch 3/5 Complete (6.9s) [LR: 0.000010]
Train - Loss: 0.5812, Acc: 0.7359, Precision: 0.6618, Recall: 0.9648, F1: 0.7851, AUC: 0.7837
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.5352, grad_norm=1.Training Epoch 4/5:   6%| | 1/18 [00:04<01:09,  4.07s/it, loss=0.5352, gradTraining Epoch 4/5:   6%| | 1/18 [00:04<01:09,  4.07s/it, loss=0.4486, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:27,  1.74s/it, loss=0.4486, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:27,  1.74s/it, loss=0.5472, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:14,  1.00it/s, loss=0.5472, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:14,  1.00it/s, loss=0.6306, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.54it/s, loss=0.6306, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.54it/s, loss=0.5029, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:05,  2.19it/s, loss=0.5029, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:05,  2.19it/s, loss=0.5327, gradTraining Epoch 4/5:  33%|3| 6/18 [00:04<00:04,  2.94it/s, loss=0.5327, gradTraining Epoch 4/5:  33%|3| 6/18 [00:04<00:04,  2.94it/s, loss=0.4939, gradTraining Epoch 4/5:  39%|3| 7/18 [00:04<00:02,  3.75it/s, loss=0.4939, gradTraining Epoch 4/5:  39%|3| 7/18 [00:04<00:02,  3.75it/s, loss=0.5604, gradTraining Epoch 4/5:  44%|4| 8/18 [00:04<00:02,  4.58it/s, loss=0.5604, gradTraining Epoch 4/5:  44%|4| 8/18 [00:04<00:02,  4.58it/s, loss=0.5470, gradTraining Epoch 4/5:  50%|5| 9/18 [00:04<00:01,  5.40it/s, loss=0.5470, gradTraining Epoch 4/5:  50%|5| 9/18 [00:05<00:01,  5.40it/s, loss=0.4871, gradTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  6.14it/s, loss=0.4871, graTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  6.14it/s, loss=0.4654, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.75it/s, loss=0.4654, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.75it/s, loss=0.5090, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  7.26it/s, loss=0.5090, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  7.26it/s, loss=0.5605, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  7.64it/s, loss=0.5605, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  7.64it/s, loss=0.5656, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  7.98it/s, loss=0.5656, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  7.98it/s, loss=0.4811, graTraining Epoch 4/5:  83%|8| 15/18 [00:05<00:00,  8.18it/s, loss=0.4811, graTraining Epoch 4/5:  83%|8| 15/18 [00:05<00:00,  8.18it/s, loss=0.6464, graTraining Epoch 4/5:  89%|8| 16/18 [00:05<00:00,  8.30it/s, loss=0.6464, graTraining Epoch 4/5:  89%|8| 16/18 [00:05<00:00,  8.30it/s, loss=0.5553, graTraining Epoch 4/5:  94%|9| 17/18 [00:05<00:00,  8.46it/s, loss=0.5553, graTraining Epoch 4/5:  94%|9| 17/18 [00:05<00:00,  8.46it/s, loss=0.4315, graTraining Epoch 4/5: 100%|#| 18/18 [00:06<00:00,  2.74it/s, loss=0.4315, gra

Epoch 4/5 Complete (7.0s) [LR: 0.000010]
Train - Loss: 0.5278, Acc: 0.7641, Precision: 0.6829, Recall: 0.9859, F1: 0.8069, AUC: 0.7938
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.4274, grad_norm=1.Training Epoch 5/5:   6%| | 1/18 [00:04<01:09,  4.09s/it, loss=0.4274, gradTraining Epoch 5/5:   6%| | 1/18 [00:04<01:09,  4.09s/it, loss=0.5267, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:28,  1.75s/it, loss=0.5267, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:28,  1.75s/it, loss=0.4253, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:15,  1.01s/it, loss=0.4253, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:15,  1.01s/it, loss=0.4725, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:09,  1.53it/s, loss=0.4725, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:09,  1.53it/s, loss=0.4995, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.4995, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.5063, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.93it/s, loss=0.5063, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.93it/s, loss=0.4236, gradTraining Epoch 5/5:  39%|3| 7/18 [00:04<00:02,  3.73it/s, loss=0.4236, gradTraining Epoch 5/5:  39%|3| 7/18 [00:04<00:02,  3.73it/s, loss=0.4532, gradTraining Epoch 5/5:  44%|4| 8/18 [00:04<00:02,  4.51it/s, loss=0.4532, gradTraining Epoch 5/5:  44%|4| 8/18 [00:05<00:02,  4.51it/s, loss=0.5891, gradTraining Epoch 5/5:  50%|5| 9/18 [00:05<00:01,  5.33it/s, loss=0.5891, gradTraining Epoch 5/5:  50%|5| 9/18 [00:05<00:01,  5.33it/s, loss=0.4910, gradTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  6.08it/s, loss=0.4910, graTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  6.08it/s, loss=0.3905, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  6.72it/s, loss=0.3905, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  6.72it/s, loss=0.4439, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  7.24it/s, loss=0.4439, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  7.24it/s, loss=0.4721, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  7.65it/s, loss=0.4721, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  7.65it/s, loss=0.3795, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  7.98it/s, loss=0.3795, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  7.98it/s, loss=0.3168, graTraining Epoch 5/5:  83%|8| 15/18 [00:05<00:00,  8.12it/s, loss=0.3168, graTraining Epoch 5/5:  83%|8| 15/18 [00:05<00:00,  8.12it/s, loss=0.4981, graTraining Epoch 5/5:  89%|8| 16/18 [00:05<00:00,  8.30it/s, loss=0.4981, graTraining Epoch 5/5:  89%|8| 16/18 [00:05<00:00,  8.30it/s, loss=0.5797, graTraining Epoch 5/5:  94%|9| 17/18 [00:05<00:00,  8.45it/s, loss=0.5797, graTraining Epoch 5/5:  94%|9| 17/18 [00:06<00:00,  8.45it/s, loss=0.4245, graTraining Epoch 5/5: 100%|#| 18/18 [00:06<00:00,  2.73it/s, loss=0.4245, gra

Epoch 5/5 Complete (7.0s) [LR: 0.000005]
Train - Loss: 0.4622, Acc: 0.7923, Precision: 0.7371, Recall: 0.9085, F1: 0.8139, AUC: 0.8625
------------------------------------------------------------
Training curves saved to model\chb06_fold4\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.6 minutes
Models saved in: model\chb06_fold4
============================================================
✅ Fold 4 training completed successfully!

============================================================
TRAINING FOLD 5/9
============================================================
Using dataset prefix: chb06_fold5
Loading datasets from: preprocessing\data\chb06_fold5
Saving models to: model\chb06_fold5
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=1.2791, std=2.5262
Loaded train dataset: 294 samples
  - Spectrogram shape: torch.Size([294, 30, 18, 50, 10])
  - Value range: [-5.2566, 3.2292]
  - Class distribution: tensor([147, 147])
LOOCV Mode (Fold 5): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/19 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/19 [00:04<?, ?it/s, loss=0.6868, grad_norm=1.Training Epoch 1/5:   5%| | 1/19 [00:04<01:15,  4.20s/it, loss=0.6868, gradTraining Epoch 1/5:   5%| | 1/19 [00:04<01:15,  4.20s/it, loss=0.6893, gradTraining Epoch 1/5:  11%|1| 2/19 [00:04<00:30,  1.80s/it, loss=0.6893, gradTraining Epoch 1/5:  11%|1| 2/19 [00:04<00:30,  1.80s/it, loss=0.6889, gradTraining Epoch 1/5:  16%|1| 3/19 [00:04<00:16,  1.03s/it, loss=0.6889, gradTraining Epoch 1/5:  16%|1| 3/19 [00:04<00:16,  1.03s/it, loss=0.6840, gradTraining Epoch 1/5:  21%|2| 4/19 [00:04<00:10,  1.50it/s, loss=0.6840, gradTraining Epoch 1/5:  21%|2| 4/19 [00:04<00:10,  1.50it/s, loss=0.6829, gradTraining Epoch 1/5:  26%|2| 5/19 [00:04<00:06,  2.14it/s, loss=0.6829, gradTraining Epoch 1/5:  26%|2| 5/19 [00:04<00:06,  2.14it/s, loss=0.6832, gradTraining Epoch 1/5:  32%|3| 6/19 [00:04<00:04,  2.88it/s, loss=0.6832, gradTraining Epoch 1/5:  32%|3| 6/19 [00:04<00:04,  2.88it/s, loss=0.6818, gradTraining Epoch 1/5:  37%|3| 7/19 [00:04<00:03,  3.69it/s, loss=0.6818, gradTraining Epoch 1/5:  37%|3| 7/19 [00:05<00:03,  3.69it/s, loss=0.6888, gradTraining Epoch 1/5:  42%|4| 8/19 [00:05<00:02,  4.52it/s, loss=0.6888, gradTraining Epoch 1/5:  42%|4| 8/19 [00:05<00:02,  4.52it/s, loss=0.7014, gradTraining Epoch 1/5:  47%|4| 9/19 [00:05<00:01,  5.32it/s, loss=0.7014, gradTraining Epoch 1/5:  47%|4| 9/19 [00:05<00:01,  5.32it/s, loss=0.6877, gradTraining Epoch 1/5:  53%|5| 10/19 [00:05<00:01,  6.04it/s, loss=0.6877, graTraining Epoch 1/5:  53%|5| 10/19 [00:05<00:01,  6.04it/s, loss=0.6769, graTraining Epoch 1/5:  58%|5| 11/19 [00:05<00:01,  6.69it/s, loss=0.6769, graTraining Epoch 1/5:  58%|5| 11/19 [00:05<00:01,  6.69it/s, loss=0.6587, graTraining Epoch 1/5:  63%|6| 12/19 [00:05<00:00,  7.18it/s, loss=0.6587, graTraining Epoch 1/5:  63%|6| 12/19 [00:05<00:00,  7.18it/s, loss=0.6514, graTraining Epoch 1/5:  68%|6| 13/19 [00:05<00:00,  7.54it/s, loss=0.6514, graTraining Epoch 1/5:  68%|6| 13/19 [00:05<00:00,  7.54it/s, loss=0.6719, graTraining Epoch 1/5:  74%|7| 14/19 [00:05<00:00,  7.82it/s, loss=0.6719, graTraining Epoch 1/5:  74%|7| 14/19 [00:05<00:00,  7.82it/s, loss=0.6590, graTraining Epoch 1/5:  79%|7| 15/19 [00:05<00:00,  8.16it/s, loss=0.6590, graTraining Epoch 1/5:  79%|7| 15/19 [00:05<00:00,  8.16it/s, loss=0.6840, graTraining Epoch 1/5:  84%|8| 16/19 [00:05<00:00,  8.39it/s, loss=0.6840, graTraining Epoch 1/5:  84%|8| 16/19 [00:06<00:00,  8.39it/s, loss=0.6741, graTraining Epoch 1/5:  89%|8| 17/19 [00:06<00:00,  8.48it/s, loss=0.6741, graTraining Epoch 1/5:  89%|8| 17/19 [00:06<00:00,  8.48it/s, loss=0.6941, graTraining Epoch 1/5:  95%|9| 18/19 [00:06<00:00,  8.58it/s, loss=0.6941, graTraining Epoch 1/5:  95%|9| 18/19 [00:06<00:00,  8.58it/s, loss=0.6491, graTraining Epoch 1/5: 100%|#| 19/19 [00:06<00:00,  2.79it/s, loss=0.6491, gra

Epoch 1/5 Complete (7.2s) [LR: 0.000010]
Train - Loss: 0.6786, Acc: 0.6463, Precision: 0.6000, Recall: 0.8776, F1: 0.7127, AUC: 0.6999
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/19 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/19 [00:04<?, ?it/s, loss=0.6537, grad_norm=1.Training Epoch 2/5:   5%| | 1/19 [00:04<01:13,  4.08s/it, loss=0.6537, gradTraining Epoch 2/5:   5%| | 1/19 [00:04<01:13,  4.08s/it, loss=0.6704, gradTraining Epoch 2/5:  11%|1| 2/19 [00:04<00:29,  1.75s/it, loss=0.6704, gradTraining Epoch 2/5:  11%|1| 2/19 [00:04<00:29,  1.75s/it, loss=0.6489, gradTraining Epoch 2/5:  16%|1| 3/19 [00:04<00:16,  1.01s/it, loss=0.6489, gradTraining Epoch 2/5:  16%|1| 3/19 [00:04<00:16,  1.01s/it, loss=0.6113, gradTraining Epoch 2/5:  21%|2| 4/19 [00:04<00:09,  1.53it/s, loss=0.6113, gradTraining Epoch 2/5:  21%|2| 4/19 [00:04<00:09,  1.53it/s, loss=0.6525, gradTraining Epoch 2/5:  26%|2| 5/19 [00:04<00:06,  2.18it/s, loss=0.6525, gradTraining Epoch 2/5:  26%|2| 5/19 [00:04<00:06,  2.18it/s, loss=0.6061, gradTraining Epoch 2/5:  32%|3| 6/19 [00:04<00:04,  2.94it/s, loss=0.6061, gradTraining Epoch 2/5:  32%|3| 6/19 [00:04<00:04,  2.94it/s, loss=0.6502, gradTraining Epoch 2/5:  37%|3| 7/19 [00:04<00:03,  3.76it/s, loss=0.6502, gradTraining Epoch 2/5:  37%|3| 7/19 [00:04<00:03,  3.76it/s, loss=0.6302, gradTraining Epoch 2/5:  42%|4| 8/19 [00:04<00:02,  4.61it/s, loss=0.6302, gradTraining Epoch 2/5:  42%|4| 8/19 [00:04<00:02,  4.61it/s, loss=0.6365, gradTraining Epoch 2/5:  47%|4| 9/19 [00:04<00:01,  5.44it/s, loss=0.6365, gradTraining Epoch 2/5:  47%|4| 9/19 [00:05<00:01,  5.44it/s, loss=0.6882, gradTraining Epoch 2/5:  53%|5| 10/19 [00:05<00:01,  6.18it/s, loss=0.6882, graTraining Epoch 2/5:  53%|5| 10/19 [00:05<00:01,  6.18it/s, loss=0.6777, graTraining Epoch 2/5:  58%|5| 11/19 [00:05<00:01,  6.81it/s, loss=0.6777, graTraining Epoch 2/5:  58%|5| 11/19 [00:05<00:01,  6.81it/s, loss=0.6449, graTraining Epoch 2/5:  63%|6| 12/19 [00:05<00:00,  7.32it/s, loss=0.6449, graTraining Epoch 2/5:  63%|6| 12/19 [00:05<00:00,  7.32it/s, loss=0.6918, graTraining Epoch 2/5:  68%|6| 13/19 [00:05<00:00,  7.72it/s, loss=0.6918, graTraining Epoch 2/5:  68%|6| 13/19 [00:05<00:00,  7.72it/s, loss=0.6481, graTraining Epoch 2/5:  74%|7| 14/19 [00:05<00:00,  8.05it/s, loss=0.6481, graTraining Epoch 2/5:  74%|7| 14/19 [00:05<00:00,  8.05it/s, loss=0.6416, graTraining Epoch 2/5:  79%|7| 15/19 [00:05<00:00,  8.33it/s, loss=0.6416, graTraining Epoch 2/5:  79%|7| 15/19 [00:05<00:00,  8.33it/s, loss=0.5676, graTraining Epoch 2/5:  84%|8| 16/19 [00:05<00:00,  8.48it/s, loss=0.5676, graTraining Epoch 2/5:  84%|8| 16/19 [00:05<00:00,  8.48it/s, loss=0.5861, graTraining Epoch 2/5:  89%|8| 17/19 [00:05<00:00,  8.59it/s, loss=0.5861, graTraining Epoch 2/5:  89%|8| 17/19 [00:06<00:00,  8.59it/s, loss=0.6132, graTraining Epoch 2/5:  95%|9| 18/19 [00:06<00:00,  8.71it/s, loss=0.6132, graTraining Epoch 2/5:  95%|9| 18/19 [00:06<00:00,  8.71it/s, loss=0.5539, graTraining Epoch 2/5: 100%|#| 19/19 [00:06<00:00,  2.86it/s, loss=0.5539, gra

Epoch 2/5 Complete (7.0s) [LR: 0.000010]
Train - Loss: 0.6354, Acc: 0.7279, Precision: 0.6718, Recall: 0.8912, F1: 0.7661, AUC: 0.7406
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/19 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/19 [00:04<?, ?it/s, loss=0.6387, grad_norm=1.Training Epoch 3/5:   5%| | 1/19 [00:04<01:13,  4.07s/it, loss=0.6387, gradTraining Epoch 3/5:   5%| | 1/19 [00:04<01:13,  4.07s/it, loss=0.6582, gradTraining Epoch 3/5:  11%|1| 2/19 [00:04<00:29,  1.74s/it, loss=0.6582, gradTraining Epoch 3/5:  11%|1| 2/19 [00:04<00:29,  1.74s/it, loss=0.6147, gradTraining Epoch 3/5:  16%|1| 3/19 [00:04<00:16,  1.00s/it, loss=0.6147, gradTraining Epoch 3/5:  16%|1| 3/19 [00:04<00:16,  1.00s/it, loss=0.6537, gradTraining Epoch 3/5:  21%|2| 4/19 [00:04<00:09,  1.54it/s, loss=0.6537, gradTraining Epoch 3/5:  21%|2| 4/19 [00:04<00:09,  1.54it/s, loss=0.5686, gradTraining Epoch 3/5:  26%|2| 5/19 [00:04<00:06,  2.19it/s, loss=0.5686, gradTraining Epoch 3/5:  26%|2| 5/19 [00:04<00:06,  2.19it/s, loss=0.5695, gradTraining Epoch 3/5:  32%|3| 6/19 [00:04<00:04,  2.95it/s, loss=0.5695, gradTraining Epoch 3/5:  32%|3| 6/19 [00:04<00:04,  2.95it/s, loss=0.5916, gradTraining Epoch 3/5:  37%|3| 7/19 [00:04<00:03,  3.77it/s, loss=0.5916, gradTraining Epoch 3/5:  37%|3| 7/19 [00:04<00:03,  3.77it/s, loss=0.5164, gradTraining Epoch 3/5:  42%|4| 8/19 [00:04<00:02,  4.62it/s, loss=0.5164, gradTraining Epoch 3/5:  42%|4| 8/19 [00:04<00:02,  4.62it/s, loss=0.6255, gradTraining Epoch 3/5:  47%|4| 9/19 [00:04<00:01,  5.45it/s, loss=0.6255, gradTraining Epoch 3/5:  47%|4| 9/19 [00:05<00:01,  5.45it/s, loss=0.6653, gradTraining Epoch 3/5:  53%|5| 10/19 [00:05<00:01,  6.19it/s, loss=0.6653, graTraining Epoch 3/5:  53%|5| 10/19 [00:05<00:01,  6.19it/s, loss=0.5197, graTraining Epoch 3/5:  58%|5| 11/19 [00:05<00:01,  6.83it/s, loss=0.5197, graTraining Epoch 3/5:  58%|5| 11/19 [00:05<00:01,  6.83it/s, loss=0.6452, graTraining Epoch 3/5:  63%|6| 12/19 [00:05<00:00,  7.33it/s, loss=0.6452, graTraining Epoch 3/5:  63%|6| 12/19 [00:05<00:00,  7.33it/s, loss=0.5625, graTraining Epoch 3/5:  68%|6| 13/19 [00:05<00:00,  7.72it/s, loss=0.5625, graTraining Epoch 3/5:  68%|6| 13/19 [00:05<00:00,  7.72it/s, loss=0.5545, graTraining Epoch 3/5:  74%|7| 14/19 [00:05<00:00,  8.01it/s, loss=0.5545, graTraining Epoch 3/5:  74%|7| 14/19 [00:05<00:00,  8.01it/s, loss=0.5469, graTraining Epoch 3/5:  79%|7| 15/19 [00:05<00:00,  8.27it/s, loss=0.5469, graTraining Epoch 3/5:  79%|7| 15/19 [00:05<00:00,  8.27it/s, loss=0.6412, graTraining Epoch 3/5:  84%|8| 16/19 [00:05<00:00,  8.47it/s, loss=0.6412, graTraining Epoch 3/5:  84%|8| 16/19 [00:05<00:00,  8.47it/s, loss=0.5246, graTraining Epoch 3/5:  89%|8| 17/19 [00:05<00:00,  8.61it/s, loss=0.5246, graTraining Epoch 3/5:  89%|8| 17/19 [00:05<00:00,  8.61it/s, loss=0.5025, graTraining Epoch 3/5:  95%|9| 18/19 [00:05<00:00,  8.65it/s, loss=0.5025, graTraining Epoch 3/5:  95%|9| 18/19 [00:06<00:00,  8.65it/s, loss=0.3972, graTraining Epoch 3/5: 100%|#| 19/19 [00:06<00:00,  2.87it/s, loss=0.3972, gra

Epoch 3/5 Complete (7.0s) [LR: 0.000010]
Train - Loss: 0.5788, Acc: 0.7313, Precision: 0.6717, Recall: 0.9048, F1: 0.7710, AUC: 0.7756
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/19 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/19 [00:04<?, ?it/s, loss=0.5080, grad_norm=1.Training Epoch 4/5:   5%| | 1/19 [00:04<01:13,  4.06s/it, loss=0.5080, gradTraining Epoch 4/5:   5%| | 1/19 [00:04<01:13,  4.06s/it, loss=0.4817, gradTraining Epoch 4/5:  11%|1| 2/19 [00:04<00:29,  1.74s/it, loss=0.4817, gradTraining Epoch 4/5:  11%|1| 2/19 [00:04<00:29,  1.74s/it, loss=0.4312, gradTraining Epoch 4/5:  16%|1| 3/19 [00:04<00:15,  1.00it/s, loss=0.4312, gradTraining Epoch 4/5:  16%|1| 3/19 [00:04<00:15,  1.00it/s, loss=0.5118, gradTraining Epoch 4/5:  21%|2| 4/19 [00:04<00:09,  1.54it/s, loss=0.5118, gradTraining Epoch 4/5:  21%|2| 4/19 [00:04<00:09,  1.54it/s, loss=0.5061, gradTraining Epoch 4/5:  26%|2| 5/19 [00:04<00:06,  2.19it/s, loss=0.5061, gradTraining Epoch 4/5:  26%|2| 5/19 [00:04<00:06,  2.19it/s, loss=0.6576, gradTraining Epoch 4/5:  32%|3| 6/19 [00:04<00:04,  2.94it/s, loss=0.6576, gradTraining Epoch 4/5:  32%|3| 6/19 [00:04<00:04,  2.94it/s, loss=0.5622, gradTraining Epoch 4/5:  37%|3| 7/19 [00:04<00:03,  3.75it/s, loss=0.5622, gradTraining Epoch 4/5:  37%|3| 7/19 [00:04<00:03,  3.75it/s, loss=0.6418, gradTraining Epoch 4/5:  42%|4| 8/19 [00:04<00:02,  4.57it/s, loss=0.6418, gradTraining Epoch 4/5:  42%|4| 8/19 [00:04<00:02,  4.57it/s, loss=0.5461, gradTraining Epoch 4/5:  47%|4| 9/19 [00:04<00:01,  5.38it/s, loss=0.5461, gradTraining Epoch 4/5:  47%|4| 9/19 [00:05<00:01,  5.38it/s, loss=0.5508, gradTraining Epoch 4/5:  53%|5| 10/19 [00:05<00:01,  6.08it/s, loss=0.5508, graTraining Epoch 4/5:  53%|5| 10/19 [00:05<00:01,  6.08it/s, loss=0.5567, graTraining Epoch 4/5:  58%|5| 11/19 [00:05<00:01,  6.72it/s, loss=0.5567, graTraining Epoch 4/5:  58%|5| 11/19 [00:05<00:01,  6.72it/s, loss=0.5446, graTraining Epoch 4/5:  63%|6| 12/19 [00:05<00:00,  7.15it/s, loss=0.5446, graTraining Epoch 4/5:  63%|6| 12/19 [00:05<00:00,  7.15it/s, loss=0.6186, graTraining Epoch 4/5:  68%|6| 13/19 [00:05<00:00,  7.56it/s, loss=0.6186, graTraining Epoch 4/5:  68%|6| 13/19 [00:05<00:00,  7.56it/s, loss=0.4778, graTraining Epoch 4/5:  74%|7| 14/19 [00:05<00:00,  7.88it/s, loss=0.4778, graTraining Epoch 4/5:  74%|7| 14/19 [00:05<00:00,  7.88it/s, loss=0.4771, graTraining Epoch 4/5:  79%|7| 15/19 [00:05<00:00,  8.13it/s, loss=0.4771, graTraining Epoch 4/5:  79%|7| 15/19 [00:05<00:00,  8.13it/s, loss=0.4476, graTraining Epoch 4/5:  84%|8| 16/19 [00:05<00:00,  8.33it/s, loss=0.4476, graTraining Epoch 4/5:  84%|8| 16/19 [00:05<00:00,  8.33it/s, loss=0.4621, graTraining Epoch 4/5:  89%|8| 17/19 [00:05<00:00,  8.44it/s, loss=0.4621, graTraining Epoch 4/5:  89%|8| 17/19 [00:06<00:00,  8.44it/s, loss=0.4579, graTraining Epoch 4/5:  95%|9| 18/19 [00:06<00:00,  8.49it/s, loss=0.4579, graTraining Epoch 4/5:  95%|9| 18/19 [00:06<00:00,  8.49it/s, loss=0.4788, graTraining Epoch 4/5: 100%|#| 19/19 [00:06<00:00,  2.85it/s, loss=0.4788, gra

Epoch 4/5 Complete (7.1s) [LR: 0.000010]
Train - Loss: 0.5220, Acc: 0.7517, Precision: 0.6850, Recall: 0.9320, F1: 0.7896, AUC: 0.8031
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/19 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/19 [00:04<?, ?it/s, loss=0.4034, grad_norm=1.Training Epoch 5/5:   5%| | 1/19 [00:04<01:12,  4.03s/it, loss=0.4034, gradTraining Epoch 5/5:   5%| | 1/19 [00:04<01:12,  4.03s/it, loss=0.5969, gradTraining Epoch 5/5:  11%|1| 2/19 [00:04<00:29,  1.73s/it, loss=0.5969, gradTraining Epoch 5/5:  11%|1| 2/19 [00:04<00:29,  1.73s/it, loss=0.5256, gradTraining Epoch 5/5:  16%|1| 3/19 [00:04<00:15,  1.01it/s, loss=0.5256, gradTraining Epoch 5/5:  16%|1| 3/19 [00:04<00:15,  1.01it/s, loss=0.3826, gradTraining Epoch 5/5:  21%|2| 4/19 [00:04<00:09,  1.55it/s, loss=0.3826, gradTraining Epoch 5/5:  21%|2| 4/19 [00:04<00:09,  1.55it/s, loss=0.4558, gradTraining Epoch 5/5:  26%|2| 5/19 [00:04<00:06,  2.20it/s, loss=0.4558, gradTraining Epoch 5/5:  26%|2| 5/19 [00:04<00:06,  2.20it/s, loss=0.4453, gradTraining Epoch 5/5:  32%|3| 6/19 [00:04<00:04,  2.95it/s, loss=0.4453, gradTraining Epoch 5/5:  32%|3| 6/19 [00:04<00:04,  2.95it/s, loss=0.4242, gradTraining Epoch 5/5:  37%|3| 7/19 [00:04<00:03,  3.76it/s, loss=0.4242, gradTraining Epoch 5/5:  37%|3| 7/19 [00:04<00:03,  3.76it/s, loss=0.5516, gradTraining Epoch 5/5:  42%|4| 8/19 [00:04<00:02,  4.60it/s, loss=0.5516, gradTraining Epoch 5/5:  42%|4| 8/19 [00:04<00:02,  4.60it/s, loss=0.3465, gradTraining Epoch 5/5:  47%|4| 9/19 [00:04<00:01,  5.38it/s, loss=0.3465, gradTraining Epoch 5/5:  47%|4| 9/19 [00:05<00:01,  5.38it/s, loss=0.4316, gradTraining Epoch 5/5:  53%|5| 10/19 [00:05<00:01,  6.09it/s, loss=0.4316, graTraining Epoch 5/5:  53%|5| 10/19 [00:05<00:01,  6.09it/s, loss=0.7479, graTraining Epoch 5/5:  58%|5| 11/19 [00:05<00:01,  6.69it/s, loss=0.7479, graTraining Epoch 5/5:  58%|5| 11/19 [00:05<00:01,  6.69it/s, loss=0.3973, graTraining Epoch 5/5:  63%|6| 12/19 [00:05<00:00,  7.16it/s, loss=0.3973, graTraining Epoch 5/5:  63%|6| 12/19 [00:05<00:00,  7.16it/s, loss=0.4125, graTraining Epoch 5/5:  68%|6| 13/19 [00:05<00:00,  7.41it/s, loss=0.4125, graTraining Epoch 5/5:  68%|6| 13/19 [00:05<00:00,  7.41it/s, loss=0.4479, graTraining Epoch 5/5:  74%|7| 14/19 [00:05<00:00,  7.77it/s, loss=0.4479, graTraining Epoch 5/5:  74%|7| 14/19 [00:05<00:00,  7.77it/s, loss=0.4308, graTraining Epoch 5/5:  79%|7| 15/19 [00:05<00:00,  8.06it/s, loss=0.4308, graTraining Epoch 5/5:  79%|7| 15/19 [00:05<00:00,  8.06it/s, loss=0.2963, graTraining Epoch 5/5:  84%|8| 16/19 [00:05<00:00,  8.21it/s, loss=0.2963, graTraining Epoch 5/5:  84%|8| 16/19 [00:05<00:00,  8.21it/s, loss=0.6379, graTraining Epoch 5/5:  89%|8| 17/19 [00:05<00:00,  8.34it/s, loss=0.6379, graTraining Epoch 5/5:  89%|8| 17/19 [00:06<00:00,  8.34it/s, loss=0.4417, graTraining Epoch 5/5:  95%|9| 18/19 [00:06<00:00,  8.43it/s, loss=0.4417, graTraining Epoch 5/5:  95%|9| 18/19 [00:06<00:00,  8.43it/s, loss=0.6914, graTraining Epoch 5/5: 100%|#| 19/19 [00:06<00:00,  2.86it/s, loss=0.6914, gra

Epoch 5/5 Complete (7.0s) [LR: 0.000005]
Train - Loss: 0.4772, Acc: 0.7993, Precision: 0.7683, Recall: 0.8571, F1: 0.8103, AUC: 0.8864
------------------------------------------------------------
Training curves saved to model\chb06_fold5\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.6 minutes
Models saved in: model\chb06_fold5
============================================================
✅ Fold 5 training completed successfully!

============================================================
TRAINING FOLD 6/9
============================================================
Using dataset prefix: chb06_fold6
Loading datasets from: preprocessing\data\chb06_fold6
Saving models to: model\chb06_fold6
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=1.2299, std=2.5478
Loaded train dataset: 276 samples
  - Spectrogram shape: torch.Size([276, 30, 18, 50, 10])
  - Value range: [-5.1927, 3.1525]
  - Class distribution: tensor([138, 138])
LOOCV Mode (Fold 6): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6935, grad_norm=1.Training Epoch 1/5:   6%| | 1/18 [00:04<01:09,  4.10s/it, loss=0.6935, gradTraining Epoch 1/5:   6%| | 1/18 [00:04<01:09,  4.10s/it, loss=0.6875, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:28,  1.76s/it, loss=0.6875, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:28,  1.76s/it, loss=0.6979, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.01s/it, loss=0.6979, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.01s/it, loss=0.6805, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.53it/s, loss=0.6805, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.53it/s, loss=0.7047, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.7047, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.6976, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.93it/s, loss=0.6976, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.93it/s, loss=0.6789, gradTraining Epoch 1/5:  39%|3| 7/18 [00:04<00:02,  3.75it/s, loss=0.6789, gradTraining Epoch 1/5:  39%|3| 7/18 [00:04<00:02,  3.75it/s, loss=0.6805, gradTraining Epoch 1/5:  44%|4| 8/18 [00:04<00:02,  4.59it/s, loss=0.6805, gradTraining Epoch 1/5:  44%|4| 8/18 [00:05<00:02,  4.59it/s, loss=0.6839, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  5.37it/s, loss=0.6839, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  5.37it/s, loss=0.6749, gradTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  6.08it/s, loss=0.6749, graTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  6.08it/s, loss=0.6821, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  6.77it/s, loss=0.6821, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  6.77it/s, loss=0.6619, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:00,  7.29it/s, loss=0.6619, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:00,  7.29it/s, loss=0.6913, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  7.65it/s, loss=0.6913, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  7.65it/s, loss=0.6711, graTraining Epoch 1/5:  78%|7| 14/18 [00:05<00:00,  7.94it/s, loss=0.6711, graTraining Epoch 1/5:  78%|7| 14/18 [00:05<00:00,  7.94it/s, loss=0.6734, graTraining Epoch 1/5:  83%|8| 15/18 [00:05<00:00,  8.21it/s, loss=0.6734, graTraining Epoch 1/5:  83%|8| 15/18 [00:05<00:00,  8.21it/s, loss=0.6737, graTraining Epoch 1/5:  89%|8| 16/18 [00:05<00:00,  8.37it/s, loss=0.6737, graTraining Epoch 1/5:  89%|8| 16/18 [00:05<00:00,  8.37it/s, loss=0.6823, graTraining Epoch 1/5:  94%|9| 17/18 [00:05<00:00,  8.47it/s, loss=0.6823, graTraining Epoch 1/5:  94%|9| 17/18 [00:05<00:00,  8.47it/s, loss=0.7416, graTraining Epoch 1/5: 100%|#| 18/18 [00:06<00:00,  2.74it/s, loss=0.7416, gra

Epoch 1/5 Complete (7.0s) [LR: 0.000010]
Train - Loss: 0.6865, Acc: 0.6196, Precision: 0.6410, Recall: 0.5435, F1: 0.5882, AUC: 0.6665
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6744, grad_norm=1.Training Epoch 2/5:   6%| | 1/18 [00:04<01:09,  4.07s/it, loss=0.6744, gradTraining Epoch 2/5:   6%| | 1/18 [00:04<01:09,  4.07s/it, loss=0.6779, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:27,  1.75s/it, loss=0.6779, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:27,  1.75s/it, loss=0.6696, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:15,  1.00s/it, loss=0.6696, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:15,  1.00s/it, loss=0.6753, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:09,  1.54it/s, loss=0.6753, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:09,  1.54it/s, loss=0.6774, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:05,  2.19it/s, loss=0.6774, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:05,  2.19it/s, loss=0.6560, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.93it/s, loss=0.6560, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.93it/s, loss=0.6518, gradTraining Epoch 2/5:  39%|3| 7/18 [00:04<00:02,  3.75it/s, loss=0.6518, gradTraining Epoch 2/5:  39%|3| 7/18 [00:04<00:02,  3.75it/s, loss=0.6968, gradTraining Epoch 2/5:  44%|4| 8/18 [00:04<00:02,  4.60it/s, loss=0.6968, gradTraining Epoch 2/5:  44%|4| 8/18 [00:04<00:02,  4.60it/s, loss=0.6641, gradTraining Epoch 2/5:  50%|5| 9/18 [00:04<00:01,  5.38it/s, loss=0.6641, gradTraining Epoch 2/5:  50%|5| 9/18 [00:05<00:01,  5.38it/s, loss=0.6687, gradTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  6.10it/s, loss=0.6687, graTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  6.10it/s, loss=0.6708, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.76it/s, loss=0.6708, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.76it/s, loss=0.6553, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  7.28it/s, loss=0.6553, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  7.28it/s, loss=0.6381, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  7.63it/s, loss=0.6381, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  7.63it/s, loss=0.6420, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  7.93it/s, loss=0.6420, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  7.93it/s, loss=0.6147, graTraining Epoch 2/5:  83%|8| 15/18 [00:05<00:00,  8.18it/s, loss=0.6147, graTraining Epoch 2/5:  83%|8| 15/18 [00:05<00:00,  8.18it/s, loss=0.6541, graTraining Epoch 2/5:  89%|8| 16/18 [00:05<00:00,  8.33it/s, loss=0.6541, graTraining Epoch 2/5:  89%|8| 16/18 [00:05<00:00,  8.33it/s, loss=0.6218, graTraining Epoch 2/5:  94%|9| 17/18 [00:05<00:00,  8.43it/s, loss=0.6218, graTraining Epoch 2/5:  94%|9| 17/18 [00:05<00:00,  8.43it/s, loss=0.7346, graTraining Epoch 2/5: 100%|#| 18/18 [00:06<00:00,  2.75it/s, loss=0.7346, gra

Epoch 2/5 Complete (6.9s) [LR: 0.000010]
Train - Loss: 0.6635, Acc: 0.6377, Precision: 0.6188, Recall: 0.7174, F1: 0.6644, AUC: 0.6758
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/18 [00:03<?, ?it/s, loss=0.5855, grad_norm=1.Training Epoch 3/5:   6%| | 1/18 [00:03<01:07,  3.97s/it, loss=0.5855, gradTraining Epoch 3/5:   6%| | 1/18 [00:04<01:07,  3.97s/it, loss=0.5820, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:27,  1.70s/it, loss=0.5820, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:27,  1.70s/it, loss=0.7228, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:14,  1.02it/s, loss=0.7228, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:14,  1.02it/s, loss=0.6125, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:08,  1.57it/s, loss=0.6125, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:08,  1.57it/s, loss=0.5933, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:05,  2.22it/s, loss=0.5933, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:05,  2.22it/s, loss=0.6534, gradTraining Epoch 3/5:  33%|3| 6/18 [00:04<00:04,  2.99it/s, loss=0.6534, gradTraining Epoch 3/5:  33%|3| 6/18 [00:04<00:04,  2.99it/s, loss=0.5961, gradTraining Epoch 3/5:  39%|3| 7/18 [00:04<00:02,  3.82it/s, loss=0.5961, gradTraining Epoch 3/5:  39%|3| 7/18 [00:04<00:02,  3.82it/s, loss=0.6496, gradTraining Epoch 3/5:  44%|4| 8/18 [00:04<00:02,  4.66it/s, loss=0.6496, gradTraining Epoch 3/5:  44%|4| 8/18 [00:04<00:02,  4.66it/s, loss=0.6317, gradTraining Epoch 3/5:  50%|5| 9/18 [00:04<00:01,  5.46it/s, loss=0.6317, gradTraining Epoch 3/5:  50%|5| 9/18 [00:05<00:01,  5.46it/s, loss=0.6412, gradTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  6.16it/s, loss=0.6412, graTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  6.16it/s, loss=0.6097, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  6.75it/s, loss=0.6097, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  6.75it/s, loss=0.6662, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:00,  7.29it/s, loss=0.6662, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:00,  7.29it/s, loss=0.5698, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  7.63it/s, loss=0.5698, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  7.63it/s, loss=0.5462, graTraining Epoch 3/5:  78%|7| 14/18 [00:05<00:00,  7.98it/s, loss=0.5462, graTraining Epoch 3/5:  78%|7| 14/18 [00:05<00:00,  7.98it/s, loss=0.5878, graTraining Epoch 3/5:  83%|8| 15/18 [00:05<00:00,  8.20it/s, loss=0.5878, graTraining Epoch 3/5:  83%|8| 15/18 [00:05<00:00,  8.20it/s, loss=0.6079, graTraining Epoch 3/5:  89%|8| 16/18 [00:05<00:00,  8.39it/s, loss=0.6079, graTraining Epoch 3/5:  89%|8| 16/18 [00:05<00:00,  8.39it/s, loss=0.5976, graTraining Epoch 3/5:  94%|9| 17/18 [00:05<00:00,  8.54it/s, loss=0.5976, graTraining Epoch 3/5:  94%|9| 17/18 [00:05<00:00,  8.54it/s, loss=0.4504, graTraining Epoch 3/5: 100%|#| 18/18 [00:06<00:00,  2.80it/s, loss=0.4504, gra

Epoch 3/5 Complete (6.8s) [LR: 0.000010]
Train - Loss: 0.6058, Acc: 0.6920, Precision: 0.6359, Recall: 0.8986, F1: 0.7447, AUC: 0.7385
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6108, grad_norm=1.Training Epoch 4/5:   6%| | 1/18 [00:04<01:09,  4.09s/it, loss=0.6108, gradTraining Epoch 4/5:   6%| | 1/18 [00:04<01:09,  4.09s/it, loss=0.6655, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:28,  1.76s/it, loss=0.6655, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:28,  1.76s/it, loss=0.5136, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:15,  1.01s/it, loss=0.5136, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:15,  1.01s/it, loss=0.5506, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.52it/s, loss=0.5506, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.52it/s, loss=0.5540, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:05,  2.17it/s, loss=0.5540, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:05,  2.17it/s, loss=0.5514, gradTraining Epoch 4/5:  33%|3| 6/18 [00:04<00:04,  2.91it/s, loss=0.5514, gradTraining Epoch 4/5:  33%|3| 6/18 [00:04<00:04,  2.91it/s, loss=0.5274, gradTraining Epoch 4/5:  39%|3| 7/18 [00:04<00:02,  3.72it/s, loss=0.5274, gradTraining Epoch 4/5:  39%|3| 7/18 [00:04<00:02,  3.72it/s, loss=0.5900, gradTraining Epoch 4/5:  44%|4| 8/18 [00:04<00:02,  4.57it/s, loss=0.5900, gradTraining Epoch 4/5:  44%|4| 8/18 [00:05<00:02,  4.57it/s, loss=0.5175, gradTraining Epoch 4/5:  50%|5| 9/18 [00:05<00:01,  5.41it/s, loss=0.5175, gradTraining Epoch 4/5:  50%|5| 9/18 [00:05<00:01,  5.41it/s, loss=0.5419, gradTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  6.16it/s, loss=0.5419, graTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  6.16it/s, loss=0.6147, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.81it/s, loss=0.6147, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.81it/s, loss=0.5495, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  7.26it/s, loss=0.5495, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  7.26it/s, loss=0.7376, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  7.69it/s, loss=0.7376, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  7.69it/s, loss=0.6002, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  8.00it/s, loss=0.6002, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  8.00it/s, loss=0.4079, graTraining Epoch 4/5:  83%|8| 15/18 [00:05<00:00,  8.27it/s, loss=0.4079, graTraining Epoch 4/5:  83%|8| 15/18 [00:05<00:00,  8.27it/s, loss=0.5368, graTraining Epoch 4/5:  89%|8| 16/18 [00:05<00:00,  8.48it/s, loss=0.5368, graTraining Epoch 4/5:  89%|8| 16/18 [00:05<00:00,  8.48it/s, loss=0.5944, graTraining Epoch 4/5:  94%|9| 17/18 [00:05<00:00,  8.65it/s, loss=0.5944, graTraining Epoch 4/5:  94%|9| 17/18 [00:05<00:00,  8.65it/s, loss=0.7832, graTraining Epoch 4/5: 100%|#| 18/18 [00:06<00:00,  2.75it/s, loss=0.7832, gra

Epoch 4/5 Complete (6.9s) [LR: 0.000010]
Train - Loss: 0.5804, Acc: 0.6993, Precision: 0.6396, Recall: 0.9130, F1: 0.7522, AUC: 0.7409
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/18 [00:03<?, ?it/s, loss=0.4499, grad_norm=1.Training Epoch 5/5:   6%| | 1/18 [00:03<01:07,  4.00s/it, loss=0.4499, gradTraining Epoch 5/5:   6%| | 1/18 [00:04<01:07,  4.00s/it, loss=0.4581, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:27,  1.72s/it, loss=0.4581, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:27,  1.72s/it, loss=0.5132, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:14,  1.02it/s, loss=0.5132, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:14,  1.02it/s, loss=0.5640, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:08,  1.57it/s, loss=0.5640, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:08,  1.57it/s, loss=0.5359, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:05,  2.23it/s, loss=0.5359, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:05,  2.23it/s, loss=0.5325, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.98it/s, loss=0.5325, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.98it/s, loss=0.5661, gradTraining Epoch 5/5:  39%|3| 7/18 [00:04<00:02,  3.82it/s, loss=0.5661, gradTraining Epoch 5/5:  39%|3| 7/18 [00:04<00:02,  3.82it/s, loss=0.4732, gradTraining Epoch 5/5:  44%|4| 8/18 [00:04<00:02,  4.68it/s, loss=0.4732, gradTraining Epoch 5/5:  44%|4| 8/18 [00:04<00:02,  4.68it/s, loss=0.6095, gradTraining Epoch 5/5:  50%|5| 9/18 [00:04<00:01,  5.47it/s, loss=0.6095, gradTraining Epoch 5/5:  50%|5| 9/18 [00:05<00:01,  5.47it/s, loss=0.4966, gradTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  6.21it/s, loss=0.4966, graTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  6.21it/s, loss=0.5339, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  6.88it/s, loss=0.5339, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  6.88it/s, loss=0.4832, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  7.39it/s, loss=0.4832, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  7.39it/s, loss=0.6020, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  7.77it/s, loss=0.6020, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  7.77it/s, loss=0.5805, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  8.07it/s, loss=0.5805, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  8.07it/s, loss=0.5083, graTraining Epoch 5/5:  83%|8| 15/18 [00:05<00:00,  8.32it/s, loss=0.5083, graTraining Epoch 5/5:  83%|8| 15/18 [00:05<00:00,  8.32it/s, loss=0.5697, graTraining Epoch 5/5:  89%|8| 16/18 [00:05<00:00,  8.47it/s, loss=0.5697, graTraining Epoch 5/5:  89%|8| 16/18 [00:05<00:00,  8.47it/s, loss=0.5071, graTraining Epoch 5/5:  94%|9| 17/18 [00:05<00:00,  8.61it/s, loss=0.5071, graTraining Epoch 5/5:  94%|9| 17/18 [00:05<00:00,  8.61it/s, loss=0.7864, graTraining Epoch 5/5: 100%|#| 18/18 [00:06<00:00,  2.81it/s, loss=0.7864, gra

Epoch 5/5 Complete (6.8s) [LR: 0.000005]
Train - Loss: 0.5428, Acc: 0.7319, Precision: 0.6600, Recall: 0.9565, F1: 0.7811, AUC: 0.7784
------------------------------------------------------------
Training curves saved to model\chb06_fold6\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.6 minutes
Models saved in: model\chb06_fold6
============================================================
✅ Fold 6 training completed successfully!

============================================================
TRAINING FOLD 7/9
============================================================
Using dataset prefix: chb06_fold7
Loading datasets from: preprocessing\data\chb06_fold7
Saving models to: model\chb06_fold7
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=1.2923, std=2.5008
Loaded train dataset: 280 samples
  - Spectrogram shape: torch.Size([280, 30, 18, 50, 10])
  - Value range: [-5.3152, 3.2129]
  - Class distribution: tensor([140, 140])
LOOCV Mode (Fold 7): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6911, grad_norm=0.Training Epoch 1/5:   6%| | 1/18 [00:04<01:09,  4.08s/it, loss=0.6911, gradTraining Epoch 1/5:   6%| | 1/18 [00:04<01:09,  4.08s/it, loss=0.6997, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:27,  1.75s/it, loss=0.6997, gradTraining Epoch 1/5:  11%|1| 2/18 [00:04<00:27,  1.75s/it, loss=0.6962, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.00s/it, loss=0.6962, gradTraining Epoch 1/5:  17%|1| 3/18 [00:04<00:15,  1.00s/it, loss=0.6905, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.54it/s, loss=0.6905, gradTraining Epoch 1/5:  22%|2| 4/18 [00:04<00:09,  1.54it/s, loss=0.6904, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.6904, gradTraining Epoch 1/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.6891, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.92it/s, loss=0.6891, gradTraining Epoch 1/5:  33%|3| 6/18 [00:04<00:04,  2.92it/s, loss=0.6866, gradTraining Epoch 1/5:  39%|3| 7/18 [00:04<00:02,  3.73it/s, loss=0.6866, gradTraining Epoch 1/5:  39%|3| 7/18 [00:04<00:02,  3.73it/s, loss=0.6900, gradTraining Epoch 1/5:  44%|4| 8/18 [00:04<00:02,  4.57it/s, loss=0.6900, gradTraining Epoch 1/5:  44%|4| 8/18 [00:04<00:02,  4.57it/s, loss=0.6823, gradTraining Epoch 1/5:  50%|5| 9/18 [00:04<00:01,  5.37it/s, loss=0.6823, gradTraining Epoch 1/5:  50%|5| 9/18 [00:05<00:01,  5.37it/s, loss=0.6912, gradTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  6.09it/s, loss=0.6912, graTraining Epoch 1/5:  56%|5| 10/18 [00:05<00:01,  6.09it/s, loss=0.6815, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  6.69it/s, loss=0.6815, graTraining Epoch 1/5:  61%|6| 11/18 [00:05<00:01,  6.69it/s, loss=0.6766, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:00,  7.27it/s, loss=0.6766, graTraining Epoch 1/5:  67%|6| 12/18 [00:05<00:00,  7.27it/s, loss=0.6825, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  7.51it/s, loss=0.6825, graTraining Epoch 1/5:  72%|7| 13/18 [00:05<00:00,  7.51it/s, loss=0.6735, graTraining Epoch 1/5:  78%|7| 14/18 [00:05<00:00,  7.78it/s, loss=0.6735, graTraining Epoch 1/5:  78%|7| 14/18 [00:05<00:00,  7.78it/s, loss=0.6775, graTraining Epoch 1/5:  83%|8| 15/18 [00:05<00:00,  8.01it/s, loss=0.6775, graTraining Epoch 1/5:  83%|8| 15/18 [00:05<00:00,  8.01it/s, loss=0.6763, graTraining Epoch 1/5:  89%|8| 16/18 [00:05<00:00,  8.22it/s, loss=0.6763, graTraining Epoch 1/5:  89%|8| 16/18 [00:05<00:00,  8.22it/s, loss=0.6900, graTraining Epoch 1/5:  94%|9| 17/18 [00:05<00:00,  8.38it/s, loss=0.6900, graTraining Epoch 1/5:  94%|9| 17/18 [00:06<00:00,  8.38it/s, loss=0.6666, graTraining Epoch 1/5: 100%|#| 18/18 [00:06<00:00,  2.73it/s, loss=0.6666, gra

Epoch 1/5 Complete (7.0s) [LR: 0.000010]
Train - Loss: 0.6851, Acc: 0.5750, Precision: 0.5745, Recall: 0.5786, F1: 0.5765, AUC: 0.6261
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6647, grad_norm=0.Training Epoch 2/5:   6%| | 1/18 [00:04<01:08,  4.03s/it, loss=0.6647, gradTraining Epoch 2/5:   6%| | 1/18 [00:04<01:08,  4.03s/it, loss=0.6540, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:27,  1.73s/it, loss=0.6540, gradTraining Epoch 2/5:  11%|1| 2/18 [00:04<00:27,  1.73s/it, loss=0.6752, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:14,  1.01it/s, loss=0.6752, gradTraining Epoch 2/5:  17%|1| 3/18 [00:04<00:14,  1.01it/s, loss=0.6917, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:09,  1.55it/s, loss=0.6917, gradTraining Epoch 2/5:  22%|2| 4/18 [00:04<00:09,  1.55it/s, loss=0.6797, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:05,  2.21it/s, loss=0.6797, gradTraining Epoch 2/5:  28%|2| 5/18 [00:04<00:05,  2.21it/s, loss=0.6921, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.96it/s, loss=0.6921, gradTraining Epoch 2/5:  33%|3| 6/18 [00:04<00:04,  2.96it/s, loss=0.6632, gradTraining Epoch 2/5:  39%|3| 7/18 [00:04<00:02,  3.78it/s, loss=0.6632, gradTraining Epoch 2/5:  39%|3| 7/18 [00:04<00:02,  3.78it/s, loss=0.6359, gradTraining Epoch 2/5:  44%|4| 8/18 [00:04<00:02,  4.61it/s, loss=0.6359, gradTraining Epoch 2/5:  44%|4| 8/18 [00:04<00:02,  4.61it/s, loss=0.6558, gradTraining Epoch 2/5:  50%|5| 9/18 [00:04<00:01,  5.42it/s, loss=0.6558, gradTraining Epoch 2/5:  50%|5| 9/18 [00:05<00:01,  5.42it/s, loss=0.7085, gradTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  6.13it/s, loss=0.7085, graTraining Epoch 2/5:  56%|5| 10/18 [00:05<00:01,  6.13it/s, loss=0.6386, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.74it/s, loss=0.6386, graTraining Epoch 2/5:  61%|6| 11/18 [00:05<00:01,  6.74it/s, loss=0.6340, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  7.24it/s, loss=0.6340, graTraining Epoch 2/5:  67%|6| 12/18 [00:05<00:00,  7.24it/s, loss=0.6343, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  7.62it/s, loss=0.6343, graTraining Epoch 2/5:  72%|7| 13/18 [00:05<00:00,  7.62it/s, loss=0.6489, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  7.84it/s, loss=0.6489, graTraining Epoch 2/5:  78%|7| 14/18 [00:05<00:00,  7.84it/s, loss=0.6496, graTraining Epoch 2/5:  83%|8| 15/18 [00:05<00:00,  8.11it/s, loss=0.6496, graTraining Epoch 2/5:  83%|8| 15/18 [00:05<00:00,  8.11it/s, loss=0.6073, graTraining Epoch 2/5:  89%|8| 16/18 [00:05<00:00,  8.33it/s, loss=0.6073, graTraining Epoch 2/5:  89%|8| 16/18 [00:05<00:00,  8.33it/s, loss=0.6215, graTraining Epoch 2/5:  94%|9| 17/18 [00:05<00:00,  8.40it/s, loss=0.6215, graTraining Epoch 2/5:  94%|9| 17/18 [00:05<00:00,  8.40it/s, loss=0.6255, graTraining Epoch 2/5: 100%|#| 18/18 [00:06<00:00,  2.76it/s, loss=0.6255, gra

Epoch 2/5 Complete (6.9s) [LR: 0.000010]
Train - Loss: 0.6545, Acc: 0.6821, Precision: 0.6335, Recall: 0.8643, F1: 0.7311, AUC: 0.7219
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6099, grad_norm=0.Training Epoch 3/5:   6%| | 1/18 [00:04<01:09,  4.08s/it, loss=0.6099, gradTraining Epoch 3/5:   6%| | 1/18 [00:04<01:09,  4.08s/it, loss=0.5994, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:28,  1.75s/it, loss=0.5994, gradTraining Epoch 3/5:  11%|1| 2/18 [00:04<00:28,  1.75s/it, loss=0.6228, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:15,  1.00s/it, loss=0.6228, gradTraining Epoch 3/5:  17%|1| 3/18 [00:04<00:15,  1.00s/it, loss=0.6456, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:09,  1.54it/s, loss=0.6456, gradTraining Epoch 3/5:  22%|2| 4/18 [00:04<00:09,  1.54it/s, loss=0.6621, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.6621, gradTraining Epoch 3/5:  28%|2| 5/18 [00:04<00:05,  2.18it/s, loss=0.5758, gradTraining Epoch 3/5:  33%|3| 6/18 [00:04<00:04,  2.92it/s, loss=0.5758, gradTraining Epoch 3/5:  33%|3| 6/18 [00:04<00:04,  2.92it/s, loss=0.5854, gradTraining Epoch 3/5:  39%|3| 7/18 [00:04<00:02,  3.74it/s, loss=0.5854, gradTraining Epoch 3/5:  39%|3| 7/18 [00:04<00:02,  3.74it/s, loss=0.5742, gradTraining Epoch 3/5:  44%|4| 8/18 [00:04<00:02,  4.59it/s, loss=0.5742, gradTraining Epoch 3/5:  44%|4| 8/18 [00:04<00:02,  4.59it/s, loss=0.6702, gradTraining Epoch 3/5:  50%|5| 9/18 [00:04<00:01,  5.40it/s, loss=0.6702, gradTraining Epoch 3/5:  50%|5| 9/18 [00:05<00:01,  5.40it/s, loss=0.5832, gradTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  6.13it/s, loss=0.5832, graTraining Epoch 3/5:  56%|5| 10/18 [00:05<00:01,  6.13it/s, loss=0.5645, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  6.79it/s, loss=0.5645, graTraining Epoch 3/5:  61%|6| 11/18 [00:05<00:01,  6.79it/s, loss=0.7160, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:00,  7.32it/s, loss=0.7160, graTraining Epoch 3/5:  67%|6| 12/18 [00:05<00:00,  7.32it/s, loss=0.6270, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  7.72it/s, loss=0.6270, graTraining Epoch 3/5:  72%|7| 13/18 [00:05<00:00,  7.72it/s, loss=0.5592, graTraining Epoch 3/5:  78%|7| 14/18 [00:05<00:00,  8.00it/s, loss=0.5592, graTraining Epoch 3/5:  78%|7| 14/18 [00:05<00:00,  8.00it/s, loss=0.5559, graTraining Epoch 3/5:  83%|8| 15/18 [00:05<00:00,  8.27it/s, loss=0.5559, graTraining Epoch 3/5:  83%|8| 15/18 [00:05<00:00,  8.27it/s, loss=0.6335, graTraining Epoch 3/5:  89%|8| 16/18 [00:05<00:00,  8.46it/s, loss=0.6335, graTraining Epoch 3/5:  89%|8| 16/18 [00:05<00:00,  8.46it/s, loss=0.5793, graTraining Epoch 3/5:  94%|9| 17/18 [00:05<00:00,  8.46it/s, loss=0.5793, graTraining Epoch 3/5:  94%|9| 17/18 [00:05<00:00,  8.46it/s, loss=0.5617, graTraining Epoch 3/5: 100%|#| 18/18 [00:06<00:00,  2.75it/s, loss=0.5617, gra

Epoch 3/5 Complete (6.9s) [LR: 0.000010]
Train - Loss: 0.6070, Acc: 0.7000, Precision: 0.6386, Recall: 0.9214, F1: 0.7544, AUC: 0.7627
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.6305, grad_norm=1.Training Epoch 4/5:   6%| | 1/18 [00:04<01:10,  4.14s/it, loss=0.6305, gradTraining Epoch 4/5:   6%| | 1/18 [00:04<01:10,  4.14s/it, loss=0.6764, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:28,  1.78s/it, loss=0.6764, gradTraining Epoch 4/5:  11%|1| 2/18 [00:04<00:28,  1.78s/it, loss=0.7247, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:15,  1.02s/it, loss=0.7247, gradTraining Epoch 4/5:  17%|1| 3/18 [00:04<00:15,  1.02s/it, loss=0.5610, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.50it/s, loss=0.5610, gradTraining Epoch 4/5:  22%|2| 4/18 [00:04<00:09,  1.50it/s, loss=0.5781, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:06,  2.14it/s, loss=0.5781, gradTraining Epoch 4/5:  28%|2| 5/18 [00:04<00:06,  2.14it/s, loss=0.5563, gradTraining Epoch 4/5:  33%|3| 6/18 [00:04<00:04,  2.86it/s, loss=0.5563, gradTraining Epoch 4/5:  33%|3| 6/18 [00:04<00:04,  2.86it/s, loss=0.5839, gradTraining Epoch 4/5:  39%|3| 7/18 [00:04<00:02,  3.67it/s, loss=0.5839, gradTraining Epoch 4/5:  39%|3| 7/18 [00:04<00:02,  3.67it/s, loss=0.6559, gradTraining Epoch 4/5:  44%|4| 8/18 [00:04<00:02,  4.51it/s, loss=0.6559, gradTraining Epoch 4/5:  44%|4| 8/18 [00:05<00:02,  4.51it/s, loss=0.5223, gradTraining Epoch 4/5:  50%|5| 9/18 [00:05<00:01,  5.31it/s, loss=0.5223, gradTraining Epoch 4/5:  50%|5| 9/18 [00:05<00:01,  5.31it/s, loss=0.5746, gradTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  6.07it/s, loss=0.5746, graTraining Epoch 4/5:  56%|5| 10/18 [00:05<00:01,  6.07it/s, loss=0.5135, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.72it/s, loss=0.5135, graTraining Epoch 4/5:  61%|6| 11/18 [00:05<00:01,  6.72it/s, loss=0.4622, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  7.25it/s, loss=0.4622, graTraining Epoch 4/5:  67%|6| 12/18 [00:05<00:00,  7.25it/s, loss=0.4715, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  7.68it/s, loss=0.4715, graTraining Epoch 4/5:  72%|7| 13/18 [00:05<00:00,  7.68it/s, loss=0.5277, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  7.92it/s, loss=0.5277, graTraining Epoch 4/5:  78%|7| 14/18 [00:05<00:00,  7.92it/s, loss=0.4958, graTraining Epoch 4/5:  83%|8| 15/18 [00:05<00:00,  8.13it/s, loss=0.4958, graTraining Epoch 4/5:  83%|8| 15/18 [00:05<00:00,  8.13it/s, loss=0.5292, graTraining Epoch 4/5:  89%|8| 16/18 [00:05<00:00,  8.35it/s, loss=0.5292, graTraining Epoch 4/5:  89%|8| 16/18 [00:05<00:00,  8.35it/s, loss=0.4581, graTraining Epoch 4/5:  94%|9| 17/18 [00:05<00:00,  8.46it/s, loss=0.4581, graTraining Epoch 4/5:  94%|9| 17/18 [00:06<00:00,  8.46it/s, loss=0.5811, graTraining Epoch 4/5: 100%|#| 18/18 [00:06<00:00,  2.71it/s, loss=0.5811, gra

Epoch 4/5 Complete (7.0s) [LR: 0.000010]
Train - Loss: 0.5613, Acc: 0.7143, Precision: 0.6562, Recall: 0.9000, F1: 0.7590, AUC: 0.8329
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/18 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/18 [00:04<?, ?it/s, loss=0.4391, grad_norm=1.Training Epoch 5/5:   6%| | 1/18 [00:04<01:09,  4.08s/it, loss=0.4391, gradTraining Epoch 5/5:   6%| | 1/18 [00:04<01:09,  4.08s/it, loss=0.4751, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:28,  1.75s/it, loss=0.4751, gradTraining Epoch 5/5:  11%|1| 2/18 [00:04<00:28,  1.75s/it, loss=0.4424, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:15,  1.01s/it, loss=0.4424, gradTraining Epoch 5/5:  17%|1| 3/18 [00:04<00:15,  1.01s/it, loss=0.4669, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:09,  1.53it/s, loss=0.4669, gradTraining Epoch 5/5:  22%|2| 4/18 [00:04<00:09,  1.53it/s, loss=0.5702, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:06,  2.16it/s, loss=0.5702, gradTraining Epoch 5/5:  28%|2| 5/18 [00:04<00:06,  2.16it/s, loss=0.4138, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.92it/s, loss=0.4138, gradTraining Epoch 5/5:  33%|3| 6/18 [00:04<00:04,  2.92it/s, loss=0.5916, gradTraining Epoch 5/5:  39%|3| 7/18 [00:04<00:02,  3.74it/s, loss=0.5916, gradTraining Epoch 5/5:  39%|3| 7/18 [00:04<00:02,  3.74it/s, loss=0.4491, gradTraining Epoch 5/5:  44%|4| 8/18 [00:04<00:02,  4.55it/s, loss=0.4491, gradTraining Epoch 5/5:  44%|4| 8/18 [00:05<00:02,  4.55it/s, loss=0.4550, gradTraining Epoch 5/5:  50%|5| 9/18 [00:05<00:01,  5.38it/s, loss=0.4550, gradTraining Epoch 5/5:  50%|5| 9/18 [00:05<00:01,  5.38it/s, loss=0.5199, gradTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  6.15it/s, loss=0.5199, graTraining Epoch 5/5:  56%|5| 10/18 [00:05<00:01,  6.15it/s, loss=0.4335, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  6.74it/s, loss=0.4335, graTraining Epoch 5/5:  61%|6| 11/18 [00:05<00:01,  6.74it/s, loss=0.4392, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  7.32it/s, loss=0.4392, graTraining Epoch 5/5:  67%|6| 12/18 [00:05<00:00,  7.32it/s, loss=0.5229, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  7.73it/s, loss=0.5229, graTraining Epoch 5/5:  72%|7| 13/18 [00:05<00:00,  7.73it/s, loss=0.3707, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  8.03it/s, loss=0.3707, graTraining Epoch 5/5:  78%|7| 14/18 [00:05<00:00,  8.03it/s, loss=0.3661, graTraining Epoch 5/5:  83%|8| 15/18 [00:05<00:00,  8.19it/s, loss=0.3661, graTraining Epoch 5/5:  83%|8| 15/18 [00:05<00:00,  8.19it/s, loss=0.5986, graTraining Epoch 5/5:  89%|8| 16/18 [00:05<00:00,  8.37it/s, loss=0.5986, graTraining Epoch 5/5:  89%|8| 16/18 [00:05<00:00,  8.37it/s, loss=0.4407, graTraining Epoch 5/5:  94%|9| 17/18 [00:05<00:00,  8.48it/s, loss=0.4407, graTraining Epoch 5/5:  94%|9| 17/18 [00:05<00:00,  8.48it/s, loss=0.4662, graTraining Epoch 5/5: 100%|#| 18/18 [00:06<00:00,  2.74it/s, loss=0.4662, gra

Epoch 5/5 Complete (7.0s) [LR: 0.000005]
Train - Loss: 0.4701, Acc: 0.7929, Precision: 0.7440, Recall: 0.8929, F1: 0.8117, AUC: 0.9084
------------------------------------------------------------
Training curves saved to model\chb06_fold7\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.6 minutes
Models saved in: model\chb06_fold7
============================================================
✅ Fold 7 training completed successfully!

============================================================
TRAINING FOLD 8/9
============================================================
Using dataset prefix: chb06_fold8
Loading datasets from: preprocessing\data\chb06_fold8
Saving models to: model\chb06_fold8
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=1.2104, std=2.5328
Loaded train dataset: 324 samples
  - Spectrogram shape: torch.Size([324, 30, 18, 50, 10])
  - Value range: [-5.2157, 3.2560]
  - Class distribution: tensor([162, 162])
LOOCV Mode (Fold 8): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/21 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/21 [00:03<?, ?it/s, loss=0.7106, grad_norm=1.Training Epoch 1/5:   5%| | 1/21 [00:03<01:19,  4.00s/it, loss=0.7106, gradTraining Epoch 1/5:   5%| | 1/21 [00:04<01:19,  4.00s/it, loss=0.6891, gradTraining Epoch 1/5:  10%| | 2/21 [00:04<00:32,  1.71s/it, loss=0.6891, gradTraining Epoch 1/5:  10%| | 2/21 [00:04<00:32,  1.71s/it, loss=0.6807, gradTraining Epoch 1/5:  14%|1| 3/21 [00:04<00:17,  1.02it/s, loss=0.6807, gradTraining Epoch 1/5:  14%|1| 3/21 [00:04<00:17,  1.02it/s, loss=0.6864, gradTraining Epoch 1/5:  19%|1| 4/21 [00:04<00:10,  1.57it/s, loss=0.6864, gradTraining Epoch 1/5:  19%|1| 4/21 [00:04<00:10,  1.57it/s, loss=0.6914, gradTraining Epoch 1/5:  24%|2| 5/21 [00:04<00:07,  2.22it/s, loss=0.6914, gradTraining Epoch 1/5:  24%|2| 5/21 [00:04<00:07,  2.22it/s, loss=0.6919, gradTraining Epoch 1/5:  29%|2| 6/21 [00:04<00:05,  2.98it/s, loss=0.6919, gradTraining Epoch 1/5:  29%|2| 6/21 [00:04<00:05,  2.98it/s, loss=0.6808, gradTraining Epoch 1/5:  33%|3| 7/21 [00:04<00:03,  3.82it/s, loss=0.6808, gradTraining Epoch 1/5:  33%|3| 7/21 [00:04<00:03,  3.82it/s, loss=0.7106, gradTraining Epoch 1/5:  38%|3| 8/21 [00:04<00:02,  4.67it/s, loss=0.7106, gradTraining Epoch 1/5:  38%|3| 8/21 [00:04<00:02,  4.67it/s, loss=0.6747, gradTraining Epoch 1/5:  43%|4| 9/21 [00:04<00:02,  5.47it/s, loss=0.6747, gradTraining Epoch 1/5:  43%|4| 9/21 [00:05<00:02,  5.47it/s, loss=0.6903, gradTraining Epoch 1/5:  48%|4| 10/21 [00:05<00:01,  6.23it/s, loss=0.6903, graTraining Epoch 1/5:  48%|4| 10/21 [00:05<00:01,  6.23it/s, loss=0.6693, graTraining Epoch 1/5:  52%|5| 11/21 [00:05<00:01,  6.87it/s, loss=0.6693, graTraining Epoch 1/5:  52%|5| 11/21 [00:05<00:01,  6.87it/s, loss=0.6850, graTraining Epoch 1/5:  57%|5| 12/21 [00:05<00:01,  7.40it/s, loss=0.6850, graTraining Epoch 1/5:  57%|5| 12/21 [00:05<00:01,  7.40it/s, loss=0.6848, graTraining Epoch 1/5:  62%|6| 13/21 [00:05<00:01,  7.83it/s, loss=0.6848, graTraining Epoch 1/5:  62%|6| 13/21 [00:05<00:01,  7.83it/s, loss=0.6815, graTraining Epoch 1/5:  67%|6| 14/21 [00:05<00:00,  8.06it/s, loss=0.6815, graTraining Epoch 1/5:  67%|6| 14/21 [00:05<00:00,  8.06it/s, loss=0.6709, graTraining Epoch 1/5:  71%|7| 15/21 [00:05<00:00,  8.24it/s, loss=0.6709, graTraining Epoch 1/5:  71%|7| 15/21 [00:05<00:00,  8.24it/s, loss=0.6636, graTraining Epoch 1/5:  76%|7| 16/21 [00:05<00:00,  8.45it/s, loss=0.6636, graTraining Epoch 1/5:  76%|7| 16/21 [00:05<00:00,  8.45it/s, loss=0.6767, graTraining Epoch 1/5:  81%|8| 17/21 [00:05<00:00,  8.61it/s, loss=0.6767, graTraining Epoch 1/5:  81%|8| 17/21 [00:05<00:00,  8.61it/s, loss=0.6480, graTraining Epoch 1/5:  86%|8| 18/21 [00:05<00:00,  8.75it/s, loss=0.6480, graTraining Epoch 1/5:  86%|8| 18/21 [00:06<00:00,  8.75it/s, loss=0.6418, graTraining Epoch 1/5:  90%|9| 19/21 [00:06<00:00,  8.82it/s, loss=0.6418, graTraining Epoch 1/5:  90%|9| 19/21 [00:06<00:00,  8.82it/s, loss=0.6745, graTraining Epoch 1/5:  95%|9| 20/21 [00:06<00:00,  8.87it/s, loss=0.6745, graTraining Epoch 1/5:  95%|9| 20/21 [00:06<00:00,  8.87it/s, loss=0.7084, graTraining Epoch 1/5: 100%|#| 21/21 [00:06<00:00,  3.10it/s, loss=0.7084, gra

Epoch 1/5 Complete (7.2s) [LR: 0.000010]
Train - Loss: 0.6815, Acc: 0.6019, Precision: 0.5690, Recall: 0.8395, F1: 0.6783, AUC: 0.6550
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/21 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/21 [00:04<?, ?it/s, loss=0.6476, grad_norm=1.Training Epoch 2/5:   5%| | 1/21 [00:04<01:20,  4.01s/it, loss=0.6476, gradTraining Epoch 2/5:   5%| | 1/21 [00:04<01:20,  4.01s/it, loss=0.6434, gradTraining Epoch 2/5:  10%| | 2/21 [00:04<00:32,  1.72s/it, loss=0.6434, gradTraining Epoch 2/5:  10%| | 2/21 [00:04<00:32,  1.72s/it, loss=0.6646, gradTraining Epoch 2/5:  14%|1| 3/21 [00:04<00:17,  1.01it/s, loss=0.6646, gradTraining Epoch 2/5:  14%|1| 3/21 [00:04<00:17,  1.01it/s, loss=0.6577, gradTraining Epoch 2/5:  19%|1| 4/21 [00:04<00:10,  1.55it/s, loss=0.6577, gradTraining Epoch 2/5:  19%|1| 4/21 [00:04<00:10,  1.55it/s, loss=0.6651, gradTraining Epoch 2/5:  24%|2| 5/21 [00:04<00:07,  2.20it/s, loss=0.6651, gradTraining Epoch 2/5:  24%|2| 5/21 [00:04<00:07,  2.20it/s, loss=0.6683, gradTraining Epoch 2/5:  29%|2| 6/21 [00:04<00:05,  2.96it/s, loss=0.6683, gradTraining Epoch 2/5:  29%|2| 6/21 [00:04<00:05,  2.96it/s, loss=0.6339, gradTraining Epoch 2/5:  33%|3| 7/21 [00:04<00:03,  3.79it/s, loss=0.6339, gradTraining Epoch 2/5:  33%|3| 7/21 [00:04<00:03,  3.79it/s, loss=0.6107, gradTraining Epoch 2/5:  38%|3| 8/21 [00:04<00:02,  4.64it/s, loss=0.6107, gradTraining Epoch 2/5:  38%|3| 8/21 [00:04<00:02,  4.64it/s, loss=0.6050, gradTraining Epoch 2/5:  43%|4| 9/21 [00:04<00:02,  5.48it/s, loss=0.6050, gradTraining Epoch 2/5:  43%|4| 9/21 [00:05<00:02,  5.48it/s, loss=0.6110, gradTraining Epoch 2/5:  48%|4| 10/21 [00:05<00:01,  6.23it/s, loss=0.6110, graTraining Epoch 2/5:  48%|4| 10/21 [00:05<00:01,  6.23it/s, loss=0.6079, graTraining Epoch 2/5:  52%|5| 11/21 [00:05<00:01,  6.85it/s, loss=0.6079, graTraining Epoch 2/5:  52%|5| 11/21 [00:05<00:01,  6.85it/s, loss=0.6525, graTraining Epoch 2/5:  57%|5| 12/21 [00:05<00:01,  7.36it/s, loss=0.6525, graTraining Epoch 2/5:  57%|5| 12/21 [00:05<00:01,  7.36it/s, loss=0.6844, graTraining Epoch 2/5:  62%|6| 13/21 [00:05<00:01,  7.79it/s, loss=0.6844, graTraining Epoch 2/5:  62%|6| 13/21 [00:05<00:01,  7.79it/s, loss=0.6473, graTraining Epoch 2/5:  67%|6| 14/21 [00:05<00:00,  8.05it/s, loss=0.6473, graTraining Epoch 2/5:  67%|6| 14/21 [00:05<00:00,  8.05it/s, loss=0.5828, graTraining Epoch 2/5:  71%|7| 15/21 [00:05<00:00,  8.27it/s, loss=0.5828, graTraining Epoch 2/5:  71%|7| 15/21 [00:05<00:00,  8.27it/s, loss=0.6544, graTraining Epoch 2/5:  76%|7| 16/21 [00:05<00:00,  8.43it/s, loss=0.6544, graTraining Epoch 2/5:  76%|7| 16/21 [00:05<00:00,  8.43it/s, loss=0.6082, graTraining Epoch 2/5:  81%|8| 17/21 [00:05<00:00,  8.61it/s, loss=0.6082, graTraining Epoch 2/5:  81%|8| 17/21 [00:05<00:00,  8.61it/s, loss=0.5501, graTraining Epoch 2/5:  86%|8| 18/21 [00:05<00:00,  8.67it/s, loss=0.5501, graTraining Epoch 2/5:  86%|8| 18/21 [00:06<00:00,  8.67it/s, loss=0.5808, graTraining Epoch 2/5:  90%|9| 19/21 [00:06<00:00,  8.76it/s, loss=0.5808, graTraining Epoch 2/5:  90%|9| 19/21 [00:06<00:00,  8.76it/s, loss=0.6083, graTraining Epoch 2/5:  95%|9| 20/21 [00:06<00:00,  8.81it/s, loss=0.6083, graTraining Epoch 2/5:  95%|9| 20/21 [00:06<00:00,  8.81it/s, loss=0.8234, graTraining Epoch 2/5: 100%|#| 21/21 [00:06<00:00,  3.09it/s, loss=0.8234, gra

Epoch 2/5 Complete (7.2s) [LR: 0.000010]
Train - Loss: 0.6384, Acc: 0.7160, Precision: 0.6683, Recall: 0.8580, F1: 0.7514, AUC: 0.7602
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/21 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/21 [00:04<?, ?it/s, loss=0.6598, grad_norm=1.Training Epoch 3/5:   5%| | 1/21 [00:04<01:20,  4.04s/it, loss=0.6598, gradTraining Epoch 3/5:   5%| | 1/21 [00:04<01:20,  4.04s/it, loss=0.5154, gradTraining Epoch 3/5:  10%| | 2/21 [00:04<00:32,  1.73s/it, loss=0.5154, gradTraining Epoch 3/5:  10%| | 2/21 [00:04<00:32,  1.73s/it, loss=0.6027, gradTraining Epoch 3/5:  14%|1| 3/21 [00:04<00:17,  1.01it/s, loss=0.6027, gradTraining Epoch 3/5:  14%|1| 3/21 [00:04<00:17,  1.01it/s, loss=0.6413, gradTraining Epoch 3/5:  19%|1| 4/21 [00:04<00:10,  1.55it/s, loss=0.6413, gradTraining Epoch 3/5:  19%|1| 4/21 [00:04<00:10,  1.55it/s, loss=0.5535, gradTraining Epoch 3/5:  24%|2| 5/21 [00:04<00:07,  2.20it/s, loss=0.5535, gradTraining Epoch 3/5:  24%|2| 5/21 [00:04<00:07,  2.20it/s, loss=0.5937, gradTraining Epoch 3/5:  29%|2| 6/21 [00:04<00:05,  2.96it/s, loss=0.5937, gradTraining Epoch 3/5:  29%|2| 6/21 [00:04<00:05,  2.96it/s, loss=0.5687, gradTraining Epoch 3/5:  33%|3| 7/21 [00:04<00:03,  3.77it/s, loss=0.5687, gradTraining Epoch 3/5:  33%|3| 7/21 [00:04<00:03,  3.77it/s, loss=0.5821, gradTraining Epoch 3/5:  38%|3| 8/21 [00:04<00:02,  4.60it/s, loss=0.5821, gradTraining Epoch 3/5:  38%|3| 8/21 [00:04<00:02,  4.60it/s, loss=0.5600, gradTraining Epoch 3/5:  43%|4| 9/21 [00:04<00:02,  5.41it/s, loss=0.5600, gradTraining Epoch 3/5:  43%|4| 9/21 [00:05<00:02,  5.41it/s, loss=0.6126, gradTraining Epoch 3/5:  48%|4| 10/21 [00:05<00:01,  5.65it/s, loss=0.6126, graTraining Epoch 3/5:  48%|4| 10/21 [00:05<00:01,  5.65it/s, loss=0.5279, graTraining Epoch 3/5:  52%|5| 11/21 [00:05<00:01,  6.30it/s, loss=0.5279, graTraining Epoch 3/5:  52%|5| 11/21 [00:05<00:01,  6.30it/s, loss=0.5469, graTraining Epoch 3/5:  57%|5| 12/21 [00:05<00:01,  6.87it/s, loss=0.5469, graTraining Epoch 3/5:  57%|5| 12/21 [00:05<00:01,  6.87it/s, loss=0.5509, graTraining Epoch 3/5:  62%|6| 13/21 [00:05<00:01,  7.35it/s, loss=0.5509, graTraining Epoch 3/5:  62%|6| 13/21 [00:05<00:01,  7.35it/s, loss=0.5415, graTraining Epoch 3/5:  67%|6| 14/21 [00:05<00:00,  7.70it/s, loss=0.5415, graTraining Epoch 3/5:  67%|6| 14/21 [00:05<00:00,  7.70it/s, loss=0.4863, graTraining Epoch 3/5:  71%|7| 15/21 [00:05<00:00,  7.95it/s, loss=0.4863, graTraining Epoch 3/5:  71%|7| 15/21 [00:05<00:00,  7.95it/s, loss=0.5967, graTraining Epoch 3/5:  76%|7| 16/21 [00:05<00:00,  8.16it/s, loss=0.5967, graTraining Epoch 3/5:  76%|7| 16/21 [00:05<00:00,  8.16it/s, loss=0.5081, graTraining Epoch 3/5:  81%|8| 17/21 [00:05<00:00,  8.34it/s, loss=0.5081, graTraining Epoch 3/5:  81%|8| 17/21 [00:06<00:00,  8.34it/s, loss=0.5586, graTraining Epoch 3/5:  86%|8| 18/21 [00:06<00:00,  8.48it/s, loss=0.5586, graTraining Epoch 3/5:  86%|8| 18/21 [00:06<00:00,  8.48it/s, loss=0.4581, graTraining Epoch 3/5:  90%|9| 19/21 [00:06<00:00,  8.43it/s, loss=0.4581, graTraining Epoch 3/5:  90%|9| 19/21 [00:06<00:00,  8.43it/s, loss=0.5879, graTraining Epoch 3/5:  95%|9| 20/21 [00:06<00:00,  8.50it/s, loss=0.5879, graTraining Epoch 3/5:  95%|9| 20/21 [00:06<00:00,  8.50it/s, loss=1.0507, graTraining Epoch 3/5: 100%|#| 21/21 [00:06<00:00,  3.03it/s, loss=1.0507, gra

Epoch 3/5 Complete (7.3s) [LR: 0.000010]
Train - Loss: 0.5859, Acc: 0.7284, Precision: 0.6652, Recall: 0.9198, F1: 0.7720, AUC: 0.7582
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/21 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/21 [00:04<?, ?it/s, loss=0.5291, grad_norm=1.Training Epoch 4/5:   5%| | 1/21 [00:04<01:21,  4.08s/it, loss=0.5291, gradTraining Epoch 4/5:   5%| | 1/21 [00:04<01:21,  4.08s/it, loss=0.5838, gradTraining Epoch 4/5:  10%| | 2/21 [00:04<00:33,  1.75s/it, loss=0.5838, gradTraining Epoch 4/5:  10%| | 2/21 [00:04<00:33,  1.75s/it, loss=0.5484, gradTraining Epoch 4/5:  14%|1| 3/21 [00:04<00:18,  1.00s/it, loss=0.5484, gradTraining Epoch 4/5:  14%|1| 3/21 [00:04<00:18,  1.00s/it, loss=0.5298, gradTraining Epoch 4/5:  19%|1| 4/21 [00:04<00:11,  1.53it/s, loss=0.5298, gradTraining Epoch 4/5:  19%|1| 4/21 [00:04<00:11,  1.53it/s, loss=0.5167, gradTraining Epoch 4/5:  24%|2| 5/21 [00:04<00:07,  2.18it/s, loss=0.5167, gradTraining Epoch 4/5:  24%|2| 5/21 [00:04<00:07,  2.18it/s, loss=0.5390, gradTraining Epoch 4/5:  29%|2| 6/21 [00:04<00:05,  2.93it/s, loss=0.5390, gradTraining Epoch 4/5:  29%|2| 6/21 [00:04<00:05,  2.93it/s, loss=0.5731, gradTraining Epoch 4/5:  33%|3| 7/21 [00:04<00:03,  3.74it/s, loss=0.5731, gradTraining Epoch 4/5:  33%|3| 7/21 [00:04<00:03,  3.74it/s, loss=0.5568, gradTraining Epoch 4/5:  38%|3| 8/21 [00:04<00:02,  4.57it/s, loss=0.5568, gradTraining Epoch 4/5:  38%|3| 8/21 [00:05<00:02,  4.57it/s, loss=0.4050, gradTraining Epoch 4/5:  43%|4| 9/21 [00:05<00:02,  5.37it/s, loss=0.4050, gradTraining Epoch 4/5:  43%|4| 9/21 [00:05<00:02,  5.37it/s, loss=0.6269, gradTraining Epoch 4/5:  48%|4| 10/21 [00:05<00:01,  6.09it/s, loss=0.6269, graTraining Epoch 4/5:  48%|4| 10/21 [00:05<00:01,  6.09it/s, loss=0.4642, graTraining Epoch 4/5:  52%|5| 11/21 [00:05<00:01,  6.72it/s, loss=0.4642, graTraining Epoch 4/5:  52%|5| 11/21 [00:05<00:01,  6.72it/s, loss=0.5098, graTraining Epoch 4/5:  57%|5| 12/21 [00:05<00:01,  7.23it/s, loss=0.5098, graTraining Epoch 4/5:  57%|5| 12/21 [00:05<00:01,  7.23it/s, loss=0.4335, graTraining Epoch 4/5:  62%|6| 13/21 [00:05<00:01,  7.61it/s, loss=0.4335, graTraining Epoch 4/5:  62%|6| 13/21 [00:05<00:01,  7.61it/s, loss=0.5609, graTraining Epoch 4/5:  67%|6| 14/21 [00:05<00:00,  7.91it/s, loss=0.5609, graTraining Epoch 4/5:  67%|6| 14/21 [00:05<00:00,  7.91it/s, loss=0.4887, graTraining Epoch 4/5:  71%|7| 15/21 [00:05<00:00,  8.14it/s, loss=0.4887, graTraining Epoch 4/5:  71%|7| 15/21 [00:05<00:00,  8.14it/s, loss=0.4479, graTraining Epoch 4/5:  76%|7| 16/21 [00:05<00:00,  8.26it/s, loss=0.4479, graTraining Epoch 4/5:  76%|7| 16/21 [00:05<00:00,  8.26it/s, loss=0.4891, graTraining Epoch 4/5:  81%|8| 17/21 [00:05<00:00,  8.47it/s, loss=0.4891, graTraining Epoch 4/5:  81%|8| 17/21 [00:06<00:00,  8.47it/s, loss=0.5247, graTraining Epoch 4/5:  86%|8| 18/21 [00:06<00:00,  8.48it/s, loss=0.5247, graTraining Epoch 4/5:  86%|8| 18/21 [00:06<00:00,  8.48it/s, loss=0.6415, graTraining Epoch 4/5:  90%|9| 19/21 [00:06<00:00,  8.56it/s, loss=0.6415, graTraining Epoch 4/5:  90%|9| 19/21 [00:06<00:00,  8.56it/s, loss=0.5705, graTraining Epoch 4/5:  95%|9| 20/21 [00:06<00:00,  8.65it/s, loss=0.5705, graTraining Epoch 4/5:  95%|9| 20/21 [00:06<00:00,  8.65it/s, loss=0.2852, graTraining Epoch 4/5: 100%|#| 21/21 [00:06<00:00,  3.05it/s, loss=0.2852, gra

Epoch 4/5 Complete (7.3s) [LR: 0.000010]
Train - Loss: 0.5154, Acc: 0.7438, Precision: 0.6740, Recall: 0.9444, F1: 0.7866, AUC: 0.7642
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/21 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/21 [00:03<?, ?it/s, loss=0.6062, grad_norm=2.Training Epoch 5/5:   5%| | 1/21 [00:03<01:19,  4.00s/it, loss=0.6062, gradTraining Epoch 5/5:   5%| | 1/21 [00:04<01:19,  4.00s/it, loss=0.5326, gradTraining Epoch 5/5:  10%| | 2/21 [00:04<00:32,  1.72s/it, loss=0.5326, gradTraining Epoch 5/5:  10%| | 2/21 [00:04<00:32,  1.72s/it, loss=0.7650, gradTraining Epoch 5/5:  14%|1| 3/21 [00:04<00:17,  1.01it/s, loss=0.7650, gradTraining Epoch 5/5:  14%|1| 3/21 [00:04<00:17,  1.01it/s, loss=0.4739, gradTraining Epoch 5/5:  19%|1| 4/21 [00:04<00:10,  1.56it/s, loss=0.4739, gradTraining Epoch 5/5:  19%|1| 4/21 [00:04<00:10,  1.56it/s, loss=0.3917, gradTraining Epoch 5/5:  24%|2| 5/21 [00:04<00:07,  2.22it/s, loss=0.3917, gradTraining Epoch 5/5:  24%|2| 5/21 [00:04<00:07,  2.22it/s, loss=0.6361, gradTraining Epoch 5/5:  29%|2| 6/21 [00:04<00:05,  2.97it/s, loss=0.6361, gradTraining Epoch 5/5:  29%|2| 6/21 [00:04<00:05,  2.97it/s, loss=0.5702, gradTraining Epoch 5/5:  33%|3| 7/21 [00:04<00:03,  3.79it/s, loss=0.5702, gradTraining Epoch 5/5:  33%|3| 7/21 [00:04<00:03,  3.79it/s, loss=0.4721, gradTraining Epoch 5/5:  38%|3| 8/21 [00:04<00:02,  4.63it/s, loss=0.4721, gradTraining Epoch 5/5:  38%|3| 8/21 [00:04<00:02,  4.63it/s, loss=0.5055, gradTraining Epoch 5/5:  43%|4| 9/21 [00:04<00:02,  5.43it/s, loss=0.5055, gradTraining Epoch 5/5:  43%|4| 9/21 [00:05<00:02,  5.43it/s, loss=0.4727, gradTraining Epoch 5/5:  48%|4| 10/21 [00:05<00:01,  6.16it/s, loss=0.4727, graTraining Epoch 5/5:  48%|4| 10/21 [00:05<00:01,  6.16it/s, loss=0.4112, graTraining Epoch 5/5:  52%|5| 11/21 [00:05<00:01,  6.81it/s, loss=0.4112, graTraining Epoch 5/5:  52%|5| 11/21 [00:05<00:01,  6.81it/s, loss=0.5123, graTraining Epoch 5/5:  57%|5| 12/21 [00:05<00:01,  7.34it/s, loss=0.5123, graTraining Epoch 5/5:  57%|5| 12/21 [00:05<00:01,  7.34it/s, loss=0.3496, graTraining Epoch 5/5:  62%|6| 13/21 [00:05<00:01,  7.71it/s, loss=0.3496, graTraining Epoch 5/5:  62%|6| 13/21 [00:05<00:01,  7.71it/s, loss=0.4183, graTraining Epoch 5/5:  67%|6| 14/21 [00:05<00:00,  8.00it/s, loss=0.4183, graTraining Epoch 5/5:  67%|6| 14/21 [00:05<00:00,  8.00it/s, loss=0.3547, graTraining Epoch 5/5:  71%|7| 15/21 [00:05<00:00,  8.20it/s, loss=0.3547, graTraining Epoch 5/5:  71%|7| 15/21 [00:05<00:00,  8.20it/s, loss=0.4210, graTraining Epoch 5/5:  76%|7| 16/21 [00:05<00:00,  8.35it/s, loss=0.4210, graTraining Epoch 5/5:  76%|7| 16/21 [00:05<00:00,  8.35it/s, loss=0.4314, graTraining Epoch 5/5:  81%|8| 17/21 [00:05<00:00,  8.47it/s, loss=0.4314, graTraining Epoch 5/5:  81%|8| 17/21 [00:05<00:00,  8.47it/s, loss=0.3994, graTraining Epoch 5/5:  86%|8| 18/21 [00:05<00:00,  8.59it/s, loss=0.3994, graTraining Epoch 5/5:  86%|8| 18/21 [00:06<00:00,  8.59it/s, loss=0.4534, graTraining Epoch 5/5:  90%|9| 19/21 [00:06<00:00,  8.66it/s, loss=0.4534, graTraining Epoch 5/5:  90%|9| 19/21 [00:06<00:00,  8.66it/s, loss=0.4471, graTraining Epoch 5/5:  95%|9| 20/21 [00:06<00:00,  8.64it/s, loss=0.4471, graTraining Epoch 5/5:  95%|9| 20/21 [00:06<00:00,  8.64it/s, loss=0.4212, graTraining Epoch 5/5: 100%|#| 21/21 [00:06<00:00,  3.09it/s, loss=0.4212, gra

Epoch 5/5 Complete (7.2s) [LR: 0.000005]
Train - Loss: 0.4784, Acc: 0.7654, Precision: 0.6937, Recall: 0.9506, F1: 0.8021, AUC: 0.8464
------------------------------------------------------------
Training curves saved to model\chb06_fold8\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.6 minutes
Models saved in: model\chb06_fold8
============================================================
✅ Fold 8 training completed successfully!

============================================================
TRAINING FOLD 9/9
============================================================
Using dataset prefix: chb06_fold9
Loading datasets from: preprocessing\data\chb06_fold9
Saving models to: model\chb06_fold9
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=1.2520, std=2.5015
Loaded train dataset: 324 samples
  - Spectrogram shape: torch.Size([324, 30, 18, 50, 10])
  - Value range: [-5.2977, 3.2259]
  - Class distribution: tensor([162, 162])
LOOCV Mode (Fold 9): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/21 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/21 [00:03<?, ?it/s, loss=0.6893, grad_norm=0.Training Epoch 1/5:   5%| | 1/21 [00:03<01:19,  4.00s/it, loss=0.6893, gradTraining Epoch 1/5:   5%| | 1/21 [00:04<01:19,  4.00s/it, loss=0.6974, gradTraining Epoch 1/5:  10%| | 2/21 [00:04<00:32,  1.72s/it, loss=0.6974, gradTraining Epoch 1/5:  10%| | 2/21 [00:04<00:32,  1.72s/it, loss=0.6866, gradTraining Epoch 1/5:  14%|1| 3/21 [00:04<00:17,  1.01it/s, loss=0.6866, gradTraining Epoch 1/5:  14%|1| 3/21 [00:04<00:17,  1.01it/s, loss=0.6845, gradTraining Epoch 1/5:  19%|1| 4/21 [00:04<00:10,  1.56it/s, loss=0.6845, gradTraining Epoch 1/5:  19%|1| 4/21 [00:04<00:10,  1.56it/s, loss=0.6879, gradTraining Epoch 1/5:  24%|2| 5/21 [00:04<00:07,  2.21it/s, loss=0.6879, gradTraining Epoch 1/5:  24%|2| 5/21 [00:04<00:07,  2.21it/s, loss=0.6851, gradTraining Epoch 1/5:  29%|2| 6/21 [00:04<00:05,  2.97it/s, loss=0.6851, gradTraining Epoch 1/5:  29%|2| 6/21 [00:04<00:05,  2.97it/s, loss=0.6810, gradTraining Epoch 1/5:  33%|3| 7/21 [00:04<00:03,  3.80it/s, loss=0.6810, gradTraining Epoch 1/5:  33%|3| 7/21 [00:04<00:03,  3.80it/s, loss=0.6925, gradTraining Epoch 1/5:  38%|3| 8/21 [00:04<00:02,  4.63it/s, loss=0.6925, gradTraining Epoch 1/5:  38%|3| 8/21 [00:04<00:02,  4.63it/s, loss=0.6738, gradTraining Epoch 1/5:  43%|4| 9/21 [00:04<00:02,  5.47it/s, loss=0.6738, gradTraining Epoch 1/5:  43%|4| 9/21 [00:05<00:02,  5.47it/s, loss=0.7001, gradTraining Epoch 1/5:  48%|4| 10/21 [00:05<00:01,  5.81it/s, loss=0.7001, graTraining Epoch 1/5:  48%|4| 10/21 [00:05<00:01,  5.81it/s, loss=0.6771, graTraining Epoch 1/5:  52%|5| 11/21 [00:05<00:01,  6.48it/s, loss=0.6771, graTraining Epoch 1/5:  52%|5| 11/21 [00:05<00:01,  6.48it/s, loss=0.6776, graTraining Epoch 1/5:  57%|5| 12/21 [00:05<00:01,  7.00it/s, loss=0.6776, graTraining Epoch 1/5:  57%|5| 12/21 [00:05<00:01,  7.00it/s, loss=0.6782, graTraining Epoch 1/5:  62%|6| 13/21 [00:05<00:01,  7.50it/s, loss=0.6782, graTraining Epoch 1/5:  62%|6| 13/21 [00:05<00:01,  7.50it/s, loss=0.6903, graTraining Epoch 1/5:  67%|6| 14/21 [00:05<00:00,  7.84it/s, loss=0.6903, graTraining Epoch 1/5:  67%|6| 14/21 [00:05<00:00,  7.84it/s, loss=0.6833, graTraining Epoch 1/5:  71%|7| 15/21 [00:05<00:00,  8.13it/s, loss=0.6833, graTraining Epoch 1/5:  71%|7| 15/21 [00:05<00:00,  8.13it/s, loss=0.6573, graTraining Epoch 1/5:  76%|7| 16/21 [00:05<00:00,  8.32it/s, loss=0.6573, graTraining Epoch 1/5:  76%|7| 16/21 [00:05<00:00,  8.32it/s, loss=0.6681, graTraining Epoch 1/5:  81%|8| 17/21 [00:05<00:00,  8.39it/s, loss=0.6681, graTraining Epoch 1/5:  81%|8| 17/21 [00:05<00:00,  8.39it/s, loss=0.6529, graTraining Epoch 1/5:  86%|8| 18/21 [00:05<00:00,  8.55it/s, loss=0.6529, graTraining Epoch 1/5:  86%|8| 18/21 [00:06<00:00,  8.55it/s, loss=0.6727, graTraining Epoch 1/5:  90%|9| 19/21 [00:06<00:00,  8.56it/s, loss=0.6727, graTraining Epoch 1/5:  90%|9| 19/21 [00:06<00:00,  8.56it/s, loss=0.6613, graTraining Epoch 1/5:  95%|9| 20/21 [00:06<00:00,  8.52it/s, loss=0.6613, graTraining Epoch 1/5:  95%|9| 20/21 [00:06<00:00,  8.52it/s, loss=0.6762, graTraining Epoch 1/5: 100%|#| 21/21 [00:06<00:00,  3.08it/s, loss=0.6762, gra

Epoch 1/5 Complete (7.2s) [LR: 0.000010]
Train - Loss: 0.6797, Acc: 0.6265, Precision: 0.5945, Recall: 0.7963, F1: 0.6807, AUC: 0.6478
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/21 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/21 [00:04<?, ?it/s, loss=0.6788, grad_norm=0.Training Epoch 2/5:   5%| | 1/21 [00:04<01:22,  4.11s/it, loss=0.6788, gradTraining Epoch 2/5:   5%| | 1/21 [00:04<01:22,  4.11s/it, loss=0.6504, gradTraining Epoch 2/5:  10%| | 2/21 [00:04<00:33,  1.76s/it, loss=0.6504, gradTraining Epoch 2/5:  10%| | 2/21 [00:04<00:33,  1.76s/it, loss=0.6775, gradTraining Epoch 2/5:  14%|1| 3/21 [00:04<00:18,  1.01s/it, loss=0.6775, gradTraining Epoch 2/5:  14%|1| 3/21 [00:04<00:18,  1.01s/it, loss=0.6980, gradTraining Epoch 2/5:  19%|1| 4/21 [00:04<00:11,  1.52it/s, loss=0.6980, gradTraining Epoch 2/5:  19%|1| 4/21 [00:04<00:11,  1.52it/s, loss=0.6517, gradTraining Epoch 2/5:  24%|2| 5/21 [00:04<00:07,  2.17it/s, loss=0.6517, gradTraining Epoch 2/5:  24%|2| 5/21 [00:04<00:07,  2.17it/s, loss=0.6167, gradTraining Epoch 2/5:  29%|2| 6/21 [00:04<00:05,  2.91it/s, loss=0.6167, gradTraining Epoch 2/5:  29%|2| 6/21 [00:04<00:05,  2.91it/s, loss=0.6842, gradTraining Epoch 2/5:  33%|3| 7/21 [00:04<00:03,  3.71it/s, loss=0.6842, gradTraining Epoch 2/5:  33%|3| 7/21 [00:04<00:03,  3.71it/s, loss=0.6784, gradTraining Epoch 2/5:  38%|3| 8/21 [00:04<00:02,  4.48it/s, loss=0.6784, gradTraining Epoch 2/5:  38%|3| 8/21 [00:05<00:02,  4.48it/s, loss=0.6598, gradTraining Epoch 2/5:  43%|4| 9/21 [00:05<00:02,  5.28it/s, loss=0.6598, gradTraining Epoch 2/5:  43%|4| 9/21 [00:05<00:02,  5.28it/s, loss=0.6171, gradTraining Epoch 2/5:  48%|4| 10/21 [00:05<00:01,  5.96it/s, loss=0.6171, graTraining Epoch 2/5:  48%|4| 10/21 [00:05<00:01,  5.96it/s, loss=0.6459, graTraining Epoch 2/5:  52%|5| 11/21 [00:05<00:01,  6.50it/s, loss=0.6459, graTraining Epoch 2/5:  52%|5| 11/21 [00:05<00:01,  6.50it/s, loss=0.6368, graTraining Epoch 2/5:  57%|5| 12/21 [00:05<00:01,  6.97it/s, loss=0.6368, graTraining Epoch 2/5:  57%|5| 12/21 [00:05<00:01,  6.97it/s, loss=0.6235, graTraining Epoch 2/5:  62%|6| 13/21 [00:05<00:01,  7.32it/s, loss=0.6235, graTraining Epoch 2/5:  62%|6| 13/21 [00:05<00:01,  7.32it/s, loss=0.6342, graTraining Epoch 2/5:  67%|6| 14/21 [00:05<00:00,  7.58it/s, loss=0.6342, graTraining Epoch 2/5:  67%|6| 14/21 [00:05<00:00,  7.58it/s, loss=0.6070, graTraining Epoch 2/5:  71%|7| 15/21 [00:05<00:00,  7.78it/s, loss=0.6070, graTraining Epoch 2/5:  71%|7| 15/21 [00:05<00:00,  7.78it/s, loss=0.6262, graTraining Epoch 2/5:  76%|7| 16/21 [00:05<00:00,  7.94it/s, loss=0.6262, graTraining Epoch 2/5:  76%|7| 16/21 [00:06<00:00,  7.94it/s, loss=0.6000, graTraining Epoch 2/5:  81%|8| 17/21 [00:06<00:00,  8.09it/s, loss=0.6000, graTraining Epoch 2/5:  81%|8| 17/21 [00:06<00:00,  8.09it/s, loss=0.6124, graTraining Epoch 2/5:  86%|8| 18/21 [00:06<00:00,  8.33it/s, loss=0.6124, graTraining Epoch 2/5:  86%|8| 18/21 [00:06<00:00,  8.33it/s, loss=0.6205, graTraining Epoch 2/5:  90%|9| 19/21 [00:06<00:00,  8.44it/s, loss=0.6205, graTraining Epoch 2/5:  90%|9| 19/21 [00:06<00:00,  8.44it/s, loss=0.6718, graTraining Epoch 2/5:  95%|9| 20/21 [00:06<00:00,  8.67it/s, loss=0.6718, graTraining Epoch 2/5:  95%|9| 20/21 [00:06<00:00,  8.67it/s, loss=0.6485, graTraining Epoch 2/5: 100%|#| 21/21 [00:06<00:00,  3.01it/s, loss=0.6485, gra

Epoch 2/5 Complete (7.4s) [LR: 0.000010]
Train - Loss: 0.6447, Acc: 0.6914, Precision: 0.6360, Recall: 0.8951, F1: 0.7436, AUC: 0.7238
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/21 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/21 [00:04<?, ?it/s, loss=0.5844, grad_norm=0.Training Epoch 3/5:   5%| | 1/21 [00:04<01:22,  4.11s/it, loss=0.5844, gradTraining Epoch 3/5:   5%| | 1/21 [00:04<01:22,  4.11s/it, loss=0.6408, gradTraining Epoch 3/5:  10%| | 2/21 [00:04<00:33,  1.76s/it, loss=0.6408, gradTraining Epoch 3/5:  10%| | 2/21 [00:04<00:33,  1.76s/it, loss=0.5877, gradTraining Epoch 3/5:  14%|1| 3/21 [00:04<00:18,  1.01s/it, loss=0.5877, gradTraining Epoch 3/5:  14%|1| 3/21 [00:04<00:18,  1.01s/it, loss=0.6088, gradTraining Epoch 3/5:  19%|1| 4/21 [00:04<00:11,  1.53it/s, loss=0.6088, gradTraining Epoch 3/5:  19%|1| 4/21 [00:04<00:11,  1.53it/s, loss=0.6565, gradTraining Epoch 3/5:  24%|2| 5/21 [00:04<00:07,  2.18it/s, loss=0.6565, gradTraining Epoch 3/5:  24%|2| 5/21 [00:04<00:07,  2.18it/s, loss=0.6338, gradTraining Epoch 3/5:  29%|2| 6/21 [00:04<00:05,  2.93it/s, loss=0.6338, gradTraining Epoch 3/5:  29%|2| 6/21 [00:04<00:05,  2.93it/s, loss=0.6111, gradTraining Epoch 3/5:  33%|3| 7/21 [00:04<00:03,  3.78it/s, loss=0.6111, gradTraining Epoch 3/5:  33%|3| 7/21 [00:04<00:03,  3.78it/s, loss=0.5447, gradTraining Epoch 3/5:  38%|3| 8/21 [00:04<00:02,  4.62it/s, loss=0.5447, gradTraining Epoch 3/5:  38%|3| 8/21 [00:05<00:02,  4.62it/s, loss=0.5040, gradTraining Epoch 3/5:  43%|4| 9/21 [00:05<00:02,  5.44it/s, loss=0.5040, gradTraining Epoch 3/5:  43%|4| 9/21 [00:05<00:02,  5.44it/s, loss=0.6136, gradTraining Epoch 3/5:  48%|4| 10/21 [00:05<00:01,  6.18it/s, loss=0.6136, graTraining Epoch 3/5:  48%|4| 10/21 [00:05<00:01,  6.18it/s, loss=0.6467, graTraining Epoch 3/5:  52%|5| 11/21 [00:05<00:01,  6.86it/s, loss=0.6467, graTraining Epoch 3/5:  52%|5| 11/21 [00:05<00:01,  6.86it/s, loss=0.6084, graTraining Epoch 3/5:  57%|5| 12/21 [00:05<00:01,  7.38it/s, loss=0.6084, graTraining Epoch 3/5:  57%|5| 12/21 [00:05<00:01,  7.38it/s, loss=0.5644, graTraining Epoch 3/5:  62%|6| 13/21 [00:05<00:01,  7.77it/s, loss=0.5644, graTraining Epoch 3/5:  62%|6| 13/21 [00:05<00:01,  7.77it/s, loss=0.5988, graTraining Epoch 3/5:  67%|6| 14/21 [00:05<00:00,  8.04it/s, loss=0.5988, graTraining Epoch 3/5:  67%|6| 14/21 [00:05<00:00,  8.04it/s, loss=0.6563, graTraining Epoch 3/5:  71%|7| 15/21 [00:05<00:00,  8.25it/s, loss=0.6563, graTraining Epoch 3/5:  71%|7| 15/21 [00:05<00:00,  8.25it/s, loss=0.6834, graTraining Epoch 3/5:  76%|7| 16/21 [00:05<00:00,  8.41it/s, loss=0.6834, graTraining Epoch 3/5:  76%|7| 16/21 [00:05<00:00,  8.41it/s, loss=0.5462, graTraining Epoch 3/5:  81%|8| 17/21 [00:05<00:00,  8.52it/s, loss=0.5462, graTraining Epoch 3/5:  81%|8| 17/21 [00:06<00:00,  8.52it/s, loss=0.4826, graTraining Epoch 3/5:  86%|8| 18/21 [00:06<00:00,  8.68it/s, loss=0.4826, graTraining Epoch 3/5:  86%|8| 18/21 [00:06<00:00,  8.68it/s, loss=0.5453, graTraining Epoch 3/5:  90%|9| 19/21 [00:06<00:00,  8.69it/s, loss=0.5453, graTraining Epoch 3/5:  90%|9| 19/21 [00:06<00:00,  8.69it/s, loss=0.6463, graTraining Epoch 3/5:  95%|9| 20/21 [00:06<00:00,  8.75it/s, loss=0.6463, graTraining Epoch 3/5:  95%|9| 20/21 [00:06<00:00,  8.75it/s, loss=0.6558, graTraining Epoch 3/5: 100%|#| 21/21 [00:06<00:00,  3.05it/s, loss=0.6558, gra

Epoch 3/5 Complete (7.3s) [LR: 0.000010]
Train - Loss: 0.6009, Acc: 0.6790, Precision: 0.6229, Recall: 0.9074, F1: 0.7387, AUC: 0.7204
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/21 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/21 [00:04<?, ?it/s, loss=0.5579, grad_norm=0.Training Epoch 4/5:   5%| | 1/21 [00:04<01:21,  4.07s/it, loss=0.5579, gradTraining Epoch 4/5:   5%| | 1/21 [00:04<01:21,  4.07s/it, loss=0.4779, gradTraining Epoch 4/5:  10%| | 2/21 [00:04<00:33,  1.75s/it, loss=0.4779, gradTraining Epoch 4/5:  10%| | 2/21 [00:04<00:33,  1.75s/it, loss=0.5143, gradTraining Epoch 4/5:  14%|1| 3/21 [00:04<00:18,  1.00s/it, loss=0.5143, gradTraining Epoch 4/5:  14%|1| 3/21 [00:04<00:18,  1.00s/it, loss=0.6261, gradTraining Epoch 4/5:  19%|1| 4/21 [00:04<00:11,  1.54it/s, loss=0.6261, gradTraining Epoch 4/5:  19%|1| 4/21 [00:04<00:11,  1.54it/s, loss=0.5140, gradTraining Epoch 4/5:  24%|2| 5/21 [00:04<00:07,  2.19it/s, loss=0.5140, gradTraining Epoch 4/5:  24%|2| 5/21 [00:04<00:07,  2.19it/s, loss=0.5751, gradTraining Epoch 4/5:  29%|2| 6/21 [00:04<00:05,  2.95it/s, loss=0.5751, gradTraining Epoch 4/5:  29%|2| 6/21 [00:04<00:05,  2.95it/s, loss=0.5414, gradTraining Epoch 4/5:  33%|3| 7/21 [00:04<00:03,  3.79it/s, loss=0.5414, gradTraining Epoch 4/5:  33%|3| 7/21 [00:04<00:03,  3.79it/s, loss=0.7049, gradTraining Epoch 4/5:  38%|3| 8/21 [00:04<00:02,  4.64it/s, loss=0.7049, gradTraining Epoch 4/5:  38%|3| 8/21 [00:04<00:02,  4.64it/s, loss=0.6178, gradTraining Epoch 4/5:  43%|4| 9/21 [00:04<00:02,  5.46it/s, loss=0.6178, gradTraining Epoch 4/5:  43%|4| 9/21 [00:05<00:02,  5.46it/s, loss=0.5426, gradTraining Epoch 4/5:  48%|4| 10/21 [00:05<00:01,  6.20it/s, loss=0.5426, graTraining Epoch 4/5:  48%|4| 10/21 [00:05<00:01,  6.20it/s, loss=0.5577, graTraining Epoch 4/5:  52%|5| 11/21 [00:05<00:01,  6.85it/s, loss=0.5577, graTraining Epoch 4/5:  52%|5| 11/21 [00:05<00:01,  6.85it/s, loss=0.4713, graTraining Epoch 4/5:  57%|5| 12/21 [00:05<00:01,  7.31it/s, loss=0.4713, graTraining Epoch 4/5:  57%|5| 12/21 [00:05<00:01,  7.31it/s, loss=0.6053, graTraining Epoch 4/5:  62%|6| 13/21 [00:05<00:01,  7.71it/s, loss=0.6053, graTraining Epoch 4/5:  62%|6| 13/21 [00:05<00:01,  7.71it/s, loss=0.5916, graTraining Epoch 4/5:  67%|6| 14/21 [00:05<00:00,  8.04it/s, loss=0.5916, graTraining Epoch 4/5:  67%|6| 14/21 [00:05<00:00,  8.04it/s, loss=0.5852, graTraining Epoch 4/5:  71%|7| 15/21 [00:05<00:00,  8.30it/s, loss=0.5852, graTraining Epoch 4/5:  71%|7| 15/21 [00:05<00:00,  8.30it/s, loss=0.5842, graTraining Epoch 4/5:  76%|7| 16/21 [00:05<00:00,  8.44it/s, loss=0.5842, graTraining Epoch 4/5:  76%|7| 16/21 [00:05<00:00,  8.44it/s, loss=0.5276, graTraining Epoch 4/5:  81%|8| 17/21 [00:05<00:00,  8.61it/s, loss=0.5276, graTraining Epoch 4/5:  81%|8| 17/21 [00:05<00:00,  8.61it/s, loss=0.4738, graTraining Epoch 4/5:  86%|8| 18/21 [00:05<00:00,  8.74it/s, loss=0.4738, graTraining Epoch 4/5:  86%|8| 18/21 [00:06<00:00,  8.74it/s, loss=0.6504, graTraining Epoch 4/5:  90%|9| 19/21 [00:06<00:00,  8.78it/s, loss=0.6504, graTraining Epoch 4/5:  90%|9| 19/21 [00:06<00:00,  8.78it/s, loss=0.5862, graTraining Epoch 4/5:  95%|9| 20/21 [00:06<00:00,  8.78it/s, loss=0.5862, graTraining Epoch 4/5:  95%|9| 20/21 [00:06<00:00,  8.78it/s, loss=0.5535, graTraining Epoch 4/5: 100%|#| 21/21 [00:06<00:00,  3.07it/s, loss=0.5535, gra

Epoch 4/5 Complete (7.3s) [LR: 0.000010]
Train - Loss: 0.5647, Acc: 0.6975, Precision: 0.6368, Recall: 0.9198, F1: 0.7525, AUC: 0.7244
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/21 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/21 [00:04<?, ?it/s, loss=0.6666, grad_norm=1.Training Epoch 5/5:   5%| | 1/21 [00:04<01:20,  4.02s/it, loss=0.6666, gradTraining Epoch 5/5:   5%| | 1/21 [00:04<01:20,  4.02s/it, loss=0.4688, gradTraining Epoch 5/5:  10%| | 2/21 [00:04<00:32,  1.73s/it, loss=0.4688, gradTraining Epoch 5/5:  10%| | 2/21 [00:04<00:32,  1.73s/it, loss=0.5075, gradTraining Epoch 5/5:  14%|1| 3/21 [00:04<00:17,  1.01it/s, loss=0.5075, gradTraining Epoch 5/5:  14%|1| 3/21 [00:04<00:17,  1.01it/s, loss=0.5770, gradTraining Epoch 5/5:  19%|1| 4/21 [00:04<00:10,  1.55it/s, loss=0.5770, gradTraining Epoch 5/5:  19%|1| 4/21 [00:04<00:10,  1.55it/s, loss=0.5384, gradTraining Epoch 5/5:  24%|2| 5/21 [00:04<00:07,  2.20it/s, loss=0.5384, gradTraining Epoch 5/5:  24%|2| 5/21 [00:04<00:07,  2.20it/s, loss=0.5720, gradTraining Epoch 5/5:  29%|2| 6/21 [00:04<00:05,  2.95it/s, loss=0.5720, gradTraining Epoch 5/5:  29%|2| 6/21 [00:04<00:05,  2.95it/s, loss=0.5004, gradTraining Epoch 5/5:  33%|3| 7/21 [00:04<00:03,  3.76it/s, loss=0.5004, gradTraining Epoch 5/5:  33%|3| 7/21 [00:04<00:03,  3.76it/s, loss=0.5178, gradTraining Epoch 5/5:  38%|3| 8/21 [00:04<00:02,  4.59it/s, loss=0.5178, gradTraining Epoch 5/5:  38%|3| 8/21 [00:04<00:02,  4.59it/s, loss=0.4486, gradTraining Epoch 5/5:  43%|4| 9/21 [00:04<00:02,  5.39it/s, loss=0.4486, gradTraining Epoch 5/5:  43%|4| 9/21 [00:05<00:02,  5.39it/s, loss=0.5651, gradTraining Epoch 5/5:  48%|4| 10/21 [00:05<00:01,  6.08it/s, loss=0.5651, graTraining Epoch 5/5:  48%|4| 10/21 [00:05<00:01,  6.08it/s, loss=0.5531, graTraining Epoch 5/5:  52%|5| 11/21 [00:05<00:01,  6.68it/s, loss=0.5531, graTraining Epoch 5/5:  52%|5| 11/21 [00:05<00:01,  6.68it/s, loss=0.4038, graTraining Epoch 5/5:  57%|5| 12/21 [00:05<00:01,  7.24it/s, loss=0.4038, graTraining Epoch 5/5:  57%|5| 12/21 [00:05<00:01,  7.24it/s, loss=0.4926, graTraining Epoch 5/5:  62%|6| 13/21 [00:05<00:01,  7.61it/s, loss=0.4926, graTraining Epoch 5/5:  62%|6| 13/21 [00:05<00:01,  7.61it/s, loss=0.4399, graTraining Epoch 5/5:  67%|6| 14/21 [00:05<00:00,  7.92it/s, loss=0.4399, graTraining Epoch 5/5:  67%|6| 14/21 [00:05<00:00,  7.92it/s, loss=0.6787, graTraining Epoch 5/5:  71%|7| 15/21 [00:05<00:00,  8.15it/s, loss=0.6787, graTraining Epoch 5/5:  71%|7| 15/21 [00:05<00:00,  8.15it/s, loss=0.6051, graTraining Epoch 5/5:  76%|7| 16/21 [00:05<00:00,  8.30it/s, loss=0.6051, graTraining Epoch 5/5:  76%|7| 16/21 [00:05<00:00,  8.30it/s, loss=0.5008, graTraining Epoch 5/5:  81%|8| 17/21 [00:05<00:00,  8.26it/s, loss=0.5008, graTraining Epoch 5/5:  81%|8| 17/21 [00:05<00:00,  8.26it/s, loss=0.5265, graTraining Epoch 5/5:  86%|8| 18/21 [00:05<00:00,  8.41it/s, loss=0.5265, graTraining Epoch 5/5:  86%|8| 18/21 [00:06<00:00,  8.41it/s, loss=0.4857, graTraining Epoch 5/5:  90%|9| 19/21 [00:06<00:00,  8.43it/s, loss=0.4857, graTraining Epoch 5/5:  90%|9| 19/21 [00:06<00:00,  8.43it/s, loss=0.5212, graTraining Epoch 5/5:  95%|9| 20/21 [00:06<00:00,  8.53it/s, loss=0.5212, graTraining Epoch 5/5:  95%|9| 20/21 [00:06<00:00,  8.53it/s, loss=0.4772, graTraining Epoch 5/5: 100%|#| 21/21 [00:06<00:00,  3.07it/s, loss=0.4772, gra

Epoch 5/5 Complete (7.3s) [LR: 0.000005]
Train - Loss: 0.5260, Acc: 0.7253, Precision: 0.6540, Recall: 0.9568, F1: 0.7769, AUC: 0.7891
------------------------------------------------------------
Training curves saved to model\chb06_fold9\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.6 minutes
Models saved in: model\chb06_fold9
============================================================
✅ Fold 9 training completed successfully!

============================================================
✅ BATCH TRAINING COMPLETED!
✅ Trained models for 10 folds for patient chb06
============================================================
============================================================
============================================================
BATCH EVALUATION: ALL FOLDS
BATCH EVALUATION: ALL FOLDS
Evaluating 10 folds for patient chb06
Evaluating 10 folds for patient chb06
============================================================
============================================================
Using CUDA: NVIDIA GeForce RTX 3090 Ti
Using CUDA: NVIDIA GeForce RTX 3090 Ti

============================================================
============================================================

EVALUATING FOLD 0/9
EVALUATING FOLD 0/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb06_fold0
Dataset prefix: chb06_fold0
Using test dataset: preprocessing\data\chb06_fold0\test_dataset.h5
Using test dataset: preprocessing\data\chb06_fold0\test_dataset.h5
Loading test dataset from preprocessing\data\chb06_fold0\test_dataset.h5...
Loading test dataset from preprocessing\data\chb06_fold0\test_dataset.h5...
  - Normalization: z-score, mean=1.2450, std=2.5361
  - Normalization: z-score, mean=1.2450, std=2.5361
Loaded test dataset: 42 samples
Loaded test dataset: 42 samples
  - Spectrogram shape: torch.Size([42, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([42, 30, 18, 50, 10])
  - Value range: [-5.2226, 3.1796]
  - Value range: [-5.2226, 3.1796]
  - Class distribution: tensor([21, 21])
  - Class distribution: tensor([21, 21])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb06_fold0\epoch_005.pth...
Loading model checkpoint from model\chb06_fold0\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:  33%|##########3                    | 1/3 [00:00<00:00,  4.12it/s]Testing:  33%|##########3                    | 1/3 [00:00<00:00,  4.12it/s]Testing: 100%|###############################| 3/3 [00:00<00:00,  9.60it/s]Testing: 100%|###############################| 3/3 [00:00<00:00,  9.60it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5912
Loss:      0.5912
Accuracy:  0.6667 (66.67%)
Accuracy:  0.6667 (66.67%)
Precision: 0.6000
Precision: 0.6000
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.7500
F1 Score:  0.7500
AUC-ROC:   0.9048
AUC-ROC:   0.9048

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal         7        14
Actual Interictal         7        14
       Preictal         0        21
       Preictal         0        21

Class Distribution:
Class Distribution:

True Interictal (0): 21 samples
True Interictal (0): 21 samples
True Preictal (1):   21 samples
True Preictal (1):   21 samples
Pred Interictal (0): 7 samples
Pred Interictal (0): 7 samples
Pred Preictal (1):   35 samples
Pred Preictal (1):   35 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.3333    0.5000        21
    Preictal     0.6000    1.0000    0.7500        21

    accuracy                         0.6667        42
   macro avg     0.8000    0.6667    0.6250        42
weighted avg     0.8000    0.6667    0.6250        42
              precision    recall  f1-score   support

  Interictal     1.0000    0.3333    0.5000        21
    Preictal     0.6000    1.0000    0.7500        21

    accuracy                         0.6667        42
   macro avg     0.8000    0.6667    0.6250        42
weighted avg     0.8000    0.6667    0.6250        42



✅ Results saved to model\chb06_fold0\test_results.json
✅ Results saved to model\chb06_fold0\test_results.json


============================================================
============================================================

EVALUATING FOLD 1/9
EVALUATING FOLD 1/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb06_fold1
Dataset prefix: chb06_fold1
Using test dataset: preprocessing\data\chb06_fold1\test_dataset.h5
Using test dataset: preprocessing\data\chb06_fold1\test_dataset.h5
Loading test dataset from preprocessing\data\chb06_fold1\test_dataset.h5...
Loading test dataset from preprocessing\data\chb06_fold1\test_dataset.h5...
  - Normalization: z-score, mean=1.2614, std=2.5059
  - Normalization: z-score, mean=1.2614, std=2.5059
Loaded test dataset: 40 samples
Loaded test dataset: 40 samples
  - Spectrogram shape: torch.Size([40, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([40, 30, 18, 50, 10])
  - Value range: [-5.2922, 3.1617]
  - Value range: [-5.2922, 3.1617]
  - Class distribution: tensor([20, 20])
  - Class distribution: tensor([20, 20])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb06_fold1\epoch_005.pth...
Loading model checkpoint from model\chb06_fold1\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 31.76it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 31.76it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.4830
Loss:      0.4830
Accuracy:  0.8000 (80.00%)
Accuracy:  0.8000 (80.00%)
Precision: 0.7143
Precision: 0.7143
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.8333
F1 Score:  0.8333
AUC-ROC:   0.7975
AUC-ROC:   0.7975

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal        12         8
Actual Interictal        12         8
       Preictal         0        20
       Preictal         0        20

Class Distribution:
Class Distribution:

True Interictal (0): 20 samples
True Interictal (0): 20 samples
True Preictal (1):   20 samples
True Preictal (1):   20 samples
Pred Interictal (0): 12 samples
Pred Interictal (0): 12 samples
Pred Preictal (1):   28 samples
Pred Preictal (1):   28 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.6000    0.7500        20
    Preictal     0.7143    1.0000    0.8333        20

    accuracy                         0.8000        40
   macro avg     0.8571    0.8000    0.7917        40
weighted avg     0.8571    0.8000    0.7917        40
              precision    recall  f1-score   support

  Interictal     1.0000    0.6000    0.7500        20
    Preictal     0.7143    1.0000    0.8333        20

    accuracy                         0.8000        40
   macro avg     0.8571    0.8000    0.7917        40
weighted avg     0.8571    0.8000    0.7917        40



✅ Results saved to model\chb06_fold1\test_results.json
✅ Results saved to model\chb06_fold1\test_results.json


============================================================
============================================================

EVALUATING FOLD 2/9
EVALUATING FOLD 2/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb06_fold2
Dataset prefix: chb06_fold2
Using test dataset: preprocessing\data\chb06_fold2\test_dataset.h5
Using test dataset: preprocessing\data\chb06_fold2\test_dataset.h5
Loading test dataset from preprocessing\data\chb06_fold2\test_dataset.h5...
Loading test dataset from preprocessing\data\chb06_fold2\test_dataset.h5...
  - Normalization: z-score, mean=1.2067, std=2.5301
  - Normalization: z-score, mean=1.2067, std=2.5301
Loaded test dataset: 40 samples
Loaded test dataset: 40 samples
  - Spectrogram shape: torch.Size([40, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([40, 30, 18, 50, 10])
  - Value range: [-5.2198, 3.1561]
  - Value range: [-5.2198, 3.1561]
  - Class distribution: tensor([20, 20])
  - Class distribution: tensor([20, 20])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb06_fold2\epoch_005.pth...
Loading model checkpoint from model\chb06_fold2\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 34.44it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 34.44it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5848
Loss:      0.5848
Accuracy:  0.6250 (62.50%)
Accuracy:  0.6250 (62.50%)
Precision: 0.5926
Precision: 0.5926
Recall:    0.8000
Recall:    0.8000
F1 Score:  0.6809
F1 Score:  0.6809
AUC-ROC:   0.5300
AUC-ROC:   0.5300

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal         9        11
Actual Interictal         9        11
       Preictal         4        16
       Preictal         4        16

Class Distribution:
Class Distribution:

True Interictal (0): 20 samples
True Interictal (0): 20 samples
True Preictal (1):   20 samples
True Preictal (1):   20 samples
Pred Interictal (0): 13 samples
Pred Interictal (0): 13 samples
Pred Preictal (1):   27 samples
Pred Preictal (1):   27 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     0.6923    0.4500    0.5455        20
    Preictal     0.5926    0.8000    0.6809        20

    accuracy                         0.6250        40
   macro avg     0.6425    0.6250    0.6132        40
weighted avg     0.6425    0.6250    0.6132        40
              precision    recall  f1-score   support

  Interictal     0.6923    0.4500    0.5455        20
    Preictal     0.5926    0.8000    0.6809        20

    accuracy                         0.6250        40
   macro avg     0.6425    0.6250    0.6132        40
weighted avg     0.6425    0.6250    0.6132        40



✅ Results saved to model\chb06_fold2\test_results.json
✅ Results saved to model\chb06_fold2\test_results.json


============================================================
============================================================

EVALUATING FOLD 3/9
EVALUATING FOLD 3/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb06_fold3
Dataset prefix: chb06_fold3
Using test dataset: preprocessing\data\chb06_fold3\test_dataset.h5
Using test dataset: preprocessing\data\chb06_fold3\test_dataset.h5
Loading test dataset from preprocessing\data\chb06_fold3\test_dataset.h5...
Loading test dataset from preprocessing\data\chb06_fold3\test_dataset.h5...
  - Normalization: z-score, mean=1.1917, std=2.5462
  - Normalization: z-score, mean=1.1917, std=2.5462
Loaded test dataset: 40 samples
Loaded test dataset: 40 samples
  - Spectrogram shape: torch.Size([40, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([40, 30, 18, 50, 10])
  - Value range: [-5.1809, 3.1722]
  - Value range: [-5.1809, 3.1722]
  - Class distribution: tensor([20, 20])
  - Class distribution: tensor([20, 20])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb06_fold3\epoch_005.pth...
Loading model checkpoint from model\chb06_fold3\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 34.10it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 34.10it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5138
Loss:      0.5138
Accuracy:  0.7500 (75.00%)
Accuracy:  0.7500 (75.00%)
Precision: 0.6667
Precision: 0.6667
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.8000
F1 Score:  0.8000
AUC-ROC:   0.8500
AUC-ROC:   0.8500

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal        10        10
Actual Interictal        10        10
       Preictal         0        20
       Preictal         0        20

Class Distribution:
Class Distribution:

True Interictal (0): 20 samples
True Interictal (0): 20 samples
True Preictal (1):   20 samples
True Preictal (1):   20 samples
Pred Interictal (0): 10 samples
Pred Interictal (0): 10 samples
Pred Preictal (1):   30 samples
Pred Preictal (1):   30 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.5000    0.6667        20
    Preictal     0.6667    1.0000    0.8000        20

    accuracy                         0.7500        40
   macro avg     0.8333    0.7500    0.7333        40
weighted avg     0.8333    0.7500    0.7333        40
              precision    recall  f1-score   support

  Interictal     1.0000    0.5000    0.6667        20
    Preictal     0.6667    1.0000    0.8000        20

    accuracy                         0.7500        40
   macro avg     0.8333    0.7500    0.7333        40
weighted avg     0.8333    0.7500    0.7333        40



✅ Results saved to model\chb06_fold3\test_results.json
✅ Results saved to model\chb06_fold3\test_results.json


============================================================
============================================================

EVALUATING FOLD 4/9
EVALUATING FOLD 4/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb06_fold4
Dataset prefix: chb06_fold4
Using test dataset: preprocessing\data\chb06_fold4\test_dataset.h5
Using test dataset: preprocessing\data\chb06_fold4\test_dataset.h5
Loading test dataset from preprocessing\data\chb06_fold4\test_dataset.h5...
Loading test dataset from preprocessing\data\chb06_fold4\test_dataset.h5...
  - Normalization: z-score, mean=1.2546, std=2.5048
  - Normalization: z-score, mean=1.2546, std=2.5048
Loaded test dataset: 40 samples
Loaded test dataset: 40 samples
  - Spectrogram shape: torch.Size([40, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([40, 30, 18, 50, 10])
  - Value range: [-5.2917, 3.1429]
  - Value range: [-5.2917, 3.1429]
  - Class distribution: tensor([20, 20])
  - Class distribution: tensor([20, 20])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb06_fold4\epoch_005.pth...
Loading model checkpoint from model\chb06_fold4\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 33.96it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 33.96it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.8222
Loss:      0.8222
Accuracy:  0.2500 (25.00%)
Accuracy:  0.2500 (25.00%)
Precision: 0.0000
Precision: 0.0000
Recall:    0.0000
Recall:    0.0000
F1 Score:  0.0000
F1 Score:  0.0000
AUC-ROC:   0.4575
AUC-ROC:   0.4575

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal        10        10
Actual Interictal        10        10
       Preictal        20         0
       Preictal        20         0

Class Distribution:
Class Distribution:

True Interictal (0): 20 samples
True Interictal (0): 20 samples
True Preictal (1):   20 samples
True Preictal (1):   20 samples
Pred Interictal (0): 30 samples
Pred Interictal (0): 30 samples
Pred Preictal (1):   10 samples
Pred Preictal (1):   10 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     0.3333    0.5000    0.4000        20
    Preictal     0.0000    0.0000    0.0000        20

    accuracy                         0.2500        40
   macro avg     0.1667    0.2500    0.2000        40
weighted avg     0.1667    0.2500    0.2000        40
              precision    recall  f1-score   support

  Interictal     0.3333    0.5000    0.4000        20
    Preictal     0.0000    0.0000    0.0000        20

    accuracy                         0.2500        40
   macro avg     0.1667    0.2500    0.2000        40
weighted avg     0.1667    0.2500    0.2000        40



✅ Results saved to model\chb06_fold4\test_results.json
✅ Results saved to model\chb06_fold4\test_results.json


============================================================
============================================================

EVALUATING FOLD 5/9
EVALUATING FOLD 5/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb06_fold5
Dataset prefix: chb06_fold5
Using test dataset: preprocessing\data\chb06_fold5\test_dataset.h5
Using test dataset: preprocessing\data\chb06_fold5\test_dataset.h5
Loading test dataset from preprocessing\data\chb06_fold5\test_dataset.h5...
Loading test dataset from preprocessing\data\chb06_fold5\test_dataset.h5...
  - Normalization: z-score, mean=1.2791, std=2.5262
  - Normalization: z-score, mean=1.2791, std=2.5262
Loaded test dataset: 30 samples
Loaded test dataset: 30 samples
  - Spectrogram shape: torch.Size([30, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([30, 30, 18, 50, 10])
  - Value range: [-5.2566, 3.0985]
  - Value range: [-5.2566, 3.0985]
  - Class distribution: tensor([15, 15])
  - Class distribution: tensor([15, 15])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb06_fold5\epoch_005.pth...
Loading model checkpoint from model\chb06_fold5\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/2 [00:00<?, ?it/s]Testing:   0%|                                       | 0/2 [00:00<?, ?it/s]Testing: 100%|###############################| 2/2 [00:00<00:00, 29.01it/s]Testing: 100%|###############################| 2/2 [00:00<00:00, 29.01it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5223
Loss:      0.5223
Accuracy:  0.8000 (80.00%)
Accuracy:  0.8000 (80.00%)
Precision: 0.7143
Precision: 0.7143
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.8333
F1 Score:  0.8333
AUC-ROC:   0.6222
AUC-ROC:   0.6222

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal         9         6
Actual Interictal         9         6
       Preictal         0        15
       Preictal         0        15

Class Distribution:
Class Distribution:

True Interictal (0): 15 samples
True Interictal (0): 15 samples
True Preictal (1):   15 samples
True Preictal (1):   15 samples
Pred Interictal (0): 9 samples
Pred Interictal (0): 9 samples
Pred Preictal (1):   21 samples
Pred Preictal (1):   21 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.6000    0.7500        15
    Preictal     0.7143    1.0000    0.8333        15

    accuracy                         0.8000        30
   macro avg     0.8571    0.8000    0.7917        30
weighted avg     0.8571    0.8000    0.7917        30
              precision    recall  f1-score   support

  Interictal     1.0000    0.6000    0.7500        15
    Preictal     0.7143    1.0000    0.8333        15

    accuracy                         0.8000        30
   macro avg     0.8571    0.8000    0.7917        30
weighted avg     0.8571    0.8000    0.7917        30



✅ Results saved to model\chb06_fold5\test_results.json
✅ Results saved to model\chb06_fold5\test_results.json


============================================================
============================================================

EVALUATING FOLD 6/9
EVALUATING FOLD 6/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb06_fold6
Dataset prefix: chb06_fold6
Using test dataset: preprocessing\data\chb06_fold6\test_dataset.h5
Using test dataset: preprocessing\data\chb06_fold6\test_dataset.h5
Loading test dataset from preprocessing\data\chb06_fold6\test_dataset.h5...
Loading test dataset from preprocessing\data\chb06_fold6\test_dataset.h5...
  - Normalization: z-score, mean=1.2299, std=2.5478
  - Normalization: z-score, mean=1.2299, std=2.5478
Loaded test dataset: 48 samples
Loaded test dataset: 48 samples
  - Spectrogram shape: torch.Size([48, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([48, 30, 18, 50, 10])
  - Value range: [-5.1927, 3.1744]
  - Value range: [-5.1927, 3.1744]
  - Class distribution: tensor([24, 24])
  - Class distribution: tensor([24, 24])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb06_fold6\epoch_005.pth...
Loading model checkpoint from model\chb06_fold6\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 29.99it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 29.99it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 29.90it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 29.90it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.3918
Loss:      0.3918
Accuracy:  0.8750 (87.50%)
Accuracy:  0.8750 (87.50%)
Precision: 0.8000
Precision: 0.8000
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.8889
F1 Score:  0.8889
AUC-ROC:   0.9688
AUC-ROC:   0.9688

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal        18         6
Actual Interictal        18         6
       Preictal         0        24
       Preictal         0        24

Class Distribution:
Class Distribution:

True Interictal (0): 24 samples
True Interictal (0): 24 samples
True Preictal (1):   24 samples
True Preictal (1):   24 samples
Pred Interictal (0): 18 samples
Pred Interictal (0): 18 samples
Pred Preictal (1):   30 samples
Pred Preictal (1):   30 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.7500    0.8571        24
    Preictal     0.8000    1.0000    0.8889        24

    accuracy                         0.8750        48
   macro avg     0.9000    0.8750    0.8730        48
weighted avg     0.9000    0.8750    0.8730        48
              precision    recall  f1-score   support

  Interictal     1.0000    0.7500    0.8571        24
    Preictal     0.8000    1.0000    0.8889        24

    accuracy                         0.8750        48
   macro avg     0.9000    0.8750    0.8730        48
weighted avg     0.9000    0.8750    0.8730        48



✅ Results saved to model\chb06_fold6\test_results.json
✅ Results saved to model\chb06_fold6\test_results.json


============================================================
============================================================

EVALUATING FOLD 7/9
EVALUATING FOLD 7/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb06_fold7
Dataset prefix: chb06_fold7
Using test dataset: preprocessing\data\chb06_fold7\test_dataset.h5
Using test dataset: preprocessing\data\chb06_fold7\test_dataset.h5
Loading test dataset from preprocessing\data\chb06_fold7\test_dataset.h5...
Loading test dataset from preprocessing\data\chb06_fold7\test_dataset.h5...
  - Normalization: z-score, mean=1.2923, std=2.5008
  - Normalization: z-score, mean=1.2923, std=2.5008
Loaded test dataset: 44 samples
Loaded test dataset: 44 samples
  - Spectrogram shape: torch.Size([44, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([44, 30, 18, 50, 10])
  - Value range: [-5.3152, 3.1228]
  - Value range: [-5.3152, 3.1228]
  - Class distribution: tensor([22, 22])
  - Class distribution: tensor([22, 22])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb06_fold7\epoch_005.pth...
Loading model checkpoint from model\chb06_fold7\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 31.39it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 31.39it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5708
Loss:      0.5708
Accuracy:  0.6364 (63.64%)
Accuracy:  0.6364 (63.64%)
Precision: 0.6154
Precision: 0.6154
Recall:    0.7273
Recall:    0.7273
F1 Score:  0.6667
F1 Score:  0.6667
AUC-ROC:   0.6591
AUC-ROC:   0.6591

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal        12        10
Actual Interictal        12        10
       Preictal         6        16
       Preictal         6        16

Class Distribution:
Class Distribution:

True Interictal (0): 22 samples
True Interictal (0): 22 samples
True Preictal (1):   22 samples
True Preictal (1):   22 samples
Pred Interictal (0): 18 samples
Pred Interictal (0): 18 samples
Pred Preictal (1):   26 samples
Pred Preictal (1):   26 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     0.6667    0.5455    0.6000        22
    Preictal     0.6154    0.7273    0.6667        22

    accuracy                         0.6364        44
   macro avg     0.6410    0.6364    0.6333        44
weighted avg     0.6410    0.6364    0.6333        44
              precision    recall  f1-score   support

  Interictal     0.6667    0.5455    0.6000        22
    Preictal     0.6154    0.7273    0.6667        22

    accuracy                         0.6364        44
   macro avg     0.6410    0.6364    0.6333        44
weighted avg     0.6410    0.6364    0.6333        44



✅ Results saved to model\chb06_fold7\test_results.json
✅ Results saved to model\chb06_fold7\test_results.json


============================================================
============================================================

EVALUATING FOLD 8/9
EVALUATING FOLD 8/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb06_fold8
Dataset prefix: chb06_fold8
Using test dataset: preprocessing\data\chb06_fold8\test_dataset.h5
Using test dataset: preprocessing\data\chb06_fold8\test_dataset.h5
Loading test dataset from preprocessing\data\chb06_fold8\test_dataset.h5...
Loading test dataset from preprocessing\data\chb06_fold8\test_dataset.h5...
  - Normalization: z-score, mean=1.2104, std=2.5328
  - Normalization: z-score, mean=1.2104, std=2.5328
Loaded test dataset: 492 samples
Loaded test dataset: 492 samples
  - Spectrogram shape: torch.Size([492, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([492, 30, 18, 50, 10])
  - Value range: [-5.2157, 3.2609]
  - Value range: [-5.2157, 3.2609]
  - Class distribution: tensor([492])
  - Class distribution: tensor([492])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb06_fold8\epoch_005.pth...
Loading model checkpoint from model\chb06_fold8\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                      | 0/31 [00:00<?, ?it/s]Testing:   0%|                                      | 0/31 [00:00<?, ?it/s]Testing:  13%|###8                          | 4/31 [00:00<00:00, 31.04it/s]Testing:  13%|###8                          | 4/31 [00:00<00:00, 31.04it/s]Testing:  26%|#######7                      | 8/31 [00:00<00:00, 29.83it/s]Testing:  26%|#######7                      | 8/31 [00:00<00:00, 29.83it/s]Testing:  39%|###########2                 | 12/31 [00:00<00:00, 30.51it/s]Testing:  39%|###########2                 | 12/31 [00:00<00:00, 30.51it/s]Testing:  52%|##############9              | 16/31 [00:00<00:00, 31.04it/s]Testing:  52%|##############9              | 16/31 [00:00<00:00, 31.04it/s]Testing:  65%|##################7          | 20/31 [00:00<00:00, 31.47it/s]Testing:  65%|##################7          | 20/31 [00:00<00:00, 31.47it/s]Testing:  77%|######################4      | 24/31 [00:00<00:00, 31.54it/s]Testing:  77%|######################4      | 24/31 [00:00<00:00, 31.54it/s]Testing:  90%|##########################1  | 28/31 [00:00<00:00, 31.82it/s]Testing:  90%|##########################1  | 28/31 [00:00<00:00, 31.82it/s]Testing: 100%|#############################| 31/31 [00:00<00:00, 31.57it/s]Testing: 100%|#############################| 31/31 [00:00<00:00, 31.57it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5728
Loss:      0.5728
Accuracy:  0.5325 (53.25%)
Accuracy:  0.5325 (53.25%)
Precision: 0.0000
Precision: 0.0000
Recall:    0.0000
Recall:    0.0000
F1 Score:  0.0000
F1 Score:  0.0000
AUC-ROC:   0.0000
AUC-ROC:   0.0000

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal       262       230
Actual Interictal       262       230
       Preictal         0         0
       Preictal         0         0

Class Distribution:
Class Distribution:

True Interictal (0): 492 samples
True Interictal (0): 492 samples
True Preictal (1):   0 samples
True Preictal (1):   0 samples
Pred Interictal (0): 262 samples
Pred Interictal (0): 262 samples
Pred Preictal (1):   230 samples
Pred Preictal (1):   230 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.5325    0.6950       492
    Preictal     0.0000    0.0000    0.0000         0

    accuracy                         0.5325       492
   macro avg     0.5000    0.2663    0.3475       492
weighted avg     1.0000    0.5325    0.6950       492
              precision    recall  f1-score   support

  Interictal     1.0000    0.5325    0.6950       492
    Preictal     0.0000    0.0000    0.0000         0

    accuracy                         0.5325       492
   macro avg     0.5000    0.2663    0.3475       492
weighted avg     1.0000    0.5325    0.6950       492



✅ Results saved to model\chb06_fold8\test_results.json
✅ Results saved to model\chb06_fold8\test_results.json


============================================================
============================================================

EVALUATING FOLD 9/9
EVALUATING FOLD 9/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb06_fold9
Dataset prefix: chb06_fold9
Using test dataset: preprocessing\data\chb06_fold9\test_dataset.h5
Using test dataset: preprocessing\data\chb06_fold9\test_dataset.h5
Loading test dataset from preprocessing\data\chb06_fold9\test_dataset.h5...
Loading test dataset from preprocessing\data\chb06_fold9\test_dataset.h5...
  - Normalization: z-score, mean=1.2520, std=2.5015
  - Normalization: z-score, mean=1.2520, std=2.5015
Loaded test dataset: 492 samples
Loaded test dataset: 492 samples
  - Spectrogram shape: torch.Size([492, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([492, 30, 18, 50, 10])
  - Value range: [-5.2977, 3.2997]
  - Value range: [-5.2977, 3.2997]
  - Class distribution: tensor([492])
  - Class distribution: tensor([492])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb06_fold9\epoch_005.pth...
Loading model checkpoint from model\chb06_fold9\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                      | 0/31 [00:00<?, ?it/s]Testing:   0%|                                      | 0/31 [00:00<?, ?it/s]Testing:  13%|###8                          | 4/31 [00:00<00:00, 31.32it/s]Testing:  13%|###8                          | 4/31 [00:00<00:00, 31.32it/s]Testing:  26%|#######7                      | 8/31 [00:00<00:00, 30.77it/s]Testing:  26%|#######7                      | 8/31 [00:00<00:00, 30.77it/s]Testing:  39%|###########2                 | 12/31 [00:00<00:00, 30.40it/s]Testing:  39%|###########2                 | 12/31 [00:00<00:00, 30.40it/s]Testing:  52%|##############9              | 16/31 [00:00<00:00, 30.66it/s]Testing:  52%|##############9              | 16/31 [00:00<00:00, 30.66it/s]Testing:  65%|##################7          | 20/31 [00:00<00:00, 30.66it/s]Testing:  65%|##################7          | 20/31 [00:00<00:00, 30.66it/s]Testing:  77%|######################4      | 24/31 [00:00<00:00, 30.95it/s]Testing:  77%|######################4      | 24/31 [00:00<00:00, 30.95it/s]Testing:  90%|##########################1  | 28/31 [00:00<00:00, 31.17it/s]Testing:  90%|##########################1  | 28/31 [00:00<00:00, 31.17it/s]Testing: 100%|#############################| 31/31 [00:00<00:00, 31.15it/s]Testing: 100%|#############################| 31/31 [00:00<00:00, 31.15it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5476
Loss:      0.5476
Accuracy:  0.5488 (54.88%)
Accuracy:  0.5488 (54.88%)
Precision: 0.0000
Precision: 0.0000
Recall:    0.0000
Recall:    0.0000
F1 Score:  0.0000
F1 Score:  0.0000
AUC-ROC:   0.0000
AUC-ROC:   0.0000

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal       270       222
Actual Interictal       270       222
       Preictal         0         0
       Preictal         0         0

Class Distribution:
Class Distribution:

True Interictal (0): 492 samples
True Interictal (0): 492 samples
True Preictal (1):   0 samples
True Preictal (1):   0 samples
Pred Interictal (0): 270 samples
Pred Interictal (0): 270 samples
Pred Preictal (1):   222 samples
Pred Preictal (1):   222 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.5488    0.7087       492
    Preictal     0.0000    0.0000    0.0000         0

    accuracy                         0.5488       492
   macro avg     0.5000    0.2744    0.3543       492
weighted avg     1.0000    0.5488    0.7087       492
              precision    recall  f1-score   support

  Interictal     1.0000    0.5488    0.7087       492
    Preictal     0.0000    0.0000    0.0000         0

    accuracy                         0.5488       492
   macro avg     0.5000    0.2744    0.3543       492
weighted avg     1.0000    0.5488    0.7087       492



✅ Results saved to model\chb06_fold9\test_results.json
✅ Results saved to model\chb06_fold9\test_results.json


============================================================
============================================================

BATCH EVALUATION SUMMARY
BATCH EVALUATION SUMMARY
============================================================
============================================================
Folds evaluated: 10/10
Folds evaluated: 10/10

Mean metrics (across folds):
Mean metrics (across folds):

  Accuracy:  0.6484 (±0.1705)
  Accuracy:  0.6484 (±0.1705)
  Precision: 0.4703 (±0.3135)
  Precision: 0.4703 (±0.3135)
  Recall:    0.6527 (±0.4369)
  Recall:    0.6527 (±0.4369)
  F1 Score:  0.5453 (±0.3628)
  F1 Score:  0.5453 (±0.3628)
  AUC-ROC:   0.5790 (±0.3279)
  AUC-ROC:   0.5790 (±0.3279)

✅ Batch results saved to model\batch_test_results.json
✅ Batch results saved to model\batch_test_results.json

============================================================
============================================================
