============================================================
BATCH PROCESSING: ALL FOLDS
Processing 10 folds for patient chb16
============================================================

Configuration:
  - Task mode: PREDICTION (preictal vs interictal)
  - LOOCV Mode: ENABLED
  - Sequence length: 30 segments
  - Sequence duration: 150s (2.5 min)
  - Stride: 5 segments (83% overlap)
  - Segment duration: 5s
  - Preictal window: 10 min
  - Interictal buffer: 120 min
  - Channel validation: ENABLED
  - Target channels: 18 channels
============================================================

Extracting sequences from patient chb16...
Patient chb16: 375 sequences (199 preictal, 176 interictal)

============================================================
PROCESSING FOLD 0/9
============================================================
Output prefix: chb16_fold0
LOOCV Fold 0: Test seizure=0, Train seizures=[1, 2, 3, 4, 5, 6, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 216
  - Preictal sequences: 108
  - Interictal sequences: 108
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb16: 216 total (108 preictal, 108 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 40 total (20 preictal, 20 interictal)
train: 176 total (88 preictal, 88 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 257.1s (4.3 min)
Class balance: 108/108 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 88 preictal, 88 interictal (dropped 91 preictal, 0 interictal)
test: 20 preictal, 20 interictal (dropped 0 preictal, 68 interictal)

Sequences saved to chb16_fold0_sequences_prediction.json
File size: 0.36 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 19
Files with valid channels: 19
Files with invalid channels: 0

✅ Fold 0 completed successfully!
✅ Sequences saved to chb16_fold0_sequences_prediction.json

============================================================
PROCESSING FOLD 1/9
============================================================
Output prefix: chb16_fold1
LOOCV Fold 1: Test seizure=1, Train seizures=[0, 2, 3, 4, 5, 6, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 218
  - Preictal sequences: 109
  - Interictal sequences: 109
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb16: 218 total (109 preictal, 109 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 42 total (21 preictal, 21 interictal)
train: 176 total (88 preictal, 88 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 255.1s (4.3 min)
Class balance: 109/109 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 88 preictal, 88 interictal (dropped 90 preictal, 0 interictal)
test: 21 preictal, 21 interictal (dropped 0 preictal, 67 interictal)

Sequences saved to chb16_fold1_sequences_prediction.json
File size: 0.37 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 19
Files with valid channels: 19
Files with invalid channels: 0

✅ Fold 1 completed successfully!
✅ Sequences saved to chb16_fold1_sequences_prediction.json

============================================================
PROCESSING FOLD 2/9
============================================================
Output prefix: chb16_fold2
LOOCV Fold 2: Test seizure=2, Train seizures=[0, 1, 3, 4, 5, 6, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 218
  - Preictal sequences: 109
  - Interictal sequences: 109
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb16: 218 total (109 preictal, 109 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 42 total (21 preictal, 21 interictal)
train: 176 total (88 preictal, 88 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 245.2s (4.1 min)
Class balance: 109/109 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 88 preictal, 88 interictal (dropped 90 preictal, 0 interictal)
test: 21 preictal, 21 interictal (dropped 0 preictal, 67 interictal)

Sequences saved to chb16_fold2_sequences_prediction.json
File size: 0.37 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 19
Files with valid channels: 19
Files with invalid channels: 0

✅ Fold 2 completed successfully!
✅ Sequences saved to chb16_fold2_sequences_prediction.json

============================================================
PROCESSING FOLD 3/9
============================================================
Output prefix: chb16_fold3
LOOCV Fold 3: Test seizure=3, Train seizures=[0, 1, 2, 4, 5, 6, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 214
  - Preictal sequences: 107
  - Interictal sequences: 107
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb16: 214 total (107 preictal, 107 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 38 total (19 preictal, 19 interictal)
train: 176 total (88 preictal, 88 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 240.2s (4.0 min)
Class balance: 107/107 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 88 preictal, 88 interictal (dropped 92 preictal, 0 interictal)
test: 19 preictal, 19 interictal (dropped 0 preictal, 69 interictal)

Sequences saved to chb16_fold3_sequences_prediction.json
File size: 0.36 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 19
Files with valid channels: 19
Files with invalid channels: 0

✅ Fold 3 completed successfully!
✅ Sequences saved to chb16_fold3_sequences_prediction.json

============================================================
PROCESSING FOLD 4/9
============================================================
Output prefix: chb16_fold4
LOOCV Fold 4: Test seizure=4, Train seizures=[0, 1, 2, 3, 5, 6, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 206
  - Preictal sequences: 103
  - Interictal sequences: 103
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb16: 206 total (103 preictal, 103 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 30 total (15 preictal, 15 interictal)
train: 176 total (88 preictal, 88 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 263.7s (4.4 min)
Class balance: 103/103 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 88 preictal, 88 interictal (dropped 96 preictal, 0 interictal)
test: 15 preictal, 15 interictal (dropped 0 preictal, 73 interictal)

Sequences saved to chb16_fold4_sequences_prediction.json
File size: 0.35 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 19
Files with valid channels: 19
Files with invalid channels: 0

✅ Fold 4 completed successfully!
✅ Sequences saved to chb16_fold4_sequences_prediction.json

============================================================
PROCESSING FOLD 5/9
============================================================
Output prefix: chb16_fold5
LOOCV Fold 5: Test seizure=5, Train seizures=[0, 1, 2, 3, 4, 6, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 220
  - Preictal sequences: 110
  - Interictal sequences: 110
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb16: 220 total (110 preictal, 110 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 44 total (22 preictal, 22 interictal)
train: 176 total (88 preictal, 88 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 257.4s (4.3 min)
Class balance: 110/110 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 88 preictal, 88 interictal (dropped 89 preictal, 0 interictal)
test: 22 preictal, 22 interictal (dropped 0 preictal, 66 interictal)

Sequences saved to chb16_fold5_sequences_prediction.json
File size: 0.37 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 19
Files with valid channels: 19
Files with invalid channels: 0

✅ Fold 5 completed successfully!
✅ Sequences saved to chb16_fold5_sequences_prediction.json

============================================================
PROCESSING FOLD 6/9
============================================================
Output prefix: chb16_fold6
LOOCV Fold 6: Test seizure=6, Train seizures=[0, 1, 2, 3, 4, 5, 7, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 214
  - Preictal sequences: 107
  - Interictal sequences: 107
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb16: 214 total (107 preictal, 107 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 38 total (19 preictal, 19 interictal)
train: 176 total (88 preictal, 88 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 259.7s (4.3 min)
Class balance: 107/107 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 88 preictal, 88 interictal (dropped 92 preictal, 0 interictal)
test: 19 preictal, 19 interictal (dropped 0 preictal, 69 interictal)

Sequences saved to chb16_fold6_sequences_prediction.json
File size: 0.36 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 19
Files with valid channels: 19
Files with invalid channels: 0

✅ Fold 6 completed successfully!
✅ Sequences saved to chb16_fold6_sequences_prediction.json

============================================================
PROCESSING FOLD 7/9
============================================================
Output prefix: chb16_fold7
LOOCV Fold 7: Test seizure=7, Train seizures=[0, 1, 2, 3, 4, 5, 6, 8, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 218
  - Preictal sequences: 109
  - Interictal sequences: 109
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb16: 218 total (109 preictal, 109 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 42 total (21 preictal, 21 interictal)
train: 176 total (88 preictal, 88 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 258.4s (4.3 min)
Class balance: 109/109 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 88 preictal, 88 interictal (dropped 90 preictal, 0 interictal)
test: 21 preictal, 21 interictal (dropped 0 preictal, 67 interictal)

Sequences saved to chb16_fold7_sequences_prediction.json
File size: 0.37 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 19
Files with valid channels: 19
Files with invalid channels: 0

✅ Fold 7 completed successfully!
✅ Sequences saved to chb16_fold7_sequences_prediction.json

============================================================
PROCESSING FOLD 8/9
============================================================
Output prefix: chb16_fold8
LOOCV Fold 8: Test seizure=8, Train seizures=[0, 1, 2, 3, 4, 5, 6, 7, 9]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 216
  - Preictal sequences: 108
  - Interictal sequences: 108
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb16: 216 total (108 preictal, 108 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 40 total (20 preictal, 20 interictal)
train: 176 total (88 preictal, 88 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 249.1s (4.2 min)
Class balance: 108/108 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 88 preictal, 88 interictal (dropped 91 preictal, 0 interictal)
test: 20 preictal, 20 interictal (dropped 0 preictal, 68 interictal)

Sequences saved to chb16_fold8_sequences_prediction.json
File size: 0.36 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 19
Files with valid channels: 19
Files with invalid channels: 0

✅ Fold 8 completed successfully!
✅ Sequences saved to chb16_fold8_sequences_prediction.json

============================================================
PROCESSING FOLD 9/9
============================================================
Output prefix: chb16_fold9
LOOCV Fold 9: Test seizure=9, Train seizures=[0, 1, 2, 3, 4, 5, 6, 7, 8]

============================================================
FOLD SPLIT SUMMARY
============================================================

=== OVERALL SUMMARY ===
Task mode: PREDICTION
Total sequences: 218
  - Preictal sequences: 109
  - Interictal sequences: 109
Sequence configuration:
  - Segments per sequence: 30
  - Sequence duration: 150s (2.5 min)
  - Sequence stride: 5 segments (25s)
  - Preictal window: 10 min
  - Interictal buffer: 120 min

=== PER-PATIENT BREAKDOWN ===
Patients processed: 1
chb16: 218 total (109 preictal, 109 interictal)

=== PER-SPLIT BREAKDOWN ===
test: 42 total (21 preictal, 21 interictal)
train: 176 total (88 preictal, 88 interictal)

=== STATISTICS ===
Average time to seizure (preictal): 239.4s (4.0 min)
Class balance: 109/109 = 1.00

=== SPLIT BALANCING SUMMARY ===
train: 88 preictal, 88 interictal (dropped 90 preictal, 0 interictal)
test: 21 preictal, 21 interictal (dropped 0 preictal, 67 interictal)

Sequences saved to chb16_fold9_sequences_prediction.json
File size: 0.37 MB

=== CHANNEL VALIDATION SUMMARY ===
Validation enabled: True
Files checked: 19
Files with valid channels: 19
Files with invalid channels: 0

✅ Fold 9 completed successfully!
✅ Sequences saved to chb16_fold9_sequences_prediction.json

============================================================
✅ BATCH PROCESSING COMPLETED!
✅ Processed 10 folds for patient chb16
============================================================
============================================================
BATCH PROCESSING: ALL FOLDS
Processing 10 folds for patient chb16
============================================================

============================================================
PREPROCESSING FOLD 0/9
============================================================
2025-11-19 13:04:32,237 - INFO - ============================================================
2025-11-19 13:04:32,238 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 13:04:32,238 - INFO - ============================================================
2025-11-19 13:04:32,238 - INFO - Output prefix: chb16_fold0
2025-11-19 13:04:32,238 - INFO - EEG Preprocessor initialized
2025-11-19 13:04:32,238 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 13:04:32,238 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 13:04:32,238 - INFO - Segment duration: 5 seconds
2025-11-19 13:04:32,238 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 13:04:32,238 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 13:04:32,238 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 13:04:32,238 - INFO - Loading segments from chb16_fold0_sequences_prediction.json
2025-11-19 13:04:32,250 - INFO - Loaded 216 total sequences
2025-11-19 13:04:32,250 - INFO - Channel validation (from segmentation): 19/19 files valid
2025-11-19 13:04:32,250 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 13:04:32,250 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 13:04:32,250 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 13:04:32,250 - INFO - train: 176 sequences (88 preictal, 88 interictal)
2025-11-19 13:04:32,250 - INFO - test: 40 sequences (20 preictal, 20 interictal)
2025-11-19 13:04:32,262 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 13:04:32,262 - INFO - train: kept 88 preictal and 88 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:04:32,262 - INFO - test: kept 20 preictal and 20 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:04:32,273 - INFO - ============================================================
2025-11-19 13:04:32,273 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 13:04:32,273 - INFO - ============================================================
2025-11-19 13:04:32,273 - INFO - Processing 176 training samples to compute normalization stats...
2025-11-19 13:04:32,274 - INFO - Processing 176 sequences from 13 unique files
Processing training data:   0%|                    | 0/176 [00:00<?, ?it/s]Processing training data:   1%|            | 1/176 [00:02<06:47,  2.33s/it]Processing training data:  14%|#5         | 24/176 [00:02<00:13, 11.09it/s]Processing training data:  19%|##1        | 34/176 [00:04<00:15,  8.88it/s]Processing training data:  38%|####1      | 67/176 [00:05<00:07, 14.92it/s]Processing training data:  44%|####8      | 78/176 [00:06<00:07, 12.89it/s]Processing training data:  51%|#####5     | 89/176 [00:08<00:07, 11.24it/s]Processing training data:  57%|#####7    | 101/176 [00:09<00:07, 10.05it/s]Processing training data:  67%|######7   | 118/176 [00:10<00:04, 11.84it/s]Processing training data:  71%|#######1  | 125/176 [00:12<00:05,  9.60it/s]Processing training data:  79%|#######8  | 139/176 [00:13<00:03,  9.56it/s]Processing training data:  85%|########5 | 150/176 [00:14<00:02,  9.66it/s]Processing training data:  90%|########9 | 158/176 [00:16<00:02,  8.33it/s]Processing training data:  96%|#########6| 169/176 [00:16<00:00, 10.26it/s]Processing training data: 100%|##########| 176/176 [00:16<00:00, 10.55it/s]
2025-11-19 13:04:48,953 - INFO - Computing normalization statistics from training data...
2025-11-19 13:04:49,216 - INFO - Normalization stats computed:
2025-11-19 13:04:49,216 - INFO -   Mean: 0.435590
2025-11-19 13:04:49,216 - INFO -   Std: 2.099038
2025-11-19 13:04:49,216 - INFO -   Saved to: preprocessing\checkpoints\chb16_fold0\normalization_stats.json
2025-11-19 13:04:49,246 - INFO - Applying normalization and saving 176 training sequences...
Normalizing and saving training data:   0%|        | 0/176 [00:00<?, ?it/s]2025-11-19 13:04:49,254 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold0\train_dataset.h5
Normalizing and saving training data:   6%| | 10/176 [00:00<00:10, 15.39it/Normalizing and saving training data:  11%|1| 20/176 [00:01<00:10, 14.91it/Normalizing and saving training data:  17%|1| 30/176 [00:01<00:09, 15.15it/Normalizing and saving training data:  23%|2| 40/176 [00:02<00:09, 15.06it/Normalizing and saving training data:  28%|2| 50/176 [00:03<00:08, 15.27it/Normalizing and saving training data:  34%|3| 60/176 [00:03<00:07, 15.47it/Normalizing and saving training data:  40%|3| 70/176 [00:04<00:06, 15.60it/Normalizing and saving training data:  45%|4| 80/176 [00:05<00:06, 15.66it/Normalizing and saving training data:  51%|5| 90/176 [00:05<00:05, 15.41it/Normalizing and saving training data:  57%|5| 100/176 [00:06<00:04, 15.48itNormalizing and saving training data:  62%|6| 110/176 [00:07<00:04, 15.58itNormalizing and saving training data:  68%|6| 120/176 [00:07<00:03, 15.33itNormalizing and saving training data:  74%|7| 130/176 [00:08<00:02, 15.35itNormalizing and saving training data:  80%|7| 140/176 [00:09<00:02, 15.44itNormalizing and saving training data:  85%|8| 150/176 [00:09<00:01, 15.47itNormalizing and saving training data:  91%|9| 160/176 [00:10<00:01, 15.44itNormalizing and saving training data:  97%|9| 170/176 [00:11<00:00, 15.45itNormalizing and saving training data: 100%|#| 176/176 [00:11<00:00, 15.94it
2025-11-19 13:05:00,704 - INFO - Training data processing completed during stats computation phase
2025-11-19 13:05:00,711 - INFO - Loaded normalization statistics:
2025-11-19 13:05:00,711 - INFO -   Mean: 0.435590
2025-11-19 13:05:00,711 - INFO -   Std: 2.099038
2025-11-19 13:05:00,711 - INFO - Split train already completed, skipping
2025-11-19 13:05:00,711 - INFO - Processing test split...
2025-11-19 13:05:00,711 - INFO - Need to process 40/40 sequences for test
2025-11-19 13:05:00,711 - INFO - Processing 40 sequences from 8 unique files
2025-11-19 13:05:00,711 - INFO - Average 5.0 sequences per file
Processing test:   0%|                              | 0/40 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/40 [00:00<00:26,  1.46it/s]2025-11-19 13:05:01,399 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold0\test_dataset.h5
2025-11-19 13:05:02,622 - INFO - Progress: 196/216 (90.7%) - ETA: 0.1 minutes
Processing test:  52%|###########          | 21/40 [00:03<00:02,  6.62it/s]Processing test:  62%|#############1       | 25/40 [00:04<00:03,  4.93it/s]Processing test:  70%|##############7      | 28/40 [00:06<00:03,  3.99it/s]2025-11-19 13:05:07,674 - INFO - Progress: 207/216 (95.8%) - ETA: 0.0 minutes
Processing test:  80%|################8    | 32/40 [00:08<00:02,  3.21it/s]Processing test:  92%|###################4 | 37/40 [00:08<00:00,  4.03it/s]Processing test:  98%|####################4| 39/40 [00:09<00:00,  4.33it/s]Processing test: 100%|#####################| 40/40 [00:09<00:00,  4.23it/s]Processing test: 100%|#####################| 40/40 [00:09<00:00,  4.29it/s]
2025-11-19 13:05:10,619 - INFO - Validating final datasets...
2025-11-19 13:05:10,626 - INFO - train dataset validation:
2025-11-19 13:05:10,627 - INFO -   - Segments: 176
2025-11-19 13:05:10,627 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:05:10,627 - INFO -   - Classes: 88 preictal, 88 interictal
2025-11-19 13:05:10,627 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:05:10,632 - INFO - test dataset validation:
2025-11-19 13:05:10,632 - INFO -   - Segments: 40
2025-11-19 13:05:10,632 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:05:10,632 - INFO -   - Classes: 20 preictal, 20 interictal
2025-11-19 13:05:10,632 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:05:10,632 - INFO - ============================================================
2025-11-19 13:05:10,632 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 13:05:10,632 - INFO - Total time: 0.6 minutes
2025-11-19 13:05:10,632 - INFO - Processed segments: 216
2025-11-19 13:05:10,632 - INFO - Average rate: 5.6 segments/second
2025-11-19 13:05:10,632 - INFO - ============================================================
✅ Fold 0 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 1/9
============================================================
2025-11-19 13:05:10,665 - INFO - ============================================================
2025-11-19 13:05:10,665 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 13:05:10,665 - INFO - ============================================================
2025-11-19 13:05:10,665 - INFO - Output prefix: chb16_fold1
2025-11-19 13:05:10,665 - INFO - EEG Preprocessor initialized
2025-11-19 13:05:10,665 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 13:05:10,665 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 13:05:10,665 - INFO - Segment duration: 5 seconds
2025-11-19 13:05:10,665 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 13:05:10,665 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 13:05:10,665 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 13:05:10,665 - INFO - Loading segments from chb16_fold1_sequences_prediction.json
2025-11-19 13:05:10,675 - INFO - Loaded 218 total sequences
2025-11-19 13:05:10,675 - INFO - Channel validation (from segmentation): 19/19 files valid
2025-11-19 13:05:10,675 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 13:05:10,675 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 13:05:10,675 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 13:05:10,675 - INFO - train: 176 sequences (88 preictal, 88 interictal)
2025-11-19 13:05:10,675 - INFO - test: 42 sequences (21 preictal, 21 interictal)
2025-11-19 13:05:10,687 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 13:05:10,687 - INFO - train: kept 88 preictal and 88 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:05:10,687 - INFO - test: kept 21 preictal and 21 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:05:10,698 - INFO - ============================================================
2025-11-19 13:05:10,698 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 13:05:10,698 - INFO - ============================================================
2025-11-19 13:05:10,698 - INFO - Processing 176 training samples to compute normalization stats...
2025-11-19 13:05:10,698 - INFO - Processing 176 sequences from 13 unique files
Processing training data:   0%|                    | 0/176 [00:00<?, ?it/s]Processing training data:   1%|            | 1/176 [00:01<04:15,  1.46s/it]Processing training data:  20%|##1        | 35/176 [00:02<00:09, 14.83it/s]Processing training data:  27%|##9        | 47/176 [00:04<00:11, 11.63it/s]Processing training data:  34%|###6       | 59/176 [00:05<00:10, 10.80it/s]Processing training data:  40%|####3      | 70/176 [00:07<00:11,  9.52it/s]Processing training data:  47%|#####1     | 82/176 [00:07<00:07, 11.88it/s]Processing training data:  52%|#####6     | 91/176 [00:08<00:08, 10.10it/s]Processing training data:  61%|######1   | 108/176 [00:09<00:04, 14.28it/s]Processing training data:  66%|######6   | 117/176 [00:10<00:05, 11.08it/s]Processing training data:  75%|#######5  | 132/176 [00:11<00:03, 12.72it/s]Processing training data:  86%|########5 | 151/176 [00:12<00:01, 13.74it/s]Processing training data:  91%|######### | 160/176 [00:14<00:01, 11.13it/s]Processing training data:  96%|#########6| 169/176 [00:15<00:00, 10.56it/s]Processing training data: 100%|##########| 176/176 [00:15<00:00, 11.65it/s]
2025-11-19 13:05:25,812 - INFO - Computing normalization statistics from training data...
2025-11-19 13:05:26,065 - INFO - Normalization stats computed:
2025-11-19 13:05:26,065 - INFO -   Mean: 0.484748
2025-11-19 13:05:26,065 - INFO -   Std: 2.062582
2025-11-19 13:05:26,065 - INFO -   Saved to: preprocessing\checkpoints\chb16_fold1\normalization_stats.json
2025-11-19 13:05:26,084 - INFO - Applying normalization and saving 176 training sequences...
Normalizing and saving training data:   0%|        | 0/176 [00:00<?, ?it/s]2025-11-19 13:05:26,094 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold1\train_dataset.h5
Normalizing and saving training data:   6%| | 10/176 [00:00<00:10, 15.78it/Normalizing and saving training data:  11%|1| 20/176 [00:01<00:09, 15.80it/Normalizing and saving training data:  17%|1| 30/176 [00:01<00:09, 15.81it/Normalizing and saving training data:  23%|2| 40/176 [00:02<00:08, 15.86it/Normalizing and saving training data:  28%|2| 50/176 [00:03<00:07, 15.83it/Normalizing and saving training data:  34%|3| 60/176 [00:03<00:07, 15.81it/Normalizing and saving training data:  40%|3| 70/176 [00:04<00:06, 15.80it/Normalizing and saving training data:  45%|4| 80/176 [00:05<00:06, 15.80it/Normalizing and saving training data:  51%|5| 90/176 [00:05<00:05, 15.84it/Normalizing and saving training data:  57%|5| 100/176 [00:06<00:04, 15.86itNormalizing and saving training data:  62%|6| 110/176 [00:06<00:04, 15.84itNormalizing and saving training data:  68%|6| 120/176 [00:07<00:03, 15.86itNormalizing and saving training data:  74%|7| 130/176 [00:08<00:02, 15.82itNormalizing and saving training data:  80%|7| 140/176 [00:08<00:02, 15.77itNormalizing and saving training data:  85%|8| 150/176 [00:09<00:01, 15.75itNormalizing and saving training data:  91%|9| 160/176 [00:10<00:01, 15.74itNormalizing and saving training data:  97%|9| 170/176 [00:10<00:00, 15.70itNormalizing and saving training data: 100%|#| 176/176 [00:10<00:00, 16.34it
2025-11-19 13:05:37,258 - INFO - Training data processing completed during stats computation phase
2025-11-19 13:05:37,266 - INFO - Loaded normalization statistics:
2025-11-19 13:05:37,266 - INFO -   Mean: 0.484748
2025-11-19 13:05:37,266 - INFO -   Std: 2.062582
2025-11-19 13:05:37,266 - INFO - Split train already completed, skipping
2025-11-19 13:05:37,266 - INFO - Processing test split...
2025-11-19 13:05:37,266 - INFO - Need to process 42/42 sequences for test
2025-11-19 13:05:37,266 - INFO - Processing 42 sequences from 8 unique files
2025-11-19 13:05:37,266 - INFO - Average 5.2 sequences per file
Processing test:   0%|                              | 0/42 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/42 [00:00<00:25,  1.59it/s]Processing test:  10%|##                    | 4/42 [00:01<00:16,  2.24it/s]Processing test:  21%|####7                 | 9/42 [00:02<00:08,  4.03it/s]2025-11-19 13:05:39,835 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold1\test_dataset.h5
2025-11-19 13:05:40,494 - INFO - Progress: 187/218 (85.8%) - ETA: 0.1 minutes
Processing test:  29%|######               | 12/42 [00:03<00:09,  3.31it/s]2025-11-19 13:05:42,282 - INFO - Progress: 208/218 (95.4%) - ETA: 0.0 minutes
Processing test:  79%|################5    | 33/42 [00:05<00:01,  6.75it/s]Processing test:  88%|##################5  | 37/42 [00:06<00:00,  6.37it/s]Processing test:  95%|#################### | 40/42 [00:07<00:00,  5.62it/s]Processing test: 100%|#####################| 42/42 [00:07<00:00,  5.78it/s]2025-11-19 13:05:45,812 - INFO - Progress: 218/218 (100.0%) - ETA: 0.0 minutes
Processing test: 100%|#####################| 42/42 [00:08<00:00,  4.91it/s]
2025-11-19 13:05:45,824 - INFO - Validating final datasets...
2025-11-19 13:05:45,832 - INFO - train dataset validation:
2025-11-19 13:05:45,832 - INFO -   - Segments: 176
2025-11-19 13:05:45,832 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:05:45,832 - INFO -   - Classes: 88 preictal, 88 interictal
2025-11-19 13:05:45,832 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:05:45,837 - INFO - test dataset validation:
2025-11-19 13:05:45,837 - INFO -   - Segments: 42
2025-11-19 13:05:45,837 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:05:45,837 - INFO -   - Classes: 21 preictal, 21 interictal
2025-11-19 13:05:45,837 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:05:45,838 - INFO - ============================================================
2025-11-19 13:05:45,838 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 13:05:45,838 - INFO - Total time: 0.6 minutes
2025-11-19 13:05:45,838 - INFO - Processed segments: 218
2025-11-19 13:05:45,838 - INFO - Average rate: 6.2 segments/second
2025-11-19 13:05:45,838 - INFO - ============================================================
✅ Fold 1 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 2/9
============================================================
2025-11-19 13:05:45,865 - INFO - ============================================================
2025-11-19 13:05:45,865 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 13:05:45,865 - INFO - ============================================================
2025-11-19 13:05:45,865 - INFO - Output prefix: chb16_fold2
2025-11-19 13:05:45,865 - INFO - EEG Preprocessor initialized
2025-11-19 13:05:45,865 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 13:05:45,865 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 13:05:45,865 - INFO - Segment duration: 5 seconds
2025-11-19 13:05:45,865 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 13:05:45,865 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 13:05:45,866 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 13:05:45,866 - INFO - Loading segments from chb16_fold2_sequences_prediction.json
2025-11-19 13:05:45,878 - INFO - Loaded 218 total sequences
2025-11-19 13:05:45,878 - INFO - Channel validation (from segmentation): 19/19 files valid
2025-11-19 13:05:45,878 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 13:05:45,878 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 13:05:45,878 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 13:05:45,878 - INFO - train: 176 sequences (88 preictal, 88 interictal)
2025-11-19 13:05:45,878 - INFO - test: 42 sequences (21 preictal, 21 interictal)
2025-11-19 13:05:45,890 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 13:05:45,890 - INFO - train: kept 88 preictal and 88 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:05:45,890 - INFO - test: kept 21 preictal and 21 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:05:45,902 - INFO - ============================================================
2025-11-19 13:05:45,902 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 13:05:45,902 - INFO - ============================================================
2025-11-19 13:05:45,902 - INFO - Processing 176 training samples to compute normalization stats...
2025-11-19 13:05:45,902 - INFO - Processing 176 sequences from 13 unique files
Processing training data:   0%|                    | 0/176 [00:00<?, ?it/s]Processing training data:   1%|            | 1/176 [00:01<04:02,  1.39s/it]Processing training data:   6%|6          | 10/176 [00:02<00:41,  3.98it/s]Processing training data:  23%|##5        | 41/176 [00:04<00:11, 12.01it/s]Processing training data:  31%|###4       | 55/176 [00:04<00:08, 15.05it/s]Processing training data:  38%|####1      | 66/176 [00:06<00:09, 12.21it/s]Processing training data:  47%|#####1     | 83/176 [00:07<00:07, 11.88it/s]Processing training data:  56%|######1    | 98/176 [00:09<00:06, 11.42it/s]Processing training data:  61%|######1   | 108/176 [00:09<00:05, 11.41it/s]Processing training data:  73%|#######3  | 129/176 [00:11<00:03, 12.68it/s]Processing training data:  80%|#######9  | 140/176 [00:11<00:02, 14.28it/s]Processing training data:  84%|########4 | 148/176 [00:12<00:02, 12.49it/s]Processing training data:  88%|########8 | 155/176 [00:14<00:02,  9.48it/s]Processing training data:  94%|#########4| 166/176 [00:15<00:01,  8.47it/s]Processing training data: 100%|##########| 176/176 [00:15<00:00, 11.14it/s]
2025-11-19 13:06:01,698 - INFO - Computing normalization statistics from training data...
2025-11-19 13:06:01,964 - INFO - Normalization stats computed:
2025-11-19 13:06:01,964 - INFO -   Mean: 0.507117
2025-11-19 13:06:01,964 - INFO -   Std: 2.057280
2025-11-19 13:06:01,964 - INFO -   Saved to: preprocessing\checkpoints\chb16_fold2\normalization_stats.json
2025-11-19 13:06:01,983 - INFO - Applying normalization and saving 176 training sequences...
Normalizing and saving training data:   0%|        | 0/176 [00:00<?, ?it/s]2025-11-19 13:06:01,994 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold2\train_dataset.h5
Normalizing and saving training data:   6%| | 10/176 [00:00<00:10, 15.85it/Normalizing and saving training data:  11%|1| 20/176 [00:01<00:09, 15.81it/Normalizing and saving training data:  17%|1| 30/176 [00:01<00:09, 15.81it/Normalizing and saving training data:  23%|2| 40/176 [00:02<00:08, 15.85it/Normalizing and saving training data:  28%|2| 50/176 [00:03<00:07, 15.83it/Normalizing and saving training data:  34%|3| 60/176 [00:03<00:07, 15.85it/Normalizing and saving training data:  40%|3| 70/176 [00:04<00:06, 15.89it/Normalizing and saving training data:  45%|4| 80/176 [00:05<00:06, 15.92it/Normalizing and saving training data:  51%|5| 90/176 [00:05<00:05, 15.94it/Normalizing and saving training data:  57%|5| 100/176 [00:06<00:04, 15.98itNormalizing and saving training data:  62%|6| 110/176 [00:06<00:04, 15.99itNormalizing and saving training data:  68%|6| 120/176 [00:07<00:03, 16.01itNormalizing and saving training data:  74%|7| 130/176 [00:08<00:02, 15.88itNormalizing and saving training data:  80%|7| 140/176 [00:08<00:02, 15.81itNormalizing and saving training data:  85%|8| 150/176 [00:09<00:01, 15.84itNormalizing and saving training data:  91%|9| 160/176 [00:10<00:01, 15.81itNormalizing and saving training data:  97%|9| 170/176 [00:10<00:00, 15.78itNormalizing and saving training data: 100%|#| 176/176 [00:10<00:00, 16.42it
2025-11-19 13:06:13,108 - INFO - Training data processing completed during stats computation phase
2025-11-19 13:06:13,115 - INFO - Loaded normalization statistics:
2025-11-19 13:06:13,115 - INFO -   Mean: 0.507117
2025-11-19 13:06:13,115 - INFO -   Std: 2.057280
2025-11-19 13:06:13,115 - INFO - Split train already completed, skipping
2025-11-19 13:06:13,115 - INFO - Processing test split...
2025-11-19 13:06:13,116 - INFO - Need to process 42/42 sequences for test
2025-11-19 13:06:13,116 - INFO - Processing 42 sequences from 7 unique files
2025-11-19 13:06:13,116 - INFO - Average 6.0 sequences per file
Processing test:   0%|                              | 0/42 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/42 [00:00<00:21,  1.88it/s]2025-11-19 13:06:13,650 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold2\test_dataset.h5
2025-11-19 13:06:14,919 - INFO - Progress: 197/218 (90.4%) - ETA: 0.1 minutes
Processing test:  52%|###########          | 22/42 [00:03<00:02,  7.39it/s]Processing test:  62%|#############        | 26/42 [00:03<00:02,  7.87it/s]Processing test:  67%|##############       | 28/42 [00:04<00:02,  6.79it/s]Processing test:  74%|###############5     | 31/42 [00:05<00:02,  4.58it/s]2025-11-19 13:06:19,504 - INFO - Progress: 212/218 (97.2%) - ETA: 0.0 minutes
Processing test:  88%|##################5  | 37/42 [00:07<00:01,  4.24it/s]Processing test:  95%|#################### | 40/42 [00:07<00:00,  4.35it/s]Processing test: 100%|#####################| 42/42 [00:07<00:00,  5.47it/s]
2025-11-19 13:06:21,188 - INFO - Validating final datasets...
2025-11-19 13:06:21,196 - INFO - train dataset validation:
2025-11-19 13:06:21,197 - INFO -   - Segments: 176
2025-11-19 13:06:21,197 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:06:21,197 - INFO -   - Classes: 88 preictal, 88 interictal
2025-11-19 13:06:21,197 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:06:21,202 - INFO - test dataset validation:
2025-11-19 13:06:21,202 - INFO -   - Segments: 42
2025-11-19 13:06:21,202 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:06:21,202 - INFO -   - Classes: 21 preictal, 21 interictal
2025-11-19 13:06:21,202 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:06:21,202 - INFO - ============================================================
2025-11-19 13:06:21,202 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 13:06:21,202 - INFO - Total time: 0.6 minutes
2025-11-19 13:06:21,202 - INFO - Processed segments: 218
2025-11-19 13:06:21,202 - INFO - Average rate: 6.2 segments/second
2025-11-19 13:06:21,202 - INFO - ============================================================
✅ Fold 2 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 3/9
============================================================
2025-11-19 13:06:21,230 - INFO - ============================================================
2025-11-19 13:06:21,230 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 13:06:21,230 - INFO - ============================================================
2025-11-19 13:06:21,230 - INFO - Output prefix: chb16_fold3
2025-11-19 13:06:21,230 - INFO - EEG Preprocessor initialized
2025-11-19 13:06:21,230 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 13:06:21,230 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 13:06:21,230 - INFO - Segment duration: 5 seconds
2025-11-19 13:06:21,230 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 13:06:21,230 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 13:06:21,230 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 13:06:21,231 - INFO - Loading segments from chb16_fold3_sequences_prediction.json
2025-11-19 13:06:21,242 - INFO - Loaded 214 total sequences
2025-11-19 13:06:21,242 - INFO - Channel validation (from segmentation): 19/19 files valid
2025-11-19 13:06:21,242 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 13:06:21,242 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 13:06:21,242 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 13:06:21,242 - INFO - train: 176 sequences (88 preictal, 88 interictal)
2025-11-19 13:06:21,242 - INFO - test: 38 sequences (19 preictal, 19 interictal)
2025-11-19 13:06:21,254 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 13:06:21,255 - INFO - train: kept 88 preictal and 88 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:06:21,255 - INFO - test: kept 19 preictal and 19 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:06:21,266 - INFO - ============================================================
2025-11-19 13:06:21,266 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 13:06:21,266 - INFO - ============================================================
2025-11-19 13:06:21,267 - INFO - Processing 176 training samples to compute normalization stats...
2025-11-19 13:06:21,267 - INFO - Processing 176 sequences from 14 unique files
Processing training data:   0%|                    | 0/176 [00:00<?, ?it/s]Processing training data:   1%|            | 1/176 [00:00<02:43,  1.07it/s]Processing training data:  16%|#8         | 29/176 [00:02<00:10, 13.80it/s]Processing training data:  26%|##8        | 45/176 [00:02<00:06, 20.00it/s]Processing training data:  29%|###1       | 51/176 [00:04<00:10, 11.63it/s]Processing training data:  49%|#####3     | 86/176 [00:05<00:05, 17.52it/s]Processing training data:  57%|#####6    | 100/176 [00:06<00:05, 14.40it/s]Processing training data:  66%|######5   | 116/176 [00:07<00:03, 17.14it/s]Processing training data:  73%|#######3  | 129/176 [00:08<00:03, 13.86it/s]Processing training data:  81%|########  | 142/176 [00:10<00:02, 12.87it/s]Processing training data:  85%|########5 | 150/176 [00:11<00:02, 11.15it/s]Processing training data:  88%|########7 | 154/176 [00:12<00:02,  9.46it/s]Processing training data:  92%|#########2| 162/176 [00:12<00:01, 11.22it/s]Processing training data:  94%|#########3| 165/176 [00:12<00:01, 10.92it/s]Processing training data:  95%|#########5| 168/176 [00:14<00:01,  6.91it/s]Processing training data: 100%|##########| 176/176 [00:14<00:00, 12.42it/s]
2025-11-19 13:06:35,442 - INFO - Computing normalization statistics from training data...
2025-11-19 13:06:35,689 - INFO - Normalization stats computed:
2025-11-19 13:06:35,689 - INFO -   Mean: 0.341415
2025-11-19 13:06:35,689 - INFO -   Std: 2.101932
2025-11-19 13:06:35,689 - INFO -   Saved to: preprocessing\checkpoints\chb16_fold3\normalization_stats.json
2025-11-19 13:06:35,713 - INFO - Applying normalization and saving 176 training sequences...
Normalizing and saving training data:   0%|        | 0/176 [00:00<?, ?it/s]2025-11-19 13:06:35,719 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold3\train_dataset.h5
Normalizing and saving training data:   6%| | 10/176 [00:00<00:10, 16.29it/Normalizing and saving training data:  11%|1| 20/176 [00:01<00:09, 16.08it/Normalizing and saving training data:  17%|1| 30/176 [00:01<00:09, 15.70it/Normalizing and saving training data:  23%|2| 40/176 [00:02<00:08, 15.80it/Normalizing and saving training data:  28%|2| 50/176 [00:03<00:07, 15.83it/Normalizing and saving training data:  34%|3| 60/176 [00:03<00:07, 15.84it/Normalizing and saving training data:  40%|3| 70/176 [00:04<00:06, 15.85it/Normalizing and saving training data:  45%|4| 80/176 [00:05<00:06, 15.87it/Normalizing and saving training data:  51%|5| 90/176 [00:05<00:05, 15.92it/Normalizing and saving training data:  57%|5| 100/176 [00:06<00:04, 15.95itNormalizing and saving training data:  62%|6| 110/176 [00:06<00:04, 15.97itNormalizing and saving training data:  68%|6| 120/176 [00:07<00:03, 15.98itNormalizing and saving training data:  74%|7| 130/176 [00:08<00:02, 15.93itNormalizing and saving training data:  80%|7| 140/176 [00:08<00:02, 15.89itNormalizing and saving training data:  85%|8| 150/176 [00:09<00:01, 15.88itNormalizing and saving training data:  91%|9| 160/176 [00:10<00:01, 15.83itNormalizing and saving training data:  97%|9| 170/176 [00:10<00:00, 15.82itNormalizing and saving training data: 100%|#| 176/176 [00:10<00:00, 16.43it
2025-11-19 13:06:46,822 - INFO - Training data processing completed during stats computation phase
2025-11-19 13:06:46,829 - INFO - Loaded normalization statistics:
2025-11-19 13:06:46,829 - INFO -   Mean: 0.341415
2025-11-19 13:06:46,829 - INFO -   Std: 2.101932
2025-11-19 13:06:46,829 - INFO - Split train already completed, skipping
2025-11-19 13:06:46,829 - INFO - Processing test split...
2025-11-19 13:06:46,829 - INFO - Need to process 38/38 sequences for test
2025-11-19 13:06:46,829 - INFO - Processing 38 sequences from 8 unique files
2025-11-19 13:06:46,829 - INFO - Average 4.8 sequences per file
Processing test:   0%|                              | 0/38 [00:00<?, ?it/s]Processing test:   3%|5                     | 1/38 [00:00<00:18,  1.96it/s]2025-11-19 13:06:47,341 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold3\test_dataset.h5
2025-11-19 13:06:48,446 - INFO - Progress: 195/214 (91.1%) - ETA: 0.0 minutes
Processing test:  53%|###########          | 20/38 [00:02<00:02,  8.76it/s]Processing test:  61%|############7        | 23/38 [00:03<00:02,  6.09it/s]Processing test:  71%|##############9      | 27/38 [00:04<00:01,  5.71it/s]2025-11-19 13:06:51,885 - INFO - Progress: 206/214 (96.3%) - ETA: 0.0 minutes
Processing test:  82%|#################1   | 31/38 [00:06<00:01,  3.95it/s]Processing test:  95%|###################8 | 36/38 [00:06<00:00,  5.28it/s]Processing test:  97%|####################4| 37/38 [00:06<00:00,  5.10it/s]Processing test: 100%|#####################| 38/38 [00:07<00:00,  4.93it/s]Processing test: 100%|#####################| 38/38 [00:07<00:00,  5.36it/s]
2025-11-19 13:06:54,407 - INFO - Validating final datasets...
2025-11-19 13:06:54,415 - INFO - train dataset validation:
2025-11-19 13:06:54,415 - INFO -   - Segments: 176
2025-11-19 13:06:54,415 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:06:54,415 - INFO -   - Classes: 88 preictal, 88 interictal
2025-11-19 13:06:54,415 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:06:54,421 - INFO - test dataset validation:
2025-11-19 13:06:54,421 - INFO -   - Segments: 38
2025-11-19 13:06:54,421 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:06:54,421 - INFO -   - Classes: 19 preictal, 19 interictal
2025-11-19 13:06:54,421 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:06:54,421 - INFO - ============================================================
2025-11-19 13:06:54,421 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 13:06:54,421 - INFO - Total time: 0.6 minutes
2025-11-19 13:06:54,421 - INFO - Processed segments: 214
2025-11-19 13:06:54,421 - INFO - Average rate: 6.4 segments/second
2025-11-19 13:06:54,421 - INFO - ============================================================
✅ Fold 3 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 4/9
============================================================
2025-11-19 13:06:54,447 - INFO - ============================================================
2025-11-19 13:06:54,447 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 13:06:54,448 - INFO - ============================================================
2025-11-19 13:06:54,448 - INFO - Output prefix: chb16_fold4
2025-11-19 13:06:54,448 - INFO - EEG Preprocessor initialized
2025-11-19 13:06:54,448 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 13:06:54,448 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 13:06:54,448 - INFO - Segment duration: 5 seconds
2025-11-19 13:06:54,448 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 13:06:54,448 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 13:06:54,448 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 13:06:54,448 - INFO - Loading segments from chb16_fold4_sequences_prediction.json
2025-11-19 13:06:54,461 - INFO - Loaded 206 total sequences
2025-11-19 13:06:54,461 - INFO - Channel validation (from segmentation): 19/19 files valid
2025-11-19 13:06:54,461 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 13:06:54,461 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 13:06:54,462 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 13:06:54,462 - INFO - train: 176 sequences (88 preictal, 88 interictal)
2025-11-19 13:06:54,462 - INFO - test: 30 sequences (15 preictal, 15 interictal)
2025-11-19 13:06:54,473 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 13:06:54,473 - INFO - train: kept 88 preictal and 88 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:06:54,473 - INFO - test: kept 15 preictal and 15 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:06:54,484 - INFO - ============================================================
2025-11-19 13:06:54,484 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 13:06:54,484 - INFO - ============================================================
2025-11-19 13:06:54,484 - INFO - Processing 176 training samples to compute normalization stats...
2025-11-19 13:06:54,484 - INFO - Processing 176 sequences from 14 unique files
Processing training data:   0%|                    | 0/176 [00:00<?, ?it/s]Processing training data:   1%|            | 1/176 [00:00<01:25,  2.05it/s]Processing training data:   8%|8          | 14/176 [00:01<00:20,  7.92it/s]Processing training data:  18%|#9         | 31/176 [00:02<00:12, 11.52it/s]Processing training data:  34%|###7       | 60/176 [00:03<00:06, 18.83it/s]Processing training data:  47%|#####1     | 82/176 [00:04<00:04, 20.07it/s]Processing training data:  51%|#####6     | 90/176 [00:05<00:04, 17.35it/s]Processing training data:  55%|######     | 96/176 [00:07<00:06, 11.70it/s]Processing training data:  62%|######1   | 109/176 [00:08<00:06, 10.92it/s]Processing training data:  69%|######9   | 122/176 [00:08<00:03, 13.56it/s]Processing training data:  73%|#######3  | 129/176 [00:10<00:04, 10.13it/s]Processing training data:  80%|#######9  | 140/176 [00:11<00:03,  9.38it/s]Processing training data:  85%|########5 | 150/176 [00:12<00:02,  8.81it/s]Processing training data:  91%|######### | 160/176 [00:13<00:01, 10.61it/s]Processing training data:  95%|#########5| 168/176 [00:13<00:00, 11.61it/s]Processing training data: 100%|##########| 176/176 [00:13<00:00, 12.64it/s]
2025-11-19 13:07:08,407 - INFO - Computing normalization statistics from training data...
2025-11-19 13:07:08,650 - INFO - Normalization stats computed:
2025-11-19 13:07:08,651 - INFO -   Mean: 0.432128
2025-11-19 13:07:08,651 - INFO -   Std: 2.065040
2025-11-19 13:07:08,651 - INFO -   Saved to: preprocessing\checkpoints\chb16_fold4\normalization_stats.json
2025-11-19 13:07:08,673 - INFO - Applying normalization and saving 176 training sequences...
Normalizing and saving training data:   0%|        | 0/176 [00:00<?, ?it/s]2025-11-19 13:07:08,680 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold4\train_dataset.h5
Normalizing and saving training data:   6%| | 10/176 [00:00<00:10, 16.43it/Normalizing and saving training data:  11%|1| 20/176 [00:01<00:09, 16.29it/Normalizing and saving training data:  17%|1| 30/176 [00:01<00:08, 16.34it/Normalizing and saving training data:  23%|2| 40/176 [00:02<00:08, 16.31it/Normalizing and saving training data:  28%|2| 50/176 [00:03<00:07, 16.31it/Normalizing and saving training data:  34%|3| 60/176 [00:03<00:07, 16.27it/Normalizing and saving training data:  40%|3| 70/176 [00:04<00:06, 16.23it/Normalizing and saving training data:  45%|4| 80/176 [00:04<00:05, 16.19it/Normalizing and saving training data:  51%|5| 90/176 [00:05<00:05, 16.18it/Normalizing and saving training data:  57%|5| 100/176 [00:06<00:04, 16.18itNormalizing and saving training data:  62%|6| 110/176 [00:06<00:04, 16.20itNormalizing and saving training data:  68%|6| 120/176 [00:07<00:03, 15.81itNormalizing and saving training data:  74%|7| 130/176 [00:08<00:02, 15.76itNormalizing and saving training data:  80%|7| 140/176 [00:08<00:02, 15.76itNormalizing and saving training data:  85%|8| 150/176 [00:09<00:01, 15.92itNormalizing and saving training data:  91%|9| 160/176 [00:09<00:00, 16.04itNormalizing and saving training data:  97%|9| 170/176 [00:10<00:00, 16.11itNormalizing and saving training data: 100%|#| 176/176 [00:10<00:00, 16.67it
2025-11-19 13:07:19,621 - INFO - Training data processing completed during stats computation phase
2025-11-19 13:07:19,628 - INFO - Loaded normalization statistics:
2025-11-19 13:07:19,628 - INFO -   Mean: 0.432128
2025-11-19 13:07:19,628 - INFO -   Std: 2.065040
2025-11-19 13:07:19,628 - INFO - Split train already completed, skipping
2025-11-19 13:07:19,628 - INFO - Processing test split...
2025-11-19 13:07:19,628 - INFO - Need to process 30/30 sequences for test
2025-11-19 13:07:19,628 - INFO - Processing 30 sequences from 9 unique files
2025-11-19 13:07:19,628 - INFO - Average 3.3 sequences per file
Processing test:   0%|                              | 0/30 [00:00<?, ?it/s]Processing test:   3%|7                     | 1/30 [00:01<00:46,  1.60s/it]Processing test:  20%|####4                 | 6/30 [00:01<00:05,  4.12it/s]Processing test:  27%|#####8                | 8/30 [00:02<00:04,  4.48it/s]2025-11-19 13:07:21,865 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold4\test_dataset.h5
2025-11-19 13:07:22,908 - INFO - Progress: 193/206 (93.7%) - ETA: 0.0 minutes
Processing test:  60%|############6        | 18/30 [00:03<00:01,  6.20it/s]Processing test:  73%|###############4     | 22/30 [00:04<00:01,  4.76it/s]Processing test:  80%|################8    | 24/30 [00:05<00:01,  5.05it/s]Processing test:  83%|#################5   | 25/30 [00:05<00:01,  4.70it/s]Processing test:  90%|##################9  | 27/30 [00:06<00:00,  4.31it/s]2025-11-19 13:07:26,428 - INFO - Progress: 204/206 (99.0%) - ETA: 0.0 minutes
Processing test:  97%|####################3| 29/30 [00:07<00:00,  2.68it/s]Processing test: 100%|#####################| 30/30 [00:07<00:00,  3.90it/s]
2025-11-19 13:07:27,482 - INFO - Validating final datasets...
2025-11-19 13:07:27,490 - INFO - train dataset validation:
2025-11-19 13:07:27,490 - INFO -   - Segments: 176
2025-11-19 13:07:27,490 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:07:27,490 - INFO -   - Classes: 88 preictal, 88 interictal
2025-11-19 13:07:27,490 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:07:27,495 - INFO - test dataset validation:
2025-11-19 13:07:27,495 - INFO -   - Segments: 30
2025-11-19 13:07:27,495 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:07:27,495 - INFO -   - Classes: 15 preictal, 15 interictal
2025-11-19 13:07:27,495 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:07:27,496 - INFO - ============================================================
2025-11-19 13:07:27,496 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 13:07:27,496 - INFO - Total time: 0.6 minutes
2025-11-19 13:07:27,496 - INFO - Processed segments: 206
2025-11-19 13:07:27,496 - INFO - Average rate: 6.2 segments/second
2025-11-19 13:07:27,496 - INFO - ============================================================
✅ Fold 4 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 5/9
============================================================
2025-11-19 13:07:27,523 - INFO - ============================================================
2025-11-19 13:07:27,523 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 13:07:27,523 - INFO - ============================================================
2025-11-19 13:07:27,523 - INFO - Output prefix: chb16_fold5
2025-11-19 13:07:27,523 - INFO - EEG Preprocessor initialized
2025-11-19 13:07:27,524 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 13:07:27,524 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 13:07:27,524 - INFO - Segment duration: 5 seconds
2025-11-19 13:07:27,524 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 13:07:27,524 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 13:07:27,524 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 13:07:27,524 - INFO - Loading segments from chb16_fold5_sequences_prediction.json
2025-11-19 13:07:27,536 - INFO - Loaded 220 total sequences
2025-11-19 13:07:27,536 - INFO - Channel validation (from segmentation): 19/19 files valid
2025-11-19 13:07:27,536 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 13:07:27,536 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 13:07:27,536 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 13:07:27,536 - INFO - train: 176 sequences (88 preictal, 88 interictal)
2025-11-19 13:07:27,536 - INFO - test: 44 sequences (22 preictal, 22 interictal)
2025-11-19 13:07:27,548 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 13:07:27,548 - INFO - train: kept 88 preictal and 88 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:07:27,548 - INFO - test: kept 22 preictal and 22 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:07:27,560 - INFO - ============================================================
2025-11-19 13:07:27,560 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 13:07:27,560 - INFO - ============================================================
2025-11-19 13:07:27,560 - INFO - Processing 176 training samples to compute normalization stats...
2025-11-19 13:07:27,560 - INFO - Processing 176 sequences from 14 unique files
Processing training data:   0%|                    | 0/176 [00:00<?, ?it/s]Processing training data:   1%|            | 1/176 [00:01<03:50,  1.32s/it]Processing training data:   9%|#          | 16/176 [00:02<00:23,  6.78it/s]Processing training data:  17%|#8         | 30/176 [00:04<00:18,  8.10it/s]Processing training data:  23%|##5        | 41/176 [00:05<00:17,  7.90it/s]Processing training data:  35%|###8       | 61/176 [00:07<00:11, 10.11it/s]Processing training data:  43%|####6      | 75/176 [00:07<00:07, 12.87it/s]Processing training data:  50%|#####5     | 88/176 [00:08<00:05, 15.12it/s]Processing training data:  56%|######1    | 99/176 [00:08<00:04, 16.39it/s]Processing training data:  63%|######3   | 111/176 [00:09<00:04, 14.61it/s]Processing training data:  68%|######8   | 120/176 [00:10<00:04, 11.78it/s]Processing training data:  74%|#######4  | 131/176 [00:12<00:04, 10.11it/s]Processing training data:  81%|########1 | 143/176 [00:13<00:03, 10.88it/s]Processing training data:  91%|######### | 160/176 [00:14<00:01, 11.61it/s]Processing training data:  95%|#########5| 168/176 [00:15<00:00,  9.62it/s]Processing training data: 100%|##########| 176/176 [00:15<00:00, 11.06it/s]
2025-11-19 13:07:43,468 - INFO - Computing normalization statistics from training data...
2025-11-19 13:07:43,716 - INFO - Normalization stats computed:
2025-11-19 13:07:43,716 - INFO -   Mean: 0.458777
2025-11-19 13:07:43,716 - INFO -   Std: 2.068592
2025-11-19 13:07:43,716 - INFO -   Saved to: preprocessing\checkpoints\chb16_fold5\normalization_stats.json
2025-11-19 13:07:43,740 - INFO - Applying normalization and saving 176 training sequences...
Normalizing and saving training data:   0%|        | 0/176 [00:00<?, ?it/s]2025-11-19 13:07:43,747 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold5\train_dataset.h5
Normalizing and saving training data:   6%| | 10/176 [00:00<00:10, 16.27it/Normalizing and saving training data:  11%|1| 20/176 [00:01<00:09, 16.04it/Normalizing and saving training data:  17%|1| 30/176 [00:01<00:09, 15.76it/Normalizing and saving training data:  23%|2| 40/176 [00:02<00:08, 15.95it/Normalizing and saving training data:  28%|2| 50/176 [00:03<00:07, 16.02it/Normalizing and saving training data:  34%|3| 60/176 [00:03<00:07, 15.77it/Normalizing and saving training data:  40%|3| 70/176 [00:04<00:06, 15.80it/Normalizing and saving training data:  45%|4| 80/176 [00:05<00:06, 15.86it/Normalizing and saving training data:  51%|5| 90/176 [00:05<00:05, 15.89it/Normalizing and saving training data:  57%|5| 100/176 [00:06<00:04, 15.89itNormalizing and saving training data:  62%|6| 110/176 [00:06<00:04, 15.72itNormalizing and saving training data:  68%|6| 120/176 [00:07<00:03, 15.79itNormalizing and saving training data:  74%|7| 130/176 [00:08<00:02, 15.85itNormalizing and saving training data:  80%|7| 140/176 [00:08<00:02, 15.82itNormalizing and saving training data:  85%|8| 150/176 [00:09<00:01, 16.09itNormalizing and saving training data:  91%|9| 160/176 [00:10<00:00, 16.28itNormalizing and saving training data:  97%|9| 170/176 [00:10<00:00, 16.41itNormalizing and saving training data: 100%|#| 176/176 [00:10<00:00, 16.56it
2025-11-19 13:07:54,746 - INFO - Training data processing completed during stats computation phase
2025-11-19 13:07:54,754 - INFO - Loaded normalization statistics:
2025-11-19 13:07:54,754 - INFO -   Mean: 0.458777
2025-11-19 13:07:54,754 - INFO -   Std: 2.068592
2025-11-19 13:07:54,754 - INFO - Split train already completed, skipping
2025-11-19 13:07:54,754 - INFO - Processing test split...
2025-11-19 13:07:54,754 - INFO - Need to process 44/44 sequences for test
2025-11-19 13:07:54,754 - INFO - Processing 44 sequences from 8 unique files
2025-11-19 13:07:54,754 - INFO - Average 5.5 sequences per file
Processing test:   0%|                              | 0/44 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/44 [00:00<00:23,  1.80it/s]2025-11-19 13:07:55,313 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold5\test_dataset.h5
2025-11-19 13:07:56,648 - INFO - Progress: 198/220 (90.0%) - ETA: 0.1 minutes
Processing test:  52%|##########9          | 23/44 [00:03<00:02,  7.09it/s]Processing test:  61%|############8        | 27/44 [00:03<00:02,  7.04it/s]Processing test:  68%|##############3      | 30/44 [00:05<00:02,  5.58it/s]2025-11-19 13:08:00,372 - INFO - Progress: 208/220 (94.5%) - ETA: 0.0 minutes
Processing test:  75%|###############7     | 33/44 [00:06<00:02,  3.82it/s]Processing test:  84%|#################6   | 37/44 [00:07<00:01,  4.15it/s]Processing test:  91%|###################  | 40/44 [00:07<00:00,  4.66it/s]Processing test:  95%|#################### | 42/44 [00:08<00:00,  4.12it/s]2025-11-19 13:08:04,131 - INFO - Progress: 220/220 (100.0%) - ETA: 0.0 minutes
Processing test: 100%|#####################| 44/44 [00:09<00:00,  4.69it/s]
2025-11-19 13:08:04,143 - INFO - Validating final datasets...
2025-11-19 13:08:04,151 - INFO - train dataset validation:
2025-11-19 13:08:04,151 - INFO -   - Segments: 176
2025-11-19 13:08:04,151 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:08:04,151 - INFO -   - Classes: 88 preictal, 88 interictal
2025-11-19 13:08:04,151 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:08:04,157 - INFO - test dataset validation:
2025-11-19 13:08:04,157 - INFO -   - Segments: 44
2025-11-19 13:08:04,157 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:08:04,157 - INFO -   - Classes: 22 preictal, 22 interictal
2025-11-19 13:08:04,157 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:08:04,157 - INFO - ============================================================
2025-11-19 13:08:04,157 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 13:08:04,157 - INFO - Total time: 0.6 minutes
2025-11-19 13:08:04,157 - INFO - Processed segments: 220
2025-11-19 13:08:04,157 - INFO - Average rate: 6.0 segments/second
2025-11-19 13:08:04,157 - INFO - ============================================================
✅ Fold 5 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 6/9
============================================================
2025-11-19 13:08:04,183 - INFO - ============================================================
2025-11-19 13:08:04,183 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 13:08:04,183 - INFO - ============================================================
2025-11-19 13:08:04,183 - INFO - Output prefix: chb16_fold6
2025-11-19 13:08:04,183 - INFO - EEG Preprocessor initialized
2025-11-19 13:08:04,183 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 13:08:04,183 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 13:08:04,183 - INFO - Segment duration: 5 seconds
2025-11-19 13:08:04,184 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 13:08:04,184 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 13:08:04,184 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 13:08:04,184 - INFO - Loading segments from chb16_fold6_sequences_prediction.json
2025-11-19 13:08:04,197 - INFO - Loaded 214 total sequences
2025-11-19 13:08:04,197 - INFO - Channel validation (from segmentation): 19/19 files valid
2025-11-19 13:08:04,197 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 13:08:04,197 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 13:08:04,197 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 13:08:04,197 - INFO - train: 176 sequences (88 preictal, 88 interictal)
2025-11-19 13:08:04,197 - INFO - test: 38 sequences (19 preictal, 19 interictal)
2025-11-19 13:08:04,209 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 13:08:04,209 - INFO - train: kept 88 preictal and 88 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:08:04,209 - INFO - test: kept 19 preictal and 19 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:08:04,220 - INFO - ============================================================
2025-11-19 13:08:04,220 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 13:08:04,220 - INFO - ============================================================
2025-11-19 13:08:04,220 - INFO - Processing 176 training samples to compute normalization stats...
2025-11-19 13:08:04,220 - INFO - Processing 176 sequences from 14 unique files
Processing training data:   0%|                    | 0/176 [00:00<?, ?it/s]Processing training data:   1%|            | 1/176 [00:01<04:16,  1.47s/it]Processing training data:  15%|#6         | 26/176 [00:02<00:13, 11.01it/s]Processing training data:  22%|##4        | 39/176 [00:04<00:13, 10.30it/s]Processing training data:  28%|###1       | 50/176 [00:05<00:13,  9.28it/s]Processing training data:  36%|###9       | 63/176 [00:06<00:09, 12.27it/s]Processing training data:  42%|####6      | 74/176 [00:06<00:07, 14.23it/s]Processing training data:  49%|#####4     | 87/176 [00:07<00:06, 14.43it/s]Processing training data:  60%|#####9    | 105/176 [00:08<00:04, 16.01it/s]Processing training data:  64%|######3   | 112/176 [00:09<00:05, 11.18it/s]Processing training data:  71%|#######1  | 125/176 [00:11<00:04, 10.28it/s]Processing training data:  77%|#######6  | 135/176 [00:12<00:04,  9.28it/s]Processing training data:  82%|########1 | 144/176 [00:13<00:02, 10.76it/s]Processing training data:  86%|########6 | 152/176 [00:14<00:02,  8.92it/s]Processing training data:  94%|#########3| 165/176 [00:15<00:01,  9.00it/s]Processing training data: 100%|##########| 176/176 [00:15<00:00, 11.08it/s]
2025-11-19 13:08:20,108 - INFO - Computing normalization statistics from training data...
2025-11-19 13:08:20,359 - INFO - Normalization stats computed:
2025-11-19 13:08:20,359 - INFO -   Mean: 0.443659
2025-11-19 13:08:20,359 - INFO -   Std: 2.092104
2025-11-19 13:08:20,359 - INFO -   Saved to: preprocessing\checkpoints\chb16_fold6\normalization_stats.json
2025-11-19 13:08:20,378 - INFO - Applying normalization and saving 176 training sequences...
Normalizing and saving training data:   0%|        | 0/176 [00:00<?, ?it/s]2025-11-19 13:08:20,389 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold6\train_dataset.h5
Normalizing and saving training data:   6%| | 10/176 [00:00<00:10, 16.11it/Normalizing and saving training data:  11%|1| 20/176 [00:01<00:09, 15.99it/Normalizing and saving training data:  17%|1| 30/176 [00:01<00:09, 16.03it/Normalizing and saving training data:  23%|2| 40/176 [00:02<00:08, 16.10it/Normalizing and saving training data:  28%|2| 50/176 [00:03<00:07, 16.13it/Normalizing and saving training data:  34%|3| 60/176 [00:03<00:07, 16.15it/Normalizing and saving training data:  40%|3| 70/176 [00:04<00:06, 16.10it/Normalizing and saving training data:  45%|4| 80/176 [00:04<00:05, 16.08it/Normalizing and saving training data:  51%|5| 90/176 [00:05<00:05, 16.02it/Normalizing and saving training data:  57%|5| 100/176 [00:06<00:04, 15.98itNormalizing and saving training data:  62%|6| 110/176 [00:06<00:04, 16.00itNormalizing and saving training data:  68%|6| 120/176 [00:07<00:03, 16.00itNormalizing and saving training data:  74%|7| 130/176 [00:08<00:02, 15.96itNormalizing and saving training data:  80%|7| 140/176 [00:08<00:02, 15.91itNormalizing and saving training data:  85%|8| 150/176 [00:09<00:01, 15.85itNormalizing and saving training data:  91%|9| 160/176 [00:10<00:01, 15.89itNormalizing and saving training data:  97%|9| 170/176 [00:10<00:00, 15.88itNormalizing and saving training data: 100%|#| 176/176 [00:10<00:00, 16.54it
2025-11-19 13:08:31,415 - INFO - Training data processing completed during stats computation phase
2025-11-19 13:08:31,421 - INFO - Loaded normalization statistics:
2025-11-19 13:08:31,421 - INFO -   Mean: 0.443659
2025-11-19 13:08:31,421 - INFO -   Std: 2.092104
2025-11-19 13:08:31,421 - INFO - Split train already completed, skipping
2025-11-19 13:08:31,421 - INFO - Processing test split...
2025-11-19 13:08:31,421 - INFO - Need to process 38/38 sequences for test
2025-11-19 13:08:31,422 - INFO - Processing 38 sequences from 9 unique files
2025-11-19 13:08:31,422 - INFO - Average 4.2 sequences per file
Processing test:   0%|                              | 0/38 [00:00<?, ?it/s]Processing test:   3%|5                     | 1/38 [00:01<00:43,  1.18s/it]Processing test:   8%|#7                    | 3/38 [00:01<00:15,  2.33it/s]Processing test:  13%|##8                   | 5/38 [00:02<00:11,  2.97it/s]2025-11-19 13:08:33,437 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold6\test_dataset.h5
2025-11-19 13:08:34,786 - INFO - Progress: 199/214 (93.0%) - ETA: 0.0 minutes
Processing test:  63%|#############2       | 24/38 [00:04<00:02,  6.68it/s]Processing test:  71%|##############9      | 27/38 [00:05<00:01,  5.62it/s]Processing test:  79%|################5    | 30/38 [00:05<00:01,  5.35it/s]2025-11-19 13:08:38,022 - INFO - Progress: 209/214 (97.7%) - ETA: 0.0 minutes
Processing test:  89%|##################7  | 34/38 [00:08<00:01,  3.64it/s]Processing test:  97%|####################4| 37/38 [00:08<00:00,  4.29it/s]Processing test: 100%|#####################| 38/38 [00:08<00:00,  4.22it/s]Processing test: 100%|#####################| 38/38 [00:08<00:00,  4.43it/s]
2025-11-19 13:08:40,340 - INFO - Validating final datasets...
2025-11-19 13:08:40,348 - INFO - train dataset validation:
2025-11-19 13:08:40,348 - INFO -   - Segments: 176
2025-11-19 13:08:40,348 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:08:40,348 - INFO -   - Classes: 88 preictal, 88 interictal
2025-11-19 13:08:40,348 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:08:40,353 - INFO - test dataset validation:
2025-11-19 13:08:40,354 - INFO -   - Segments: 38
2025-11-19 13:08:40,354 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:08:40,354 - INFO -   - Classes: 19 preictal, 19 interictal
2025-11-19 13:08:40,354 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:08:40,354 - INFO - ============================================================
2025-11-19 13:08:40,354 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 13:08:40,354 - INFO - Total time: 0.6 minutes
2025-11-19 13:08:40,354 - INFO - Processed segments: 214
2025-11-19 13:08:40,354 - INFO - Average rate: 5.9 segments/second
2025-11-19 13:08:40,354 - INFO - ============================================================
✅ Fold 6 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 7/9
============================================================
2025-11-19 13:08:40,381 - INFO - ============================================================
2025-11-19 13:08:40,381 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 13:08:40,381 - INFO - ============================================================
2025-11-19 13:08:40,381 - INFO - Output prefix: chb16_fold7
2025-11-19 13:08:40,381 - INFO - EEG Preprocessor initialized
2025-11-19 13:08:40,382 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 13:08:40,382 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 13:08:40,382 - INFO - Segment duration: 5 seconds
2025-11-19 13:08:40,382 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 13:08:40,382 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 13:08:40,382 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 13:08:40,382 - INFO - Loading segments from chb16_fold7_sequences_prediction.json
2025-11-19 13:08:40,394 - INFO - Loaded 218 total sequences
2025-11-19 13:08:40,394 - INFO - Channel validation (from segmentation): 19/19 files valid
2025-11-19 13:08:40,394 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 13:08:40,394 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 13:08:40,394 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 13:08:40,394 - INFO - train: 176 sequences (88 preictal, 88 interictal)
2025-11-19 13:08:40,394 - INFO - test: 42 sequences (21 preictal, 21 interictal)
2025-11-19 13:08:40,406 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 13:08:40,407 - INFO - train: kept 88 preictal and 88 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:08:40,407 - INFO - test: kept 21 preictal and 21 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:08:40,419 - INFO - ============================================================
2025-11-19 13:08:40,419 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 13:08:40,419 - INFO - ============================================================
2025-11-19 13:08:40,419 - INFO - Processing 176 training samples to compute normalization stats...
2025-11-19 13:08:40,419 - INFO - Processing 176 sequences from 14 unique files
Processing training data:   0%|                    | 0/176 [00:00<?, ?it/s]Processing training data:   1%|            | 1/176 [00:00<01:22,  2.13it/s]Processing training data:   7%|8          | 13/176 [00:01<00:22,  7.30it/s]Processing training data:  15%|#6         | 26/176 [00:02<00:14, 10.24it/s]Processing training data:  26%|##8        | 45/176 [00:04<00:11, 11.61it/s]Processing training data:  33%|###6       | 58/176 [00:05<00:11, 10.46it/s]Processing training data:  40%|####4      | 71/176 [00:07<00:10, 10.24it/s]Processing training data:  48%|#####2     | 84/176 [00:07<00:07, 12.87it/s]Processing training data:  52%|#####6     | 91/176 [00:08<00:06, 13.11it/s]Processing training data:  59%|#####8    | 103/176 [00:09<00:05, 12.61it/s]Processing training data:  70%|#######   | 124/176 [00:10<00:03, 13.86it/s]Processing training data:  76%|#######6  | 134/176 [00:11<00:03, 11.61it/s]Processing training data:  86%|########5 | 151/176 [00:13<00:02, 11.56it/s]Processing training data:  91%|######### | 160/176 [00:14<00:01,  9.82it/s]Processing training data:  97%|#########6| 170/176 [00:15<00:00, 10.06it/s]Processing training data: 100%|##########| 176/176 [00:15<00:00, 11.35it/s]
2025-11-19 13:08:55,933 - INFO - Computing normalization statistics from training data...
2025-11-19 13:08:56,183 - INFO - Normalization stats computed:
2025-11-19 13:08:56,183 - INFO -   Mean: 0.449934
2025-11-19 13:08:56,183 - INFO -   Std: 2.058515
2025-11-19 13:08:56,183 - INFO -   Saved to: preprocessing\checkpoints\chb16_fold7\normalization_stats.json
2025-11-19 13:08:56,206 - INFO - Applying normalization and saving 176 training sequences...
Normalizing and saving training data:   0%|        | 0/176 [00:00<?, ?it/s]2025-11-19 13:08:56,213 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold7\train_dataset.h5
Normalizing and saving training data:   6%| | 10/176 [00:00<00:10, 16.46it/Normalizing and saving training data:  11%|1| 20/176 [00:01<00:09, 16.23it/Normalizing and saving training data:  17%|1| 30/176 [00:01<00:09, 16.21it/Normalizing and saving training data:  23%|2| 40/176 [00:02<00:08, 16.22it/Normalizing and saving training data:  28%|2| 50/176 [00:03<00:07, 16.22it/Normalizing and saving training data:  34%|3| 60/176 [00:03<00:07, 16.20it/Normalizing and saving training data:  40%|3| 70/176 [00:04<00:06, 16.14it/Normalizing and saving training data:  45%|4| 80/176 [00:04<00:05, 16.07it/Normalizing and saving training data:  51%|5| 90/176 [00:05<00:05, 16.02it/Normalizing and saving training data:  57%|5| 100/176 [00:06<00:04, 16.07itNormalizing and saving training data:  62%|6| 110/176 [00:06<00:04, 16.08itNormalizing and saving training data:  68%|6| 120/176 [00:07<00:03, 16.07itNormalizing and saving training data:  74%|7| 130/176 [00:08<00:02, 16.10itNormalizing and saving training data:  80%|7| 140/176 [00:08<00:02, 15.98itNormalizing and saving training data:  85%|8| 150/176 [00:09<00:01, 15.96itNormalizing and saving training data:  91%|9| 160/176 [00:09<00:01, 15.88itNormalizing and saving training data:  97%|9| 170/176 [00:10<00:00, 15.91itNormalizing and saving training data: 100%|#| 176/176 [00:10<00:00, 16.62it
2025-11-19 13:09:07,193 - INFO - Training data processing completed during stats computation phase
2025-11-19 13:09:07,200 - INFO - Loaded normalization statistics:
2025-11-19 13:09:07,200 - INFO -   Mean: 0.449934
2025-11-19 13:09:07,200 - INFO -   Std: 2.058515
2025-11-19 13:09:07,200 - INFO - Split train already completed, skipping
2025-11-19 13:09:07,200 - INFO - Processing test split...
2025-11-19 13:09:07,200 - INFO - Need to process 42/42 sequences for test
2025-11-19 13:09:07,200 - INFO - Processing 42 sequences from 9 unique files
2025-11-19 13:09:07,200 - INFO - Average 4.7 sequences per file
Processing test:   0%|                              | 0/42 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/42 [00:01<00:53,  1.30s/it]Processing test:  12%|##6                   | 5/42 [00:01<00:11,  3.24it/s]2025-11-19 13:09:09,042 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold7\test_dataset.h5
2025-11-19 13:09:10,560 - INFO - Progress: 201/218 (92.2%) - ETA: 0.0 minutes
Processing test:  62%|#############        | 26/42 [00:04<00:02,  7.38it/s]Processing test:  67%|##############       | 28/42 [00:04<00:02,  6.28it/s]Processing test:  71%|###############      | 30/42 [00:05<00:02,  4.82it/s]Processing test:  81%|#################    | 34/42 [00:07<00:01,  4.04it/s]2025-11-19 13:09:15,267 - INFO - Progress: 213/218 (97.7%) - ETA: 0.0 minutes
Processing test:  90%|###################  | 38/42 [00:08<00:01,  3.52it/s]Processing test:  95%|#################### | 40/42 [00:09<00:00,  3.62it/s]Processing test: 100%|#####################| 42/42 [00:09<00:00,  4.00it/s]Processing test: 100%|#####################| 42/42 [00:09<00:00,  4.38it/s]
2025-11-19 13:09:17,128 - INFO - Validating final datasets...
2025-11-19 13:09:17,136 - INFO - train dataset validation:
2025-11-19 13:09:17,136 - INFO -   - Segments: 176
2025-11-19 13:09:17,136 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:09:17,136 - INFO -   - Classes: 88 preictal, 88 interictal
2025-11-19 13:09:17,136 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:09:17,142 - INFO - test dataset validation:
2025-11-19 13:09:17,142 - INFO -   - Segments: 42
2025-11-19 13:09:17,142 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:09:17,142 - INFO -   - Classes: 21 preictal, 21 interictal
2025-11-19 13:09:17,142 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:09:17,142 - INFO - ============================================================
2025-11-19 13:09:17,142 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 13:09:17,142 - INFO - Total time: 0.6 minutes
2025-11-19 13:09:17,142 - INFO - Processed segments: 218
2025-11-19 13:09:17,142 - INFO - Average rate: 5.9 segments/second
2025-11-19 13:09:17,142 - INFO - ============================================================
✅ Fold 7 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 8/9
============================================================
2025-11-19 13:09:17,169 - INFO - ============================================================
2025-11-19 13:09:17,169 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 13:09:17,169 - INFO - ============================================================
2025-11-19 13:09:17,169 - INFO - Output prefix: chb16_fold8
2025-11-19 13:09:17,169 - INFO - EEG Preprocessor initialized
2025-11-19 13:09:17,169 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 13:09:17,169 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 13:09:17,169 - INFO - Segment duration: 5 seconds
2025-11-19 13:09:17,170 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 13:09:17,170 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 13:09:17,170 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 13:09:17,170 - INFO - Loading segments from chb16_fold8_sequences_prediction.json
2025-11-19 13:09:17,183 - INFO - Loaded 216 total sequences
2025-11-19 13:09:17,183 - INFO - Channel validation (from segmentation): 19/19 files valid
2025-11-19 13:09:17,183 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 13:09:17,183 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 13:09:17,183 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 13:09:17,183 - INFO - train: 176 sequences (88 preictal, 88 interictal)
2025-11-19 13:09:17,183 - INFO - test: 40 sequences (20 preictal, 20 interictal)
2025-11-19 13:09:17,194 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 13:09:17,194 - INFO - train: kept 88 preictal and 88 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:09:17,194 - INFO - test: kept 20 preictal and 20 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:09:17,206 - INFO - ============================================================
2025-11-19 13:09:17,206 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 13:09:17,206 - INFO - ============================================================
2025-11-19 13:09:17,206 - INFO - Processing 176 training samples to compute normalization stats...
2025-11-19 13:09:17,206 - INFO - Processing 176 sequences from 14 unique files
Processing training data:   0%|                    | 0/176 [00:00<?, ?it/s]Processing training data:   1%|            | 1/176 [00:01<04:13,  1.45s/it]Processing training data:  19%|##1        | 34/176 [00:02<00:10, 13.99it/s]Processing training data:  28%|###        | 49/176 [00:04<00:09, 13.13it/s]Processing training data:  34%|###7       | 60/176 [00:04<00:07, 14.55it/s]Processing training data:  40%|####3      | 70/176 [00:05<00:08, 12.28it/s]Processing training data:  46%|#####      | 81/176 [00:06<00:06, 14.37it/s]Processing training data:  51%|#####6     | 90/176 [00:06<00:05, 15.61it/s]Processing training data:  58%|#####7    | 102/176 [00:08<00:05, 12.55it/s]Processing training data:  64%|######3   | 112/176 [00:09<00:06, 10.29it/s]Processing training data:  70%|#######   | 124/176 [00:10<00:04, 11.22it/s]Processing training data:  75%|#######5  | 132/176 [00:11<00:04,  9.22it/s]Processing training data:  81%|########1 | 143/176 [00:13<00:03,  8.63it/s]Processing training data:  87%|########6 | 153/176 [00:13<00:02, 10.47it/s]Processing training data:  93%|#########3| 164/176 [00:14<00:01,  9.73it/s]Processing training data: 100%|##########| 176/176 [00:14<00:00, 11.81it/s]
2025-11-19 13:09:32,111 - INFO - Computing normalization statistics from training data...
2025-11-19 13:09:32,361 - INFO - Normalization stats computed:
2025-11-19 13:09:32,362 - INFO -   Mean: 0.435303
2025-11-19 13:09:32,362 - INFO -   Std: 2.116003
2025-11-19 13:09:32,362 - INFO -   Saved to: preprocessing\checkpoints\chb16_fold8\normalization_stats.json
2025-11-19 13:09:32,380 - INFO - Applying normalization and saving 176 training sequences...
Normalizing and saving training data:   0%|        | 0/176 [00:00<?, ?it/s]2025-11-19 13:09:32,393 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold8\train_dataset.h5
Normalizing and saving training data:   6%| | 10/176 [00:00<00:10, 15.90it/Normalizing and saving training data:  11%|1| 20/176 [00:01<00:09, 15.86it/Normalizing and saving training data:  17%|1| 30/176 [00:01<00:09, 15.94it/Normalizing and saving training data:  23%|2| 40/176 [00:02<00:08, 15.99it/Normalizing and saving training data:  28%|2| 50/176 [00:03<00:07, 15.99it/Normalizing and saving training data:  34%|3| 60/176 [00:03<00:07, 15.98it/Normalizing and saving training data:  40%|3| 70/176 [00:04<00:06, 16.02it/Normalizing and saving training data:  45%|4| 80/176 [00:05<00:05, 16.03it/Normalizing and saving training data:  51%|5| 90/176 [00:05<00:05, 16.04it/Normalizing and saving training data:  57%|5| 100/176 [00:06<00:04, 16.03itNormalizing and saving training data:  62%|6| 110/176 [00:06<00:04, 16.08itNormalizing and saving training data:  68%|6| 120/176 [00:07<00:03, 16.09itNormalizing and saving training data:  74%|7| 130/176 [00:08<00:02, 16.04itNormalizing and saving training data:  80%|7| 140/176 [00:08<00:02, 15.90itNormalizing and saving training data:  85%|8| 150/176 [00:09<00:01, 15.84itNormalizing and saving training data:  91%|9| 160/176 [00:10<00:01, 15.81itNormalizing and saving training data:  97%|9| 170/176 [00:10<00:00, 15.79itNormalizing and saving training data: 100%|#| 176/176 [00:10<00:00, 16.50it
2025-11-19 13:09:43,445 - INFO - Training data processing completed during stats computation phase
2025-11-19 13:09:43,451 - INFO - Loaded normalization statistics:
2025-11-19 13:09:43,451 - INFO -   Mean: 0.435303
2025-11-19 13:09:43,451 - INFO -   Std: 2.116003
2025-11-19 13:09:43,451 - INFO - Split train already completed, skipping
2025-11-19 13:09:43,451 - INFO - Processing test split...
2025-11-19 13:09:43,452 - INFO - Need to process 40/40 sequences for test
2025-11-19 13:09:43,452 - INFO - Processing 40 sequences from 8 unique files
2025-11-19 13:09:43,452 - INFO - Average 5.0 sequences per file
Processing test:   0%|                              | 0/40 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/40 [00:00<00:19,  1.99it/s]2025-11-19 13:09:43,955 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold8\test_dataset.h5
2025-11-19 13:09:45,166 - INFO - Progress: 196/216 (90.7%) - ETA: 0.0 minutes
Processing test:  52%|###########          | 21/40 [00:03<00:02,  6.70it/s]Processing test:  60%|############6        | 24/40 [00:04<00:02,  5.51it/s]Processing test:  70%|##############7      | 28/40 [00:05<00:02,  4.81it/s]Processing test:  75%|###############7     | 30/40 [00:06<00:02,  3.61it/s]2025-11-19 13:09:50,998 - INFO - Progress: 209/216 (96.8%) - ETA: 0.0 minutes
Processing test:  85%|#################8   | 34/40 [00:08<00:01,  3.28it/s]Processing test:  95%|###################9 | 38/40 [00:08<00:00,  3.97it/s]Processing test: 100%|#####################| 40/40 [00:09<00:00,  4.32it/s]Processing test: 100%|#####################| 40/40 [00:09<00:00,  4.44it/s]
2025-11-19 13:09:52,918 - INFO - Validating final datasets...
2025-11-19 13:09:52,927 - INFO - train dataset validation:
2025-11-19 13:09:52,927 - INFO -   - Segments: 176
2025-11-19 13:09:52,927 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:09:52,927 - INFO -   - Classes: 88 preictal, 88 interictal
2025-11-19 13:09:52,927 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:09:52,932 - INFO - test dataset validation:
2025-11-19 13:09:52,932 - INFO -   - Segments: 40
2025-11-19 13:09:52,932 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:09:52,932 - INFO -   - Classes: 20 preictal, 20 interictal
2025-11-19 13:09:52,932 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:09:52,932 - INFO - ============================================================
2025-11-19 13:09:52,932 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 13:09:52,932 - INFO - Total time: 0.6 minutes
2025-11-19 13:09:52,932 - INFO - Processed segments: 216
2025-11-19 13:09:52,932 - INFO - Average rate: 6.0 segments/second
2025-11-19 13:09:52,932 - INFO - ============================================================
✅ Fold 8 preprocessing completed successfully!

============================================================
PREPROCESSING FOLD 9/9
============================================================
2025-11-19 13:09:52,959 - INFO - ============================================================
2025-11-19 13:09:52,960 - INFO - EEG PREPROCESSING PIPELINE STARTED
2025-11-19 13:09:52,960 - INFO - ============================================================
2025-11-19 13:09:52,960 - INFO - Output prefix: chb16_fold9
2025-11-19 13:09:52,960 - INFO - EEG Preprocessor initialized
2025-11-19 13:09:52,960 - INFO - Target channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P8-O2', 'T7-P7', 'T8-P8']
2025-11-19 13:09:52,960 - INFO - Filter settings: 0.5-50 Hz, notch: 60 Hz
2025-11-19 13:09:52,960 - INFO - Segment duration: 5 seconds
2025-11-19 13:09:52,960 - INFO - Note: Channel validation performed during segmentation phase
2025-11-19 13:09:52,960 - INFO - Multiprocessing: Using 10/16 CPU cores for parallel preprocessing
2025-11-19 13:09:52,960 - INFO - MNE parallel filtering: 8 jobs per sequence
2025-11-19 13:09:52,961 - INFO - Loading segments from chb16_fold9_sequences_prediction.json
2025-11-19 13:09:52,972 - INFO - Loaded 218 total sequences
2025-11-19 13:09:52,972 - INFO - Channel validation (from segmentation): 19/19 files valid
2025-11-19 13:09:52,972 - INFO - Using all sequences (channel validation performed during segmentation)
2025-11-19 13:09:52,972 - INFO - Detected pre-assigned splits in segmentation metadata; using them directly.
2025-11-19 13:09:52,973 - INFO - LOOCV Mode: Using 2-split configuration (train/test only) for fold None
2025-11-19 13:09:52,973 - INFO - train: 176 sequences (88 preictal, 88 interictal)
2025-11-19 13:09:52,973 - INFO - test: 42 sequences (21 preictal, 21 interictal)
2025-11-19 13:09:52,986 - INFO - Balancing splits to enforce equal positive/interictal counts per split...
2025-11-19 13:09:52,986 - INFO - train: kept 88 preictal and 88 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:09:52,986 - INFO - test: kept 21 preictal and 21 interictal (dropped 0 preictal, 0 interictal)
2025-11-19 13:09:52,999 - INFO - ============================================================
2025-11-19 13:09:52,999 - INFO - COMPUTING NORMALIZATION STATISTICS AND PROCESSING TRAINING DATA
2025-11-19 13:09:52,999 - INFO - ============================================================
2025-11-19 13:09:52,999 - INFO - Processing 176 training samples to compute normalization stats...
2025-11-19 13:09:52,999 - INFO - Processing 176 sequences from 14 unique files
Processing training data:   0%|                    | 0/176 [00:00<?, ?it/s]Processing training data:   1%|            | 1/176 [00:01<04:12,  1.44s/it]Processing training data:  18%|##         | 32/176 [00:02<00:10, 13.63it/s]Processing training data:  25%|##7        | 44/176 [00:04<00:11, 11.31it/s]Processing training data:  32%|###5       | 56/176 [00:05<00:11, 10.45it/s]Processing training data:  40%|####4      | 71/176 [00:05<00:07, 13.75it/s]Processing training data:  49%|#####4     | 87/176 [00:07<00:06, 12.79it/s]Processing training data:  57%|#####6    | 100/176 [00:07<00:05, 15.14it/s]Processing training data:  63%|######3   | 111/176 [00:09<00:05, 12.59it/s]Processing training data:  72%|#######1  | 126/176 [00:10<00:04, 12.28it/s]Processing training data:  79%|#######8  | 139/176 [00:11<00:03, 11.71it/s]Processing training data:  83%|########2 | 146/176 [00:12<00:02, 10.81it/s]Processing training data:  86%|########6 | 152/176 [00:13<00:02,  8.54it/s]Processing training data:  92%|#########2| 162/176 [00:14<00:01, 10.47it/s]Processing training data:  96%|#########6| 169/176 [00:14<00:00, 11.46it/s]Processing training data: 100%|##########| 176/176 [00:14<00:00, 11.91it/s]
2025-11-19 13:10:07,779 - INFO - Computing normalization statistics from training data...
2025-11-19 13:10:08,043 - INFO - Normalization stats computed:
2025-11-19 13:10:08,043 - INFO -   Mean: 0.452307
2025-11-19 13:10:08,043 - INFO -   Std: 2.076558
2025-11-19 13:10:08,043 - INFO -   Saved to: preprocessing\checkpoints\chb16_fold9\normalization_stats.json
2025-11-19 13:10:08,066 - INFO - Applying normalization and saving 176 training sequences...
Normalizing and saving training data:   0%|        | 0/176 [00:00<?, ?it/s]2025-11-19 13:10:08,073 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold9\train_dataset.h5
Normalizing and saving training data:   6%| | 10/176 [00:00<00:10, 16.26it/Normalizing and saving training data:  11%|1| 20/176 [00:01<00:09, 16.06it/Normalizing and saving training data:  17%|1| 30/176 [00:01<00:09, 15.94it/Normalizing and saving training data:  23%|2| 40/176 [00:02<00:08, 16.03it/Normalizing and saving training data:  28%|2| 50/176 [00:03<00:07, 16.04it/Normalizing and saving training data:  34%|3| 60/176 [00:03<00:07, 16.08it/Normalizing and saving training data:  40%|3| 70/176 [00:04<00:06, 16.14it/Normalizing and saving training data:  45%|4| 80/176 [00:04<00:05, 16.14it/Normalizing and saving training data:  51%|5| 90/176 [00:05<00:05, 16.13it/Normalizing and saving training data:  57%|5| 100/176 [00:06<00:04, 16.17itNormalizing and saving training data:  62%|6| 110/176 [00:06<00:04, 16.18itNormalizing and saving training data:  68%|6| 120/176 [00:07<00:03, 16.20itNormalizing and saving training data:  74%|7| 130/176 [00:08<00:02, 16.19itNormalizing and saving training data:  80%|7| 140/176 [00:08<00:02, 16.04itNormalizing and saving training data:  85%|8| 150/176 [00:09<00:01, 15.94itNormalizing and saving training data:  91%|9| 160/176 [00:09<00:01, 15.82itNormalizing and saving training data:  97%|9| 170/176 [00:10<00:00, 15.84itNormalizing and saving training data: 100%|#| 176/176 [00:10<00:00, 16.60it
2025-11-19 13:10:19,070 - INFO - Training data processing completed during stats computation phase
2025-11-19 13:10:19,079 - INFO - Loaded normalization statistics:
2025-11-19 13:10:19,079 - INFO -   Mean: 0.452307
2025-11-19 13:10:19,079 - INFO -   Std: 2.076558
2025-11-19 13:10:19,079 - INFO - Split train already completed, skipping
2025-11-19 13:10:19,079 - INFO - Processing test split...
2025-11-19 13:10:19,079 - INFO - Need to process 42/42 sequences for test
2025-11-19 13:10:19,079 - INFO - Processing 42 sequences from 9 unique files
2025-11-19 13:10:19,079 - INFO - Average 4.7 sequences per file
Processing test:   0%|                              | 0/42 [00:00<?, ?it/s]Processing test:   2%|5                     | 1/42 [00:01<00:58,  1.43s/it]Processing test:  12%|##6                   | 5/42 [00:02<00:19,  1.87it/s]Processing test:  24%|#####                | 10/42 [00:03<00:08,  3.88it/s]2025-11-19 13:10:22,403 - INFO - Creating new HDF5 file or datasets in: preprocessing\data\chb16_fold9\test_dataset.h5
2025-11-19 13:10:23,066 - INFO - Progress: 187/218 (85.8%) - ETA: 0.1 minutes
Processing test:  29%|######               | 12/42 [00:04<00:10,  2.91it/s]2025-11-19 13:10:24,853 - INFO - Progress: 208/218 (95.4%) - ETA: 0.0 minutes
Processing test:  79%|################5    | 33/42 [00:06<00:01,  6.30it/s]Processing test:  86%|##################   | 36/42 [00:07<00:01,  5.88it/s]Processing test:  90%|###################  | 38/42 [00:07<00:00,  6.02it/s]Processing test:  93%|###################5 | 39/42 [00:08<00:00,  5.78it/s]Processing test:  95%|#################### | 40/42 [00:08<00:00,  4.39it/s]2025-11-19 13:10:28,501 - INFO - Progress: 218/218 (100.0%) - ETA: 0.0 minutes
Processing test: 100%|#####################| 42/42 [00:09<00:00,  4.46it/s]
2025-11-19 13:10:28,513 - INFO - Validating final datasets...
2025-11-19 13:10:28,521 - INFO - train dataset validation:
2025-11-19 13:10:28,521 - INFO -   - Segments: 176
2025-11-19 13:10:28,521 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:10:28,521 - INFO -   - Classes: 88 preictal, 88 interictal
2025-11-19 13:10:28,521 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:10:28,526 - INFO - test dataset validation:
2025-11-19 13:10:28,526 - INFO -   - Segments: 42
2025-11-19 13:10:28,526 - INFO -   - Spectrogram shape: (30, 18, 50, 10)
2025-11-19 13:10:28,526 - INFO -   - Classes: 21 preictal, 21 interictal
2025-11-19 13:10:28,526 - INFO -   - Balance: 50.0% preictal
2025-11-19 13:10:28,527 - INFO - ============================================================
2025-11-19 13:10:28,527 - INFO - PREPROCESSING COMPLETED SUCCESSFULLY
2025-11-19 13:10:28,527 - INFO - Total time: 0.6 minutes
2025-11-19 13:10:28,527 - INFO - Processed segments: 218
2025-11-19 13:10:28,527 - INFO - Average rate: 6.1 segments/second
2025-11-19 13:10:28,527 - INFO - ============================================================
✅ Fold 9 preprocessing completed successfully!

============================================================
✅ BATCH PREPROCESSING COMPLETED!
✅ Processed 10 folds for patient chb16
============================================================
============================================================
BATCH PROCESSING: ALL FOLDS
Processing 10 folds for patient chb16
============================================================

============================================================
TRAINING FOLD 0/9
============================================================
Using dataset prefix: chb16_fold0
Loading datasets from: preprocessing\data\chb16_fold0
Saving models to: model\chb16_fold0
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=0.4356, std=2.0990
Loaded train dataset: 176 samples
  - Spectrogram shape: torch.Size([176, 30, 18, 50, 10])
  - Value range: [-5.9244, 4.6708]
  - Class distribution: tensor([88, 88])
LOOCV Mode (Fold 0): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6936, grad_norm=0.Training Epoch 1/5:   9%| | 1/11 [00:04<00:42,  4.28s/it, loss=0.6936, gradTraining Epoch 1/5:   9%| | 1/11 [00:04<00:42,  4.28s/it, loss=0.6930, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:16,  1.84s/it, loss=0.6930, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:16,  1.84s/it, loss=0.6958, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:08,  1.05s/it, loss=0.6958, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:08,  1.05s/it, loss=0.6935, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.47it/s, loss=0.6935, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.47it/s, loss=0.6818, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.10it/s, loss=0.6818, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.10it/s, loss=0.6877, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.79it/s, loss=0.6877, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.79it/s, loss=0.6814, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.60it/s, loss=0.6814, gradTraining Epoch 1/5:  64%|6| 7/11 [00:05<00:01,  3.60it/s, loss=0.6787, gradTraining Epoch 1/5:  73%|7| 8/11 [00:05<00:00,  4.40it/s, loss=0.6787, gradTraining Epoch 1/5:  73%|7| 8/11 [00:05<00:00,  4.40it/s, loss=0.6761, gradTraining Epoch 1/5:  82%|8| 9/11 [00:05<00:00,  5.21it/s, loss=0.6761, gradTraining Epoch 1/5:  82%|8| 9/11 [00:05<00:00,  5.21it/s, loss=0.6829, gradTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  5.92it/s, loss=0.6829, graTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  5.92it/s, loss=0.6663, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  6.55it/s, loss=0.6663, graTraining Epoch 1/5: 100%|#| 11/11 [00:06<00:00,  1.82it/s, loss=0.6663, gra

Epoch 1/5 Complete (6.5s) [LR: 0.000010]
Train - Loss: 0.6846, Acc: 0.6023, Precision: 0.6184, Recall: 0.5341, F1: 0.5732, AUC: 0.6468
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6919, grad_norm=0.Training Epoch 2/5:   9%| | 1/11 [00:04<00:41,  4.10s/it, loss=0.6919, gradTraining Epoch 2/5:   9%| | 1/11 [00:04<00:41,  4.10s/it, loss=0.6797, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.76s/it, loss=0.6797, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.76s/it, loss=0.6636, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:08,  1.01s/it, loss=0.6636, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:08,  1.01s/it, loss=0.6637, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.53it/s, loss=0.6637, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.53it/s, loss=0.6661, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.19it/s, loss=0.6661, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.19it/s, loss=0.6692, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  2.94it/s, loss=0.6692, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  2.94it/s, loss=0.6555, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.76it/s, loss=0.6555, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.76it/s, loss=0.6632, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.61it/s, loss=0.6632, gradTraining Epoch 2/5:  73%|7| 8/11 [00:05<00:00,  4.61it/s, loss=0.6581, gradTraining Epoch 2/5:  82%|8| 9/11 [00:05<00:00,  5.42it/s, loss=0.6581, gradTraining Epoch 2/5:  82%|8| 9/11 [00:05<00:00,  5.42it/s, loss=0.6407, gradTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.09it/s, loss=0.6407, graTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.09it/s, loss=0.6654, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  6.66it/s, loss=0.6654, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  1.88it/s, loss=0.6654, gra

Epoch 2/5 Complete (6.3s) [LR: 0.000010]
Train - Loss: 0.6652, Acc: 0.6648, Precision: 0.6629, Recall: 0.6705, F1: 0.6667, AUC: 0.7279
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6740, grad_norm=1.Training Epoch 3/5:   9%| | 1/11 [00:04<00:40,  4.05s/it, loss=0.6740, gradTraining Epoch 3/5:   9%| | 1/11 [00:04<00:40,  4.05s/it, loss=0.6365, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6365, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.7324, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.00it/s, loss=0.7324, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.00it/s, loss=0.6321, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.6321, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.6622, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.6622, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.6718, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  2.98it/s, loss=0.6718, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  2.98it/s, loss=0.5915, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.82it/s, loss=0.5915, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.82it/s, loss=0.6057, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.67it/s, loss=0.6057, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.67it/s, loss=0.6555, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.51it/s, loss=0.6555, gradTraining Epoch 3/5:  82%|8| 9/11 [00:05<00:00,  5.51it/s, loss=0.6271, gradTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.28it/s, loss=0.6271, graTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.28it/s, loss=0.5871, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  6.87it/s, loss=0.5871, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  1.91it/s, loss=0.5871, gra

Epoch 3/5 Complete (6.2s) [LR: 0.000010]
Train - Loss: 0.6433, Acc: 0.7102, Precision: 0.6907, Recall: 0.7614, F1: 0.7243, AUC: 0.7771
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6062, grad_norm=1.Training Epoch 4/5:   9%| | 1/11 [00:03<00:39,  3.92s/it, loss=0.6062, gradTraining Epoch 4/5:   9%| | 1/11 [00:04<00:39,  3.92s/it, loss=0.5971, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.68s/it, loss=0.5971, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.68s/it, loss=0.6131, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.04it/s, loss=0.6131, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.04it/s, loss=0.6323, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.57it/s, loss=0.6323, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.57it/s, loss=0.6396, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.24it/s, loss=0.6396, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.24it/s, loss=0.5997, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  2.94it/s, loss=0.5997, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  2.94it/s, loss=0.6148, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.73it/s, loss=0.6148, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.73it/s, loss=0.5629, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.58it/s, loss=0.5629, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.58it/s, loss=0.6162, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.41it/s, loss=0.6162, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.41it/s, loss=0.6404, gradTraining Epoch 4/5:  91%|9| 10/11 [00:04<00:00,  6.19it/s, loss=0.6404, graTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.19it/s, loss=0.6034, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  6.65it/s, loss=0.6034, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  1.93it/s, loss=0.6034, gra

Epoch 4/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6114, Acc: 0.7159, Precision: 0.6638, Recall: 0.8750, F1: 0.7549, AUC: 0.8081
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6361, grad_norm=1.Training Epoch 5/5:   9%| | 1/11 [00:03<00:39,  3.91s/it, loss=0.6361, gradTraining Epoch 5/5:   9%| | 1/11 [00:04<00:39,  3.91s/it, loss=0.6143, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.68s/it, loss=0.6143, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.68s/it, loss=0.4853, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.4853, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6015, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.6015, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.5637, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.24it/s, loss=0.5637, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.24it/s, loss=0.5805, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  2.98it/s, loss=0.5805, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  2.98it/s, loss=0.5933, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.71it/s, loss=0.5933, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.71it/s, loss=0.4874, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.59it/s, loss=0.4874, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.59it/s, loss=0.6166, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.45it/s, loss=0.6166, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.45it/s, loss=0.4998, gradTraining Epoch 5/5:  91%|9| 10/11 [00:04<00:00,  6.23it/s, loss=0.4998, graTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  6.23it/s, loss=0.5779, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  6.58it/s, loss=0.5779, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  1.94it/s, loss=0.5779, gra

Epoch 5/5 Complete (6.1s) [LR: 0.000005]
Train - Loss: 0.5688, Acc: 0.7045, Precision: 0.6579, Recall: 0.8523, F1: 0.7426, AUC: 0.8079
------------------------------------------------------------
Training curves saved to model\chb16_fold0\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.5 minutes
Models saved in: model\chb16_fold0
============================================================
✅ Fold 0 training completed successfully!

============================================================
TRAINING FOLD 1/9
============================================================
Using dataset prefix: chb16_fold1
Loading datasets from: preprocessing\data\chb16_fold1
Saving models to: model\chb16_fold1
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=0.4847, std=2.0626
Loaded train dataset: 176 samples
  - Spectrogram shape: torch.Size([176, 30, 18, 50, 10])
  - Value range: [-6.0530, 4.5102]
  - Class distribution: tensor([88, 88])
LOOCV Mode (Fold 1): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.7073, grad_norm=1.Training Epoch 1/5:   9%| | 1/11 [00:03<00:39,  3.94s/it, loss=0.7073, gradTraining Epoch 1/5:   9%| | 1/11 [00:04<00:39,  3.94s/it, loss=0.6879, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6879, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6948, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:07,  1.02it/s, loss=0.6948, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:07,  1.02it/s, loss=0.6706, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.6706, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.7027, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.19it/s, loss=0.7027, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.19it/s, loss=0.7013, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.86it/s, loss=0.7013, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.86it/s, loss=0.6747, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.57it/s, loss=0.6747, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.57it/s, loss=0.7197, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.44it/s, loss=0.7197, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.44it/s, loss=0.7028, gradTraining Epoch 1/5:  82%|8| 9/11 [00:04<00:00,  5.30it/s, loss=0.7028, gradTraining Epoch 1/5:  82%|8| 9/11 [00:05<00:00,  5.30it/s, loss=0.6621, gradTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.08it/s, loss=0.6621, graTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.08it/s, loss=0.6867, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  6.82it/s, loss=0.6867, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  1.91it/s, loss=0.6867, gra

Epoch 1/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6919, Acc: 0.5227, Precision: 0.5833, Recall: 0.1591, F1: 0.2500, AUC: 0.5518
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6624, grad_norm=1.Training Epoch 2/5:   9%| | 1/11 [00:03<00:38,  3.86s/it, loss=0.6624, gradTraining Epoch 2/5:   9%| | 1/11 [00:03<00:38,  3.86s/it, loss=0.6827, gradTraining Epoch 2/5:  18%|1| 2/11 [00:03<00:14,  1.66s/it, loss=0.6827, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:14,  1.66s/it, loss=0.6667, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.04it/s, loss=0.6667, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.04it/s, loss=0.6719, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.6719, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.6639, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.6639, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.6740, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  2.99it/s, loss=0.6740, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  2.99it/s, loss=0.6852, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.83it/s, loss=0.6852, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.83it/s, loss=0.6931, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.60it/s, loss=0.6931, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.60it/s, loss=0.7085, gradTraining Epoch 2/5:  82%|8| 9/11 [00:04<00:00,  5.27it/s, loss=0.7085, gradTraining Epoch 2/5:  82%|8| 9/11 [00:04<00:00,  5.27it/s, loss=0.6645, gradTraining Epoch 2/5:  91%|9| 10/11 [00:04<00:00,  6.05it/s, loss=0.6645, graTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.05it/s, loss=0.6608, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  6.71it/s, loss=0.6608, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  1.95it/s, loss=0.6608, gra

Epoch 2/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6758, Acc: 0.5511, Precision: 0.6667, Recall: 0.2045, F1: 0.3130, AUC: 0.7199
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6698, grad_norm=1.Training Epoch 3/5:   9%| | 1/11 [00:03<00:39,  3.97s/it, loss=0.6698, gradTraining Epoch 3/5:   9%| | 1/11 [00:04<00:39,  3.97s/it, loss=0.6590, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6590, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6467, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6467, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.7002, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.7002, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.6526, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6526, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6531, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  3.03it/s, loss=0.6531, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  3.03it/s, loss=0.6401, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.88it/s, loss=0.6401, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.88it/s, loss=0.6603, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.76it/s, loss=0.6603, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.76it/s, loss=0.6585, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.62it/s, loss=0.6585, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.62it/s, loss=0.6441, gradTraining Epoch 3/5:  91%|9| 10/11 [00:04<00:00,  6.09it/s, loss=0.6441, graTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.09it/s, loss=0.6246, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  6.67it/s, loss=0.6246, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  1.94it/s, loss=0.6246, gra

Epoch 3/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6554, Acc: 0.7159, Precision: 0.7065, Recall: 0.7386, F1: 0.7222, AUC: 0.7845
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.5974, grad_norm=1.Training Epoch 4/5:   9%| | 1/11 [00:04<00:40,  4.08s/it, loss=0.5974, gradTraining Epoch 4/5:   9%| | 1/11 [00:04<00:40,  4.08s/it, loss=0.6684, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.75s/it, loss=0.6684, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.75s/it, loss=0.6522, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:08,  1.00s/it, loss=0.6522, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:08,  1.00s/it, loss=0.5884, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.54it/s, loss=0.5884, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.54it/s, loss=0.6123, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.20it/s, loss=0.6123, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.20it/s, loss=0.5868, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  2.92it/s, loss=0.5868, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  2.92it/s, loss=0.6141, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.66it/s, loss=0.6141, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.66it/s, loss=0.6871, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.52it/s, loss=0.6871, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.52it/s, loss=0.6731, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.38it/s, loss=0.6731, gradTraining Epoch 4/5:  82%|8| 9/11 [00:05<00:00,  5.38it/s, loss=0.5813, gradTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.19it/s, loss=0.5813, graTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.19it/s, loss=0.6589, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  6.90it/s, loss=0.6589, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  1.90it/s, loss=0.6589, gra

Epoch 4/5 Complete (6.2s) [LR: 0.000010]
Train - Loss: 0.6291, Acc: 0.7386, Precision: 0.6780, Recall: 0.9091, F1: 0.7767, AUC: 0.8241
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6248, grad_norm=1.Training Epoch 5/5:   9%| | 1/11 [00:04<00:40,  4.06s/it, loss=0.6248, gradTraining Epoch 5/5:   9%| | 1/11 [00:04<00:40,  4.06s/it, loss=0.5877, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.5877, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6227, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6227, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6399, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.6399, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.6104, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.6104, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.5882, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  3.00it/s, loss=0.5882, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  3.00it/s, loss=0.6678, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.84it/s, loss=0.6678, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.84it/s, loss=0.5592, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.73it/s, loss=0.5592, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.73it/s, loss=0.5172, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.59it/s, loss=0.5172, gradTraining Epoch 5/5:  82%|8| 9/11 [00:05<00:00,  5.59it/s, loss=0.5542, gradTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  6.39it/s, loss=0.5542, graTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  6.39it/s, loss=0.5276, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  7.04it/s, loss=0.5276, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  1.92it/s, loss=0.5276, gra

Epoch 5/5 Complete (6.1s) [LR: 0.000005]
Train - Loss: 0.5909, Acc: 0.7500, Precision: 0.6897, Recall: 0.9091, F1: 0.7843, AUC: 0.8286
------------------------------------------------------------
Training curves saved to model\chb16_fold1\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.5 minutes
Models saved in: model\chb16_fold1
============================================================
✅ Fold 1 training completed successfully!

============================================================
TRAINING FOLD 2/9
============================================================
Using dataset prefix: chb16_fold2
Loading datasets from: preprocessing\data\chb16_fold2
Saving models to: model\chb16_fold2
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=0.5071, std=2.0573
Loaded train dataset: 176 samples
  - Spectrogram shape: torch.Size([176, 30, 18, 50, 10])
  - Value range: [-6.0794, 4.5401]
  - Class distribution: tensor([88, 88])
LOOCV Mode (Fold 2): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6912, grad_norm=1.Training Epoch 1/5:   9%| | 1/11 [00:04<00:40,  4.10s/it, loss=0.6912, gradTraining Epoch 1/5:   9%| | 1/11 [00:04<00:40,  4.10s/it, loss=0.6971, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.75s/it, loss=0.6971, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.75s/it, loss=0.7017, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:08,  1.00s/it, loss=0.7017, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:08,  1.00s/it, loss=0.6945, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.54it/s, loss=0.6945, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.54it/s, loss=0.6852, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.20it/s, loss=0.6852, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.20it/s, loss=0.6820, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.96it/s, loss=0.6820, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.96it/s, loss=0.6849, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.78it/s, loss=0.6849, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.78it/s, loss=0.6790, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.64it/s, loss=0.6790, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.64it/s, loss=0.6857, gradTraining Epoch 1/5:  82%|8| 9/11 [00:04<00:00,  5.47it/s, loss=0.6857, gradTraining Epoch 1/5:  82%|8| 9/11 [00:05<00:00,  5.47it/s, loss=0.6912, gradTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.25it/s, loss=0.6912, graTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.25it/s, loss=0.6894, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  6.85it/s, loss=0.6894, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  1.90it/s, loss=0.6894, gra

Epoch 1/5 Complete (6.2s) [LR: 0.000010]
Train - Loss: 0.6893, Acc: 0.5170, Precision: 0.5161, Recall: 0.5455, F1: 0.5304, AUC: 0.5638
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6851, grad_norm=1.Training Epoch 2/5:   9%| | 1/11 [00:04<00:40,  4.05s/it, loss=0.6851, gradTraining Epoch 2/5:   9%| | 1/11 [00:04<00:40,  4.05s/it, loss=0.6835, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6835, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6898, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6898, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6876, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.6876, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.6832, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.6832, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.6669, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  2.97it/s, loss=0.6669, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  2.97it/s, loss=0.6708, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.80it/s, loss=0.6708, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.80it/s, loss=0.6655, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.66it/s, loss=0.6655, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.66it/s, loss=0.6492, gradTraining Epoch 2/5:  82%|8| 9/11 [00:04<00:00,  5.49it/s, loss=0.6492, gradTraining Epoch 2/5:  82%|8| 9/11 [00:05<00:00,  5.49it/s, loss=0.6491, gradTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.25it/s, loss=0.6491, graTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.25it/s, loss=0.6655, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  6.90it/s, loss=0.6655, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  1.91it/s, loss=0.6655, gra

Epoch 2/5 Complete (6.2s) [LR: 0.000010]
Train - Loss: 0.6724, Acc: 0.6591, Precision: 0.6250, Recall: 0.7955, F1: 0.7000, AUC: 0.6985
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6606, grad_norm=1.Training Epoch 3/5:   9%| | 1/11 [00:04<00:40,  4.06s/it, loss=0.6606, gradTraining Epoch 3/5:   9%| | 1/11 [00:04<00:40,  4.06s/it, loss=0.6604, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6604, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6702, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.00it/s, loss=0.6702, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.00it/s, loss=0.6482, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.54it/s, loss=0.6482, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.54it/s, loss=0.6471, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.20it/s, loss=0.6471, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.20it/s, loss=0.6677, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  2.95it/s, loss=0.6677, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  2.95it/s, loss=0.6389, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.78it/s, loss=0.6389, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.78it/s, loss=0.6241, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.64it/s, loss=0.6241, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.64it/s, loss=0.6152, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.50it/s, loss=0.6152, gradTraining Epoch 3/5:  82%|8| 9/11 [00:05<00:00,  5.50it/s, loss=0.6158, gradTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.25it/s, loss=0.6158, graTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.25it/s, loss=0.6189, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  6.87it/s, loss=0.6189, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  1.91it/s, loss=0.6189, gra

Epoch 3/5 Complete (6.2s) [LR: 0.000010]
Train - Loss: 0.6425, Acc: 0.6818, Precision: 0.6356, Recall: 0.8523, F1: 0.7282, AUC: 0.7651
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.5840, grad_norm=1.Training Epoch 4/5:   9%| | 1/11 [00:04<00:40,  4.08s/it, loss=0.5840, gradTraining Epoch 4/5:   9%| | 1/11 [00:04<00:40,  4.08s/it, loss=0.6222, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.75s/it, loss=0.6222, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.75s/it, loss=0.5943, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:08,  1.01s/it, loss=0.5943, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:08,  1.01s/it, loss=0.6078, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.53it/s, loss=0.6078, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.53it/s, loss=0.6274, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.18it/s, loss=0.6274, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.18it/s, loss=0.5949, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  2.92it/s, loss=0.5949, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  2.92it/s, loss=0.5830, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.72it/s, loss=0.5830, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.72it/s, loss=0.6116, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.59it/s, loss=0.6116, gradTraining Epoch 4/5:  73%|7| 8/11 [00:05<00:00,  4.59it/s, loss=0.5610, gradTraining Epoch 4/5:  82%|8| 9/11 [00:05<00:00,  5.44it/s, loss=0.5610, gradTraining Epoch 4/5:  82%|8| 9/11 [00:05<00:00,  5.44it/s, loss=0.6063, gradTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.19it/s, loss=0.6063, graTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.19it/s, loss=0.5971, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  6.86it/s, loss=0.5971, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  1.89it/s, loss=0.5971, gra

Epoch 4/5 Complete (6.2s) [LR: 0.000010]
Train - Loss: 0.5991, Acc: 0.7159, Precision: 0.6397, Recall: 0.9886, F1: 0.7768, AUC: 0.8148
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.5826, grad_norm=1.Training Epoch 5/5:   9%| | 1/11 [00:04<00:42,  4.23s/it, loss=0.5826, gradTraining Epoch 5/5:   9%| | 1/11 [00:04<00:42,  4.23s/it, loss=0.5269, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:16,  1.81s/it, loss=0.5269, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:16,  1.81s/it, loss=0.6970, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:08,  1.04s/it, loss=0.6970, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:08,  1.04s/it, loss=0.6286, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.49it/s, loss=0.6286, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.49it/s, loss=0.5454, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.13it/s, loss=0.5454, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.13it/s, loss=0.5808, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  2.89it/s, loss=0.5808, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  2.89it/s, loss=0.4975, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.70it/s, loss=0.4975, gradTraining Epoch 5/5:  64%|6| 7/11 [00:05<00:01,  3.70it/s, loss=0.5888, gradTraining Epoch 5/5:  73%|7| 8/11 [00:05<00:00,  4.54it/s, loss=0.5888, gradTraining Epoch 5/5:  73%|7| 8/11 [00:05<00:00,  4.54it/s, loss=0.5011, gradTraining Epoch 5/5:  82%|8| 9/11 [00:05<00:00,  5.37it/s, loss=0.5011, gradTraining Epoch 5/5:  82%|8| 9/11 [00:05<00:00,  5.37it/s, loss=0.6099, gradTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  6.18it/s, loss=0.6099, graTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  6.18it/s, loss=0.5014, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  6.85it/s, loss=0.5014, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  1.85it/s, loss=0.5014, gra

Epoch 5/5 Complete (6.4s) [LR: 0.000005]
Train - Loss: 0.5691, Acc: 0.7216, Precision: 0.6560, Recall: 0.9318, F1: 0.7700, AUC: 0.8289
------------------------------------------------------------
Training curves saved to model\chb16_fold2\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.5 minutes
Models saved in: model\chb16_fold2
============================================================
✅ Fold 2 training completed successfully!

============================================================
TRAINING FOLD 3/9
============================================================
Using dataset prefix: chb16_fold3
Loading datasets from: preprocessing\data\chb16_fold3
Saving models to: model\chb16_fold3
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=0.3414, std=2.1019
Loaded train dataset: 176 samples
  - Spectrogram shape: torch.Size([176, 30, 18, 50, 10])
  - Value range: [-5.8715, 4.7282]
  - Class distribution: tensor([88, 88])
LOOCV Mode (Fold 3): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.7008, grad_norm=1.Training Epoch 1/5:   9%| | 1/11 [00:04<00:42,  4.20s/it, loss=0.7008, gradTraining Epoch 1/5:   9%| | 1/11 [00:04<00:42,  4.20s/it, loss=0.6926, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:16,  1.80s/it, loss=0.6926, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:16,  1.80s/it, loss=0.6764, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:08,  1.03s/it, loss=0.6764, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:08,  1.03s/it, loss=0.6968, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.50it/s, loss=0.6968, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.50it/s, loss=0.6885, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.15it/s, loss=0.6885, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.15it/s, loss=0.6905, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.89it/s, loss=0.6905, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.89it/s, loss=0.6920, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.72it/s, loss=0.6920, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.72it/s, loss=0.6940, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.57it/s, loss=0.6940, gradTraining Epoch 1/5:  73%|7| 8/11 [00:05<00:00,  4.57it/s, loss=0.6856, gradTraining Epoch 1/5:  82%|8| 9/11 [00:05<00:00,  5.40it/s, loss=0.6856, gradTraining Epoch 1/5:  82%|8| 9/11 [00:05<00:00,  5.40it/s, loss=0.6938, gradTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.16it/s, loss=0.6938, graTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.16it/s, loss=0.6851, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  6.82it/s, loss=0.6851, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  1.87it/s, loss=0.6851, gra

Epoch 1/5 Complete (6.3s) [LR: 0.000010]
Train - Loss: 0.6905, Acc: 0.5341, Precision: 0.5238, Recall: 0.7500, F1: 0.6168, AUC: 0.5514
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6800, grad_norm=1.Training Epoch 2/5:   9%| | 1/11 [00:04<00:40,  4.08s/it, loss=0.6800, gradTraining Epoch 2/5:   9%| | 1/11 [00:04<00:40,  4.08s/it, loss=0.6840, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.75s/it, loss=0.6840, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.75s/it, loss=0.6731, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:08,  1.00s/it, loss=0.6731, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:08,  1.00s/it, loss=0.6603, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.53it/s, loss=0.6603, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.53it/s, loss=0.6651, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.19it/s, loss=0.6651, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.19it/s, loss=0.6720, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  2.95it/s, loss=0.6720, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  2.95it/s, loss=0.6731, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.78it/s, loss=0.6731, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.78it/s, loss=0.6398, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.64it/s, loss=0.6398, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.64it/s, loss=0.6509, gradTraining Epoch 2/5:  82%|8| 9/11 [00:04<00:00,  5.48it/s, loss=0.6509, gradTraining Epoch 2/5:  82%|8| 9/11 [00:05<00:00,  5.48it/s, loss=0.6489, gradTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.23it/s, loss=0.6489, graTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.23it/s, loss=0.6608, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  6.84it/s, loss=0.6608, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  1.91it/s, loss=0.6608, gra

Epoch 2/5 Complete (6.2s) [LR: 0.000010]
Train - Loss: 0.6644, Acc: 0.6989, Precision: 0.6446, Recall: 0.8864, F1: 0.7464, AUC: 0.7565
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6646, grad_norm=1.Training Epoch 3/5:   9%| | 1/11 [00:04<00:40,  4.07s/it, loss=0.6646, gradTraining Epoch 3/5:   9%| | 1/11 [00:04<00:40,  4.07s/it, loss=0.6800, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6800, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6451, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.00it/s, loss=0.6451, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.00it/s, loss=0.6499, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.54it/s, loss=0.6499, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.54it/s, loss=0.6305, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.20it/s, loss=0.6305, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.20it/s, loss=0.6220, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  2.96it/s, loss=0.6220, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  2.96it/s, loss=0.5887, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.80it/s, loss=0.5887, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.80it/s, loss=0.6658, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.66it/s, loss=0.6658, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.66it/s, loss=0.6080, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.49it/s, loss=0.6080, gradTraining Epoch 3/5:  82%|8| 9/11 [00:05<00:00,  5.49it/s, loss=0.5863, gradTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.22it/s, loss=0.5863, graTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.22it/s, loss=0.5753, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  6.86it/s, loss=0.5753, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  1.91it/s, loss=0.5753, gra

Epoch 3/5 Complete (6.2s) [LR: 0.000010]
Train - Loss: 0.6288, Acc: 0.7273, Precision: 0.6724, Recall: 0.8864, F1: 0.7647, AUC: 0.8281
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6505, grad_norm=1.Training Epoch 4/5:   9%| | 1/11 [00:03<00:39,  3.95s/it, loss=0.6505, gradTraining Epoch 4/5:   9%| | 1/11 [00:04<00:39,  3.95s/it, loss=0.5897, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.5897, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.5790, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.02it/s, loss=0.5790, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.02it/s, loss=0.5778, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.5778, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.5840, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.5840, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.6504, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  2.96it/s, loss=0.6504, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  2.96it/s, loss=0.5880, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.78it/s, loss=0.5880, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.78it/s, loss=0.5516, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.60it/s, loss=0.5516, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.60it/s, loss=0.4970, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.40it/s, loss=0.4970, gradTraining Epoch 4/5:  82%|8| 9/11 [00:05<00:00,  5.40it/s, loss=0.6372, gradTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.09it/s, loss=0.6372, graTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.09it/s, loss=0.5624, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  6.70it/s, loss=0.5624, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  1.92it/s, loss=0.5624, gra

Epoch 4/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.5879, Acc: 0.7273, Precision: 0.6724, Recall: 0.8864, F1: 0.7647, AUC: 0.8542
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.5128, grad_norm=1.Training Epoch 5/5:   9%| | 1/11 [00:04<00:40,  4.03s/it, loss=0.5128, gradTraining Epoch 5/5:   9%| | 1/11 [00:04<00:40,  4.03s/it, loss=0.5269, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.73s/it, loss=0.5269, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.73s/it, loss=0.5634, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.5634, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.5632, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.5632, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.6099, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.6099, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.4682, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  2.98it/s, loss=0.4682, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  2.98it/s, loss=0.6148, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.81it/s, loss=0.6148, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.81it/s, loss=0.6303, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.55it/s, loss=0.6303, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.55it/s, loss=0.5762, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.27it/s, loss=0.5762, gradTraining Epoch 5/5:  82%|8| 9/11 [00:05<00:00,  5.27it/s, loss=0.5713, gradTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  5.98it/s, loss=0.5713, graTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  5.98it/s, loss=0.4240, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  6.65it/s, loss=0.4240, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  1.90it/s, loss=0.4240, gra

Epoch 5/5 Complete (6.2s) [LR: 0.000005]
Train - Loss: 0.5510, Acc: 0.7386, Precision: 0.6909, Recall: 0.8636, F1: 0.7677, AUC: 0.8505
------------------------------------------------------------
Training curves saved to model\chb16_fold3\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.5 minutes
Models saved in: model\chb16_fold3
============================================================
✅ Fold 3 training completed successfully!

============================================================
TRAINING FOLD 4/9
============================================================
Using dataset prefix: chb16_fold4
Loading datasets from: preprocessing\data\chb16_fold4
Saving models to: model\chb16_fold4
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=0.4321, std=2.0650
Loaded train dataset: 176 samples
  - Spectrogram shape: torch.Size([176, 30, 18, 50, 10])
  - Value range: [-6.0203, 4.6473]
  - Class distribution: tensor([88, 88])
LOOCV Mode (Fold 4): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6858, grad_norm=1.Training Epoch 1/5:   9%| | 1/11 [00:04<00:43,  4.40s/it, loss=0.6858, gradTraining Epoch 1/5:   9%| | 1/11 [00:04<00:43,  4.40s/it, loss=0.6903, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:16,  1.88s/it, loss=0.6903, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:16,  1.88s/it, loss=0.6856, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:08,  1.07s/it, loss=0.6856, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:08,  1.07s/it, loss=0.6930, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.44it/s, loss=0.6930, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.44it/s, loss=0.6749, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.08it/s, loss=0.6749, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.08it/s, loss=0.7071, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.81it/s, loss=0.7071, gradTraining Epoch 1/5:  55%|5| 6/11 [00:05<00:01,  2.81it/s, loss=0.6961, gradTraining Epoch 1/5:  64%|6| 7/11 [00:05<00:01,  3.63it/s, loss=0.6961, gradTraining Epoch 1/5:  64%|6| 7/11 [00:05<00:01,  3.63it/s, loss=0.6895, gradTraining Epoch 1/5:  73%|7| 8/11 [00:05<00:00,  4.47it/s, loss=0.6895, gradTraining Epoch 1/5:  73%|7| 8/11 [00:05<00:00,  4.47it/s, loss=0.6975, gradTraining Epoch 1/5:  82%|8| 9/11 [00:05<00:00,  5.30it/s, loss=0.6975, gradTraining Epoch 1/5:  82%|8| 9/11 [00:05<00:00,  5.30it/s, loss=0.6691, gradTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.07it/s, loss=0.6691, graTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.07it/s, loss=0.6780, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  6.67it/s, loss=0.6780, graTraining Epoch 1/5: 100%|#| 11/11 [00:06<00:00,  1.79it/s, loss=0.6780, gra

Epoch 1/5 Complete (6.6s) [LR: 0.000010]
Train - Loss: 0.6879, Acc: 0.5284, Precision: 0.5714, Recall: 0.2273, F1: 0.3252, AUC: 0.5830
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/11 [00:06<?, ?it/s, loss=0.6974, grad_norm=1.Training Epoch 2/5:   9%| | 1/11 [00:06<01:06,  6.66s/it, loss=0.6974, gradTraining Epoch 2/5:   9%| | 1/11 [00:06<01:06,  6.66s/it, loss=0.6855, gradTraining Epoch 2/5:  18%|1| 2/11 [00:06<00:25,  2.81s/it, loss=0.6855, gradTraining Epoch 2/5:  18%|1| 2/11 [00:06<00:25,  2.81s/it, loss=0.6949, gradTraining Epoch 2/5:  27%|2| 3/11 [00:06<00:12,  1.58s/it, loss=0.6949, gradTraining Epoch 2/5:  27%|2| 3/11 [00:07<00:12,  1.58s/it, loss=0.6688, gradTraining Epoch 2/5:  36%|3| 4/11 [00:07<00:07,  1.00s/it, loss=0.6688, gradTraining Epoch 2/5:  36%|3| 4/11 [00:07<00:07,  1.00s/it, loss=0.6567, gradTraining Epoch 2/5:  45%|4| 5/11 [00:07<00:04,  1.46it/s, loss=0.6567, gradTraining Epoch 2/5:  45%|4| 5/11 [00:07<00:04,  1.46it/s, loss=0.6827, gradTraining Epoch 2/5:  55%|5| 6/11 [00:07<00:02,  2.04it/s, loss=0.6827, gradTraining Epoch 2/5:  55%|5| 6/11 [00:07<00:02,  2.04it/s, loss=0.6772, gradTraining Epoch 2/5:  64%|6| 7/11 [00:07<00:01,  2.72it/s, loss=0.6772, gradTraining Epoch 2/5:  64%|6| 7/11 [00:07<00:01,  2.72it/s, loss=0.6649, gradTraining Epoch 2/5:  73%|7| 8/11 [00:07<00:00,  3.47it/s, loss=0.6649, gradTraining Epoch 2/5:  73%|7| 8/11 [00:07<00:00,  3.47it/s, loss=0.6541, gradTraining Epoch 2/5:  82%|8| 9/11 [00:07<00:00,  4.28it/s, loss=0.6541, gradTraining Epoch 2/5:  82%|8| 9/11 [00:07<00:00,  4.28it/s, loss=0.6633, gradTraining Epoch 2/5:  91%|9| 10/11 [00:07<00:00,  5.12it/s, loss=0.6633, graTraining Epoch 2/5:  91%|9| 10/11 [00:07<00:00,  5.12it/s, loss=0.6631, graTraining Epoch 2/5: 100%|#| 11/11 [00:07<00:00,  5.90it/s, loss=0.6631, graTraining Epoch 2/5: 100%|#| 11/11 [00:08<00:00,  1.31it/s, loss=0.6631, gra

Epoch 2/5 Complete (8.8s) [LR: 0.000010]
Train - Loss: 0.6735, Acc: 0.6364, Precision: 0.6500, Recall: 0.5909, F1: 0.6190, AUC: 0.6906
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/11 [00:05<?, ?it/s, loss=0.6492, grad_norm=1.Training Epoch 3/5:   9%| | 1/11 [00:05<00:57,  5.75s/it, loss=0.6492, gradTraining Epoch 3/5:   9%| | 1/11 [00:05<00:57,  5.75s/it, loss=0.6747, gradTraining Epoch 3/5:  18%|1| 2/11 [00:05<00:21,  2.44s/it, loss=0.6747, gradTraining Epoch 3/5:  18%|1| 2/11 [00:05<00:21,  2.44s/it, loss=0.6440, gradTraining Epoch 3/5:  27%|2| 3/11 [00:05<00:10,  1.37s/it, loss=0.6440, gradTraining Epoch 3/5:  27%|2| 3/11 [00:06<00:10,  1.37s/it, loss=0.6507, gradTraining Epoch 3/5:  36%|3| 4/11 [00:06<00:06,  1.15it/s, loss=0.6507, gradTraining Epoch 3/5:  36%|3| 4/11 [00:06<00:06,  1.15it/s, loss=0.6464, gradTraining Epoch 3/5:  45%|4| 5/11 [00:06<00:03,  1.67it/s, loss=0.6464, gradTraining Epoch 3/5:  45%|4| 5/11 [00:06<00:03,  1.67it/s, loss=0.7026, gradTraining Epoch 3/5:  55%|5| 6/11 [00:06<00:02,  2.29it/s, loss=0.7026, gradTraining Epoch 3/5:  55%|5| 6/11 [00:06<00:02,  2.29it/s, loss=0.6555, gradTraining Epoch 3/5:  64%|6| 7/11 [00:06<00:01,  3.02it/s, loss=0.6555, gradTraining Epoch 3/5:  64%|6| 7/11 [00:06<00:01,  3.02it/s, loss=0.6609, gradTraining Epoch 3/5:  73%|7| 8/11 [00:06<00:00,  3.84it/s, loss=0.6609, gradTraining Epoch 3/5:  73%|7| 8/11 [00:06<00:00,  3.84it/s, loss=0.6538, gradTraining Epoch 3/5:  82%|8| 9/11 [00:06<00:00,  4.70it/s, loss=0.6538, gradTraining Epoch 3/5:  82%|8| 9/11 [00:06<00:00,  4.70it/s, loss=0.6270, gradTraining Epoch 3/5:  91%|9| 10/11 [00:06<00:00,  5.51it/s, loss=0.6270, graTraining Epoch 3/5:  91%|9| 10/11 [00:06<00:00,  5.51it/s, loss=0.6328, graTraining Epoch 3/5: 100%|#| 11/11 [00:06<00:00,  6.26it/s, loss=0.6328, graTraining Epoch 3/5: 100%|#| 11/11 [00:07<00:00,  1.48it/s, loss=0.6328, gra

Epoch 3/5 Complete (7.9s) [LR: 0.000010]
Train - Loss: 0.6543, Acc: 0.6477, Precision: 0.6300, Recall: 0.7159, F1: 0.6702, AUC: 0.6980
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6913, grad_norm=1.Training Epoch 4/5:   9%| | 1/11 [00:04<00:40,  4.04s/it, loss=0.6913, gradTraining Epoch 4/5:   9%| | 1/11 [00:04<00:40,  4.04s/it, loss=0.6521, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.73s/it, loss=0.6521, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.73s/it, loss=0.6427, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6427, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6661, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.6661, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.6076, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.6076, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.6415, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  3.00it/s, loss=0.6415, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  3.00it/s, loss=0.5798, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.84it/s, loss=0.5798, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.84it/s, loss=0.6124, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.72it/s, loss=0.6124, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.72it/s, loss=0.6225, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.58it/s, loss=0.6225, gradTraining Epoch 4/5:  82%|8| 9/11 [00:05<00:00,  5.58it/s, loss=0.5719, gradTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.35it/s, loss=0.5719, graTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.35it/s, loss=0.5922, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  7.03it/s, loss=0.5922, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  1.93it/s, loss=0.5922, gra

Epoch 4/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6255, Acc: 0.6420, Precision: 0.6087, Recall: 0.7955, F1: 0.6897, AUC: 0.7606
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.5650, grad_norm=1.Training Epoch 5/5:   9%| | 1/11 [00:03<00:39,  3.97s/it, loss=0.5650, gradTraining Epoch 5/5:   9%| | 1/11 [00:04<00:39,  3.97s/it, loss=0.6142, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6142, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.5874, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.5874, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.5541, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.5541, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.7277, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.7277, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.5402, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.5402, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.5815, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.90it/s, loss=0.5815, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.90it/s, loss=0.5962, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.78it/s, loss=0.5962, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.78it/s, loss=0.6073, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.64it/s, loss=0.6073, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.64it/s, loss=0.6312, gradTraining Epoch 5/5:  91%|9| 10/11 [00:04<00:00,  6.42it/s, loss=0.6312, graTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  6.42it/s, loss=0.5920, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  7.09it/s, loss=0.5920, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  1.96it/s, loss=0.5920, gra

Epoch 5/5 Complete (6.0s) [LR: 0.000005]
Train - Loss: 0.5997, Acc: 0.7102, Precision: 0.6581, Recall: 0.8750, F1: 0.7512, AUC: 0.7849
------------------------------------------------------------
Training curves saved to model\chb16_fold4\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.6 minutes
Models saved in: model\chb16_fold4
============================================================
✅ Fold 4 training completed successfully!

============================================================
TRAINING FOLD 5/9
============================================================
Using dataset prefix: chb16_fold5
Loading datasets from: preprocessing\data\chb16_fold5
Saving models to: model\chb16_fold5
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=0.4588, std=2.0686
Loaded train dataset: 176 samples
  - Spectrogram shape: torch.Size([176, 30, 18, 50, 10])
  - Value range: [-6.0228, 4.5932]
  - Class distribution: tensor([88, 88])
LOOCV Mode (Fold 5): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6876, grad_norm=1.Training Epoch 1/5:   9%| | 1/11 [00:03<00:39,  3.96s/it, loss=0.6876, gradTraining Epoch 1/5:   9%| | 1/11 [00:04<00:39,  3.96s/it, loss=0.6941, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6941, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6894, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6894, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6967, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.53it/s, loss=0.6967, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.53it/s, loss=0.6895, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.19it/s, loss=0.6895, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.19it/s, loss=0.6920, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.95it/s, loss=0.6920, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.95it/s, loss=0.6843, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.78it/s, loss=0.6843, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.78it/s, loss=0.6803, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.64it/s, loss=0.6803, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.64it/s, loss=0.6892, gradTraining Epoch 1/5:  82%|8| 9/11 [00:04<00:00,  5.47it/s, loss=0.6892, gradTraining Epoch 1/5:  82%|8| 9/11 [00:05<00:00,  5.47it/s, loss=0.6928, gradTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.23it/s, loss=0.6928, graTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.23it/s, loss=0.6985, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  6.84it/s, loss=0.6985, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  1.93it/s, loss=0.6985, gra

Epoch 1/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6904, Acc: 0.5625, Precision: 0.5733, Recall: 0.4886, F1: 0.5276, AUC: 0.5830
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6884, grad_norm=1.Training Epoch 2/5:   9%| | 1/11 [00:04<00:40,  4.03s/it, loss=0.6884, gradTraining Epoch 2/5:   9%| | 1/11 [00:04<00:40,  4.03s/it, loss=0.6867, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.73s/it, loss=0.6867, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.73s/it, loss=0.6913, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6913, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6830, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.6830, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.6959, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.23it/s, loss=0.6959, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.23it/s, loss=0.6878, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  3.00it/s, loss=0.6878, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  3.00it/s, loss=0.6758, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.86it/s, loss=0.6758, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.86it/s, loss=0.6820, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.72it/s, loss=0.6820, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.72it/s, loss=0.6760, gradTraining Epoch 2/5:  82%|8| 9/11 [00:04<00:00,  5.54it/s, loss=0.6760, gradTraining Epoch 2/5:  82%|8| 9/11 [00:05<00:00,  5.54it/s, loss=0.6756, gradTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.29it/s, loss=0.6756, graTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.29it/s, loss=0.6575, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  6.96it/s, loss=0.6575, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  1.93it/s, loss=0.6575, gra

Epoch 2/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6818, Acc: 0.6534, Precision: 0.6627, Recall: 0.6250, F1: 0.6433, AUC: 0.7035
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6750, grad_norm=1.Training Epoch 3/5:   9%| | 1/11 [00:03<00:39,  3.95s/it, loss=0.6750, gradTraining Epoch 3/5:   9%| | 1/11 [00:04<00:39,  3.95s/it, loss=0.6712, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.6712, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.6643, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6643, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6752, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.6752, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.6549, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6549, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6852, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.6852, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.6556, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.90it/s, loss=0.6556, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.90it/s, loss=0.6847, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.76it/s, loss=0.6847, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.76it/s, loss=0.6681, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.60it/s, loss=0.6681, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.60it/s, loss=0.6635, gradTraining Epoch 3/5:  91%|9| 10/11 [00:04<00:00,  6.35it/s, loss=0.6635, graTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.35it/s, loss=0.6509, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  7.00it/s, loss=0.6509, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  1.95it/s, loss=0.6509, gra

Epoch 3/5 Complete (6.0s) [LR: 0.000010]
Train - Loss: 0.6681, Acc: 0.6875, Precision: 0.6634, Recall: 0.7614, F1: 0.7090, AUC: 0.7447
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6530, grad_norm=1.Training Epoch 4/5:   9%| | 1/11 [00:03<00:39,  3.93s/it, loss=0.6530, gradTraining Epoch 4/5:   9%| | 1/11 [00:04<00:39,  3.93s/it, loss=0.6372, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.6372, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.6319, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.04it/s, loss=0.6319, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.04it/s, loss=0.6623, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.60it/s, loss=0.6623, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.60it/s, loss=0.6609, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.28it/s, loss=0.6609, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.28it/s, loss=0.6541, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  3.06it/s, loss=0.6541, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  3.06it/s, loss=0.6722, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.92it/s, loss=0.6722, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.92it/s, loss=0.6301, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.79it/s, loss=0.6301, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.79it/s, loss=0.5855, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.68it/s, loss=0.5855, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.68it/s, loss=0.6468, gradTraining Epoch 4/5:  91%|9| 10/11 [00:04<00:00,  6.45it/s, loss=0.6468, graTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.45it/s, loss=0.6529, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  7.10it/s, loss=0.6529, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  1.96it/s, loss=0.6529, gra

Epoch 4/5 Complete (6.0s) [LR: 0.000010]
Train - Loss: 0.6443, Acc: 0.7216, Precision: 0.6696, Recall: 0.8750, F1: 0.7586, AUC: 0.7868
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6039, grad_norm=1.Training Epoch 5/5:   9%| | 1/11 [00:04<00:40,  4.06s/it, loss=0.6039, gradTraining Epoch 5/5:   9%| | 1/11 [00:04<00:40,  4.06s/it, loss=0.6153, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6153, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.5945, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.00it/s, loss=0.5945, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.00it/s, loss=0.6287, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.54it/s, loss=0.6287, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.54it/s, loss=0.6513, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.6513, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.6240, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  2.98it/s, loss=0.6240, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  2.98it/s, loss=0.6122, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.83it/s, loss=0.6122, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.83it/s, loss=0.6560, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.71it/s, loss=0.6560, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.71it/s, loss=0.5886, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.57it/s, loss=0.5886, gradTraining Epoch 5/5:  82%|8| 9/11 [00:05<00:00,  5.57it/s, loss=0.5768, gradTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  6.27it/s, loss=0.5768, graTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  6.27it/s, loss=0.6195, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  6.96it/s, loss=0.6195, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  1.93it/s, loss=0.6195, gra

Epoch 5/5 Complete (6.1s) [LR: 0.000005]
Train - Loss: 0.6155, Acc: 0.7386, Precision: 0.6842, Recall: 0.8864, F1: 0.7723, AUC: 0.8073
------------------------------------------------------------
Training curves saved to model\chb16_fold5\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.5 minutes
Models saved in: model\chb16_fold5
============================================================
✅ Fold 5 training completed successfully!

============================================================
TRAINING FOLD 6/9
============================================================
Using dataset prefix: chb16_fold6
Loading datasets from: preprocessing\data\chb16_fold6
Saving models to: model\chb16_fold6
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=0.4437, std=2.0921
Loaded train dataset: 176 samples
  - Spectrogram shape: torch.Size([176, 30, 18, 50, 10])
  - Value range: [-5.9479, 4.6327]
  - Class distribution: tensor([88, 88])
LOOCV Mode (Fold 6): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6892, grad_norm=1.Training Epoch 1/5:   9%| | 1/11 [00:04<00:40,  4.02s/it, loss=0.6892, gradTraining Epoch 1/5:   9%| | 1/11 [00:04<00:40,  4.02s/it, loss=0.6825, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.72s/it, loss=0.6825, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.72s/it, loss=0.6965, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6965, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6720, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.6720, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.7034, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.7034, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.6692, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.97it/s, loss=0.6692, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.97it/s, loss=0.6971, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.77it/s, loss=0.6971, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.77it/s, loss=0.6722, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.60it/s, loss=0.6722, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.60it/s, loss=0.6865, gradTraining Epoch 1/5:  82%|8| 9/11 [00:04<00:00,  5.43it/s, loss=0.6865, gradTraining Epoch 1/5:  82%|8| 9/11 [00:05<00:00,  5.43it/s, loss=0.6790, gradTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.20it/s, loss=0.6790, graTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.20it/s, loss=0.6629, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  6.91it/s, loss=0.6629, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  1.92it/s, loss=0.6629, gra

Epoch 1/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6828, Acc: 0.6023, Precision: 0.5978, Recall: 0.6250, F1: 0.6111, AUC: 0.6358
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6696, grad_norm=1.Training Epoch 2/5:   9%| | 1/11 [00:04<00:40,  4.04s/it, loss=0.6696, gradTraining Epoch 2/5:   9%| | 1/11 [00:04<00:40,  4.04s/it, loss=0.6666, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.73s/it, loss=0.6666, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.73s/it, loss=0.6758, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6758, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6701, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.6701, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.6793, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.6793, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.6525, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  2.97it/s, loss=0.6525, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  2.97it/s, loss=0.6355, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.82it/s, loss=0.6355, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.82it/s, loss=0.6471, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.67it/s, loss=0.6471, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.67it/s, loss=0.6281, gradTraining Epoch 2/5:  82%|8| 9/11 [00:04<00:00,  5.50it/s, loss=0.6281, gradTraining Epoch 2/5:  82%|8| 9/11 [00:05<00:00,  5.50it/s, loss=0.6752, gradTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.26it/s, loss=0.6752, graTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.26it/s, loss=0.6543, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  6.89it/s, loss=0.6543, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  1.93it/s, loss=0.6543, gra

Epoch 2/5 Complete (6.2s) [LR: 0.000010]
Train - Loss: 0.6594, Acc: 0.6534, Precision: 0.6452, Recall: 0.6818, F1: 0.6630, AUC: 0.7282
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6362, grad_norm=1.Training Epoch 3/5:   9%| | 1/11 [00:04<00:40,  4.05s/it, loss=0.6362, gradTraining Epoch 3/5:   9%| | 1/11 [00:04<00:40,  4.05s/it, loss=0.6618, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.73s/it, loss=0.6618, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.73s/it, loss=0.6437, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.00it/s, loss=0.6437, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.00it/s, loss=0.6388, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.6388, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.5990, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.5990, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.6243, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  2.99it/s, loss=0.6243, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  2.99it/s, loss=0.5759, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.82it/s, loss=0.5759, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.82it/s, loss=0.6498, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.69it/s, loss=0.6498, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.69it/s, loss=0.6583, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.52it/s, loss=0.6583, gradTraining Epoch 3/5:  82%|8| 9/11 [00:05<00:00,  5.52it/s, loss=0.6323, gradTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.27it/s, loss=0.6323, graTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.27it/s, loss=0.5668, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  6.92it/s, loss=0.5668, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  1.92it/s, loss=0.5668, gra

Epoch 3/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6261, Acc: 0.6989, Precision: 0.6496, Recall: 0.8636, F1: 0.7415, AUC: 0.7723
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6109, grad_norm=1.Training Epoch 4/5:   9%| | 1/11 [00:03<00:39,  3.97s/it, loss=0.6109, gradTraining Epoch 4/5:   9%| | 1/11 [00:04<00:39,  3.97s/it, loss=0.5888, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.5888, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6163, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6163, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.5822, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.5822, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.6105, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.25it/s, loss=0.6105, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.25it/s, loss=0.7388, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  3.03it/s, loss=0.7388, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  3.03it/s, loss=0.5963, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.88it/s, loss=0.5963, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.88it/s, loss=0.6069, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.75it/s, loss=0.6069, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.75it/s, loss=0.5876, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.62it/s, loss=0.5876, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.62it/s, loss=0.5408, gradTraining Epoch 4/5:  91%|9| 10/11 [00:04<00:00,  6.38it/s, loss=0.5408, graTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.38it/s, loss=0.6734, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  7.06it/s, loss=0.6734, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  1.96it/s, loss=0.6734, gra

Epoch 4/5 Complete (6.0s) [LR: 0.000010]
Train - Loss: 0.6139, Acc: 0.7045, Precision: 0.6475, Recall: 0.8977, F1: 0.7524, AUC: 0.7482
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.5742, grad_norm=1.Training Epoch 5/5:   9%| | 1/11 [00:03<00:39,  3.95s/it, loss=0.5742, gradTraining Epoch 5/5:   9%| | 1/11 [00:04<00:39,  3.95s/it, loss=0.4888, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.4888, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.5201, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.5201, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.5716, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.5716, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.4762, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.4762, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6706, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.6706, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.6071, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.89it/s, loss=0.6071, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.89it/s, loss=0.7114, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.77it/s, loss=0.7114, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.77it/s, loss=0.5188, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.61it/s, loss=0.5188, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.61it/s, loss=0.5065, gradTraining Epoch 5/5:  91%|9| 10/11 [00:04<00:00,  6.37it/s, loss=0.5065, graTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  6.37it/s, loss=0.5542, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  7.01it/s, loss=0.5542, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  1.95it/s, loss=0.5542, gra

Epoch 5/5 Complete (6.0s) [LR: 0.000005]
Train - Loss: 0.5636, Acc: 0.7216, Precision: 0.6585, Recall: 0.9205, F1: 0.7678, AUC: 0.8239
------------------------------------------------------------
Training curves saved to model\chb16_fold6\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.5 minutes
Models saved in: model\chb16_fold6
============================================================
✅ Fold 6 training completed successfully!

============================================================
TRAINING FOLD 7/9
============================================================
Using dataset prefix: chb16_fold7
Loading datasets from: preprocessing\data\chb16_fold7
Saving models to: model\chb16_fold7
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=0.4499, std=2.0585
Loaded train dataset: 176 samples
  - Spectrogram shape: torch.Size([176, 30, 18, 50, 10])
  - Value range: [-6.0480, 4.5651]
  - Class distribution: tensor([88, 88])
LOOCV Mode (Fold 7): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.7146, grad_norm=1.Training Epoch 1/5:   9%| | 1/11 [00:03<00:39,  3.95s/it, loss=0.7146, gradTraining Epoch 1/5:   9%| | 1/11 [00:04<00:39,  3.95s/it, loss=0.6795, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.6795, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.7070, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.7070, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6997, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.6997, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.6961, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6961, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6852, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  3.03it/s, loss=0.6852, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  3.03it/s, loss=0.6857, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.87it/s, loss=0.6857, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.87it/s, loss=0.6901, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.72it/s, loss=0.6901, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.72it/s, loss=0.6946, gradTraining Epoch 1/5:  82%|8| 9/11 [00:04<00:00,  5.55it/s, loss=0.6946, gradTraining Epoch 1/5:  82%|8| 9/11 [00:04<00:00,  5.55it/s, loss=0.6866, gradTraining Epoch 1/5:  91%|9| 10/11 [00:04<00:00,  6.29it/s, loss=0.6866, graTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.29it/s, loss=0.6818, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  6.93it/s, loss=0.6818, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  1.95it/s, loss=0.6818, gra

Epoch 1/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6928, Acc: 0.5568, Precision: 0.5373, Recall: 0.8182, F1: 0.6486, AUC: 0.5008
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6788, grad_norm=1.Training Epoch 2/5:   9%| | 1/11 [00:04<00:40,  4.06s/it, loss=0.6788, gradTraining Epoch 2/5:   9%| | 1/11 [00:04<00:40,  4.06s/it, loss=0.6773, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6773, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6809, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.00it/s, loss=0.6809, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.00it/s, loss=0.6801, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.6801, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.6745, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.6745, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.21it/s, loss=0.6700, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  2.97it/s, loss=0.6700, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  2.97it/s, loss=0.7048, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.82it/s, loss=0.7048, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.82it/s, loss=0.6740, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.70it/s, loss=0.6740, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.70it/s, loss=0.6634, gradTraining Epoch 2/5:  82%|8| 9/11 [00:04<00:00,  5.56it/s, loss=0.6634, gradTraining Epoch 2/5:  82%|8| 9/11 [00:05<00:00,  5.56it/s, loss=0.6852, gradTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.28it/s, loss=0.6852, graTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.28it/s, loss=0.6699, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  6.92it/s, loss=0.6699, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  1.92it/s, loss=0.6699, gra

Epoch 2/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6781, Acc: 0.6307, Precision: 0.6018, Recall: 0.7727, F1: 0.6766, AUC: 0.6763
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6749, grad_norm=1.Training Epoch 3/5:   9%| | 1/11 [00:03<00:39,  3.96s/it, loss=0.6749, gradTraining Epoch 3/5:   9%| | 1/11 [00:04<00:39,  3.96s/it, loss=0.6633, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.6633, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.6613, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6613, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6602, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.6602, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.6557, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6557, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6616, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  3.03it/s, loss=0.6616, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  3.03it/s, loss=0.6452, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.87it/s, loss=0.6452, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.87it/s, loss=0.6587, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.73it/s, loss=0.6587, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.73it/s, loss=0.6253, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.56it/s, loss=0.6253, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.56it/s, loss=0.6356, gradTraining Epoch 3/5:  91%|9| 10/11 [00:04<00:00,  6.26it/s, loss=0.6356, graTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.26it/s, loss=0.6588, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  6.88it/s, loss=0.6588, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  1.94it/s, loss=0.6588, gra

Epoch 3/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6546, Acc: 0.6648, Precision: 0.6198, Recall: 0.8523, F1: 0.7177, AUC: 0.7845
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6389, grad_norm=1.Training Epoch 4/5:   9%| | 1/11 [00:04<00:40,  4.06s/it, loss=0.6389, gradTraining Epoch 4/5:   9%| | 1/11 [00:04<00:40,  4.06s/it, loss=0.6149, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6149, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.74s/it, loss=0.6081, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6081, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6709, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.6709, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.55it/s, loss=0.6624, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.6624, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.6411, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  3.00it/s, loss=0.6411, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  3.00it/s, loss=0.6022, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.85it/s, loss=0.6022, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.85it/s, loss=0.6689, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.74it/s, loss=0.6689, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.74it/s, loss=0.6636, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.57it/s, loss=0.6636, gradTraining Epoch 4/5:  82%|8| 9/11 [00:05<00:00,  5.57it/s, loss=0.5798, gradTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.35it/s, loss=0.5798, graTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.35it/s, loss=0.6268, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  7.03it/s, loss=0.6268, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  1.93it/s, loss=0.6268, gra

Epoch 4/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6343, Acc: 0.6648, Precision: 0.6218, Recall: 0.8409, F1: 0.7150, AUC: 0.8017
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6077, grad_norm=1.Training Epoch 5/5:   9%| | 1/11 [00:03<00:39,  3.97s/it, loss=0.6077, gradTraining Epoch 5/5:   9%| | 1/11 [00:04<00:39,  3.97s/it, loss=0.6209, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6209, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6105, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6105, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6005, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.6005, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.5836, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.25it/s, loss=0.5836, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.25it/s, loss=0.5742, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.5742, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.6040, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.90it/s, loss=0.6040, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.90it/s, loss=0.5973, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.78it/s, loss=0.5973, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.78it/s, loss=0.5321, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.61it/s, loss=0.5321, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.61it/s, loss=0.5504, gradTraining Epoch 5/5:  91%|9| 10/11 [00:04<00:00,  6.23it/s, loss=0.5504, graTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  6.23it/s, loss=0.5423, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  6.93it/s, loss=0.5423, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  1.96it/s, loss=0.5423, gra

Epoch 5/5 Complete (6.0s) [LR: 0.000005]
Train - Loss: 0.5840, Acc: 0.7330, Precision: 0.6783, Recall: 0.8864, F1: 0.7685, AUC: 0.8725
------------------------------------------------------------
Training curves saved to model\chb16_fold7\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.5 minutes
Models saved in: model\chb16_fold7
============================================================
✅ Fold 7 training completed successfully!

============================================================
TRAINING FOLD 8/9
============================================================
Using dataset prefix: chb16_fold8
Loading datasets from: preprocessing\data\chb16_fold8
Saving models to: model\chb16_fold8
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=0.4353, std=2.1160
Loaded train dataset: 176 samples
  - Spectrogram shape: torch.Size([176, 30, 18, 50, 10])
  - Value range: [-5.8768, 4.9397]
  - Class distribution: tensor([88, 88])
LOOCV Mode (Fold 8): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6845, grad_norm=1.Training Epoch 1/5:   9%| | 1/11 [00:04<00:40,  4.08s/it, loss=0.6845, gradTraining Epoch 1/5:   9%| | 1/11 [00:04<00:40,  4.08s/it, loss=0.6939, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.75s/it, loss=0.6939, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.75s/it, loss=0.6872, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:08,  1.00s/it, loss=0.6872, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:08,  1.00s/it, loss=0.6793, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.54it/s, loss=0.6793, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.54it/s, loss=0.6904, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.20it/s, loss=0.6904, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.20it/s, loss=0.6754, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.97it/s, loss=0.6754, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  2.97it/s, loss=0.6892, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.79it/s, loss=0.6892, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.79it/s, loss=0.6871, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.64it/s, loss=0.6871, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.64it/s, loss=0.6932, gradTraining Epoch 1/5:  82%|8| 9/11 [00:04<00:00,  5.50it/s, loss=0.6932, gradTraining Epoch 1/5:  82%|8| 9/11 [00:05<00:00,  5.50it/s, loss=0.6842, gradTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.26it/s, loss=0.6842, graTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.26it/s, loss=0.6928, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  6.89it/s, loss=0.6928, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  1.91it/s, loss=0.6928, gra

Epoch 1/5 Complete (6.2s) [LR: 0.000010]
Train - Loss: 0.6870, Acc: 0.5852, Precision: 0.5688, Recall: 0.7045, F1: 0.6294, AUC: 0.6059
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6947, grad_norm=1.Training Epoch 2/5:   9%| | 1/11 [00:03<00:39,  3.93s/it, loss=0.6947, gradTraining Epoch 2/5:   9%| | 1/11 [00:04<00:39,  3.93s/it, loss=0.6694, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.6694, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.6803, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6803, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6601, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.6601, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.6901, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6901, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6589, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.6589, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.6898, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.87it/s, loss=0.6898, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.87it/s, loss=0.6676, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.46it/s, loss=0.6676, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.46it/s, loss=0.6625, gradTraining Epoch 2/5:  82%|8| 9/11 [00:04<00:00,  5.29it/s, loss=0.6625, gradTraining Epoch 2/5:  82%|8| 9/11 [00:04<00:00,  5.29it/s, loss=0.6633, gradTraining Epoch 2/5:  91%|9| 10/11 [00:04<00:00,  6.06it/s, loss=0.6633, graTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.06it/s, loss=0.6485, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  6.78it/s, loss=0.6485, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  1.95it/s, loss=0.6485, gra

Epoch 2/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6714, Acc: 0.6648, Precision: 0.6629, Recall: 0.6705, F1: 0.6667, AUC: 0.6885
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/11 [00:04<?, ?it/s, loss=0.6824, grad_norm=1.Training Epoch 3/5:   9%| | 1/11 [00:04<00:40,  4.03s/it, loss=0.6824, gradTraining Epoch 3/5:   9%| | 1/11 [00:04<00:40,  4.03s/it, loss=0.6382, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.73s/it, loss=0.6382, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.73s/it, loss=0.6728, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6728, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.01it/s, loss=0.6388, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.6388, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.56it/s, loss=0.6543, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.6543, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.22it/s, loss=0.6557, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  2.98it/s, loss=0.6557, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  2.98it/s, loss=0.6364, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.82it/s, loss=0.6364, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.82it/s, loss=0.6483, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.68it/s, loss=0.6483, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.68it/s, loss=0.7027, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.53it/s, loss=0.7027, gradTraining Epoch 3/5:  82%|8| 9/11 [00:05<00:00,  5.53it/s, loss=0.6188, gradTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.34it/s, loss=0.6188, graTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.34it/s, loss=0.6248, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  7.01it/s, loss=0.6248, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  1.93it/s, loss=0.6248, gra

Epoch 3/5 Complete (6.1s) [LR: 0.000010]
Train - Loss: 0.6521, Acc: 0.6989, Precision: 0.6471, Recall: 0.8750, F1: 0.7440, AUC: 0.7151
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6539, grad_norm=1.Training Epoch 4/5:   9%| | 1/11 [00:03<00:39,  3.97s/it, loss=0.6539, gradTraining Epoch 4/5:   9%| | 1/11 [00:04<00:39,  3.97s/it, loss=0.6436, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6436, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6471, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.02it/s, loss=0.6471, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.02it/s, loss=0.6952, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.6952, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.5849, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.25it/s, loss=0.5849, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.25it/s, loss=0.6503, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  3.02it/s, loss=0.6503, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  3.02it/s, loss=0.5274, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.87it/s, loss=0.5274, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.87it/s, loss=0.6047, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.75it/s, loss=0.6047, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.75it/s, loss=0.6553, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.61it/s, loss=0.6553, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.61it/s, loss=0.6036, gradTraining Epoch 4/5:  91%|9| 10/11 [00:04<00:00,  6.36it/s, loss=0.6036, graTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.36it/s, loss=0.5296, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  7.03it/s, loss=0.5296, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  1.95it/s, loss=0.5296, gra

Epoch 4/5 Complete (6.0s) [LR: 0.000010]
Train - Loss: 0.6178, Acc: 0.7443, Precision: 0.6838, Recall: 0.9091, F1: 0.7805, AUC: 0.7735
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6389, grad_norm=1.Training Epoch 5/5:   9%| | 1/11 [00:03<00:39,  3.94s/it, loss=0.6389, gradTraining Epoch 5/5:   9%| | 1/11 [00:04<00:39,  3.94s/it, loss=0.5689, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.5689, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.5907, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.5907, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6811, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.6811, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.5719, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.5719, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.5408, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.5408, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.5594, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.90it/s, loss=0.5594, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.90it/s, loss=0.6251, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.77it/s, loss=0.6251, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.77it/s, loss=0.4814, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.64it/s, loss=0.4814, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.64it/s, loss=0.5480, gradTraining Epoch 5/5:  91%|9| 10/11 [00:04<00:00,  6.41it/s, loss=0.5480, graTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  6.41it/s, loss=0.5471, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  7.07it/s, loss=0.5471, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  1.97it/s, loss=0.5471, gra

Epoch 5/5 Complete (6.0s) [LR: 0.000005]
Train - Loss: 0.5776, Acc: 0.7273, Precision: 0.6587, Recall: 0.9432, F1: 0.7757, AUC: 0.8221
------------------------------------------------------------
Training curves saved to model\chb16_fold8\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.5 minutes
Models saved in: model\chb16_fold8
============================================================
✅ Fold 8 training completed successfully!

============================================================
TRAINING FOLD 9/9
============================================================
Using dataset prefix: chb16_fold9
Loading datasets from: preprocessing\data\chb16_fold9
Saving models to: model\chb16_fold9
🚀 CUDA detected: NVIDIA GeForce RTX 3090 Ti
Using device: cuda
  - Normalization: z-score, mean=0.4523, std=2.0766
Loaded train dataset: 176 samples
  - Spectrogram shape: torch.Size([176, 30, 18, 50, 10])
  - Value range: [-5.9966, 4.5453]
  - Class distribution: tensor([88, 88])
LOOCV Mode (Fold 9): No validation set, using training-only evaluation
Model initialized with 41286914 parameters
============================================================
STARTING EEG SEIZURE PREDICTION TRAINING
============================================================
Task mode: PREDICTION (preictal vs interictal)
LOOCV Mode: Fold None/9 (Test seizure: None)
Note: No validation set in LOOCV mode
Training for 5 epochs
Batch size: 16
Learning rate: 1e-05
Device: cuda (NVIDIA GeForce RTX 3090 Ti)
🚀 Using CUDA GPU - maximum performance!
============================================================
Training Epoch 1/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 1/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6871, grad_norm=1.Training Epoch 1/5:   9%| | 1/11 [00:03<00:39,  3.96s/it, loss=0.6871, gradTraining Epoch 1/5:   9%| | 1/11 [00:04<00:39,  3.96s/it, loss=0.7090, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.7090, gradTraining Epoch 1/5:  18%|1| 2/11 [00:04<00:15,  1.70s/it, loss=0.6892, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6892, gradTraining Epoch 1/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6830, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.6830, gradTraining Epoch 1/5:  36%|3| 4/11 [00:04<00:04,  1.58it/s, loss=0.6814, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.24it/s, loss=0.6814, gradTraining Epoch 1/5:  45%|4| 5/11 [00:04<00:02,  2.24it/s, loss=0.6959, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  3.01it/s, loss=0.6959, gradTraining Epoch 1/5:  55%|5| 6/11 [00:04<00:01,  3.01it/s, loss=0.6957, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.86it/s, loss=0.6957, gradTraining Epoch 1/5:  64%|6| 7/11 [00:04<00:01,  3.86it/s, loss=0.6841, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.72it/s, loss=0.6841, gradTraining Epoch 1/5:  73%|7| 8/11 [00:04<00:00,  4.72it/s, loss=0.6709, gradTraining Epoch 1/5:  82%|8| 9/11 [00:04<00:00,  5.56it/s, loss=0.6709, gradTraining Epoch 1/5:  82%|8| 9/11 [00:04<00:00,  5.56it/s, loss=0.6830, gradTraining Epoch 1/5:  91%|9| 10/11 [00:04<00:00,  6.32it/s, loss=0.6830, graTraining Epoch 1/5:  91%|9| 10/11 [00:05<00:00,  6.32it/s, loss=0.6885, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  6.96it/s, loss=0.6885, graTraining Epoch 1/5: 100%|#| 11/11 [00:05<00:00,  1.95it/s, loss=0.6885, gra

Epoch 1/5 Complete (6.0s) [LR: 0.000010]
Train - Loss: 0.6880, Acc: 0.5398, Precision: 0.5443, Recall: 0.4886, F1: 0.5150, AUC: 0.5830
------------------------------------------------------------
Training Epoch 2/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 2/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6696, grad_norm=1.Training Epoch 2/5:   9%| | 1/11 [00:03<00:39,  3.92s/it, loss=0.6696, gradTraining Epoch 2/5:   9%| | 1/11 [00:04<00:39,  3.92s/it, loss=0.6739, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.68s/it, loss=0.6739, gradTraining Epoch 2/5:  18%|1| 2/11 [00:04<00:15,  1.68s/it, loss=0.7096, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.04it/s, loss=0.7096, gradTraining Epoch 2/5:  27%|2| 3/11 [00:04<00:07,  1.04it/s, loss=0.6839, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.6839, gradTraining Epoch 2/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.6845, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6845, gradTraining Epoch 2/5:  45%|4| 5/11 [00:04<00:02,  2.26it/s, loss=0.6812, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  3.03it/s, loss=0.6812, gradTraining Epoch 2/5:  55%|5| 6/11 [00:04<00:01,  3.03it/s, loss=0.6743, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.87it/s, loss=0.6743, gradTraining Epoch 2/5:  64%|6| 7/11 [00:04<00:01,  3.87it/s, loss=0.6862, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.73it/s, loss=0.6862, gradTraining Epoch 2/5:  73%|7| 8/11 [00:04<00:00,  4.73it/s, loss=0.6532, gradTraining Epoch 2/5:  82%|8| 9/11 [00:04<00:00,  5.57it/s, loss=0.6532, gradTraining Epoch 2/5:  82%|8| 9/11 [00:04<00:00,  5.57it/s, loss=0.6611, gradTraining Epoch 2/5:  91%|9| 10/11 [00:04<00:00,  6.32it/s, loss=0.6611, graTraining Epoch 2/5:  91%|9| 10/11 [00:05<00:00,  6.32it/s, loss=0.6711, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  7.01it/s, loss=0.6711, graTraining Epoch 2/5: 100%|#| 11/11 [00:05<00:00,  1.96it/s, loss=0.6711, gra

Epoch 2/5 Complete (6.0s) [LR: 0.000010]
Train - Loss: 0.6771, Acc: 0.5739, Precision: 0.5730, Recall: 0.5795, F1: 0.5763, AUC: 0.6293
------------------------------------------------------------
Training Epoch 3/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 3/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6488, grad_norm=0.Training Epoch 3/5:   9%| | 1/11 [00:03<00:39,  3.92s/it, loss=0.6488, gradTraining Epoch 3/5:   9%| | 1/11 [00:04<00:39,  3.92s/it, loss=0.6512, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.68s/it, loss=0.6512, gradTraining Epoch 3/5:  18%|1| 2/11 [00:04<00:15,  1.68s/it, loss=0.6591, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.04it/s, loss=0.6591, gradTraining Epoch 3/5:  27%|2| 3/11 [00:04<00:07,  1.04it/s, loss=0.6427, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.6427, gradTraining Epoch 3/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.6963, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.27it/s, loss=0.6963, gradTraining Epoch 3/5:  45%|4| 5/11 [00:04<00:02,  2.27it/s, loss=0.6257, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.6257, gradTraining Epoch 3/5:  55%|5| 6/11 [00:04<00:01,  3.04it/s, loss=0.6325, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.88it/s, loss=0.6325, gradTraining Epoch 3/5:  64%|6| 7/11 [00:04<00:01,  3.88it/s, loss=0.6453, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.74it/s, loss=0.6453, gradTraining Epoch 3/5:  73%|7| 8/11 [00:04<00:00,  4.74it/s, loss=0.6154, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.58it/s, loss=0.6154, gradTraining Epoch 3/5:  82%|8| 9/11 [00:04<00:00,  5.58it/s, loss=0.6944, gradTraining Epoch 3/5:  91%|9| 10/11 [00:04<00:00,  6.33it/s, loss=0.6944, graTraining Epoch 3/5:  91%|9| 10/11 [00:05<00:00,  6.33it/s, loss=0.6534, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  6.98it/s, loss=0.6534, graTraining Epoch 3/5: 100%|#| 11/11 [00:05<00:00,  1.96it/s, loss=0.6534, gra

Epoch 3/5 Complete (6.0s) [LR: 0.000010]
Train - Loss: 0.6514, Acc: 0.6761, Precision: 0.6535, Recall: 0.7500, F1: 0.6984, AUC: 0.7512
------------------------------------------------------------
Training Epoch 4/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 4/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6393, grad_norm=1.Training Epoch 4/5:   9%| | 1/11 [00:03<00:39,  3.92s/it, loss=0.6393, gradTraining Epoch 4/5:   9%| | 1/11 [00:04<00:39,  3.92s/it, loss=0.6089, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.68s/it, loss=0.6089, gradTraining Epoch 4/5:  18%|1| 2/11 [00:04<00:15,  1.68s/it, loss=0.6328, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.04it/s, loss=0.6328, gradTraining Epoch 4/5:  27%|2| 3/11 [00:04<00:07,  1.04it/s, loss=0.5683, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.60it/s, loss=0.5683, gradTraining Epoch 4/5:  36%|3| 4/11 [00:04<00:04,  1.60it/s, loss=0.5981, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.28it/s, loss=0.5981, gradTraining Epoch 4/5:  45%|4| 5/11 [00:04<00:02,  2.28it/s, loss=0.5974, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  3.06it/s, loss=0.5974, gradTraining Epoch 4/5:  55%|5| 6/11 [00:04<00:01,  3.06it/s, loss=0.6317, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.92it/s, loss=0.6317, gradTraining Epoch 4/5:  64%|6| 7/11 [00:04<00:01,  3.92it/s, loss=0.6580, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.80it/s, loss=0.6580, gradTraining Epoch 4/5:  73%|7| 8/11 [00:04<00:00,  4.80it/s, loss=0.6697, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.67it/s, loss=0.6697, gradTraining Epoch 4/5:  82%|8| 9/11 [00:04<00:00,  5.67it/s, loss=0.6242, gradTraining Epoch 4/5:  91%|9| 10/11 [00:04<00:00,  6.44it/s, loss=0.6242, graTraining Epoch 4/5:  91%|9| 10/11 [00:05<00:00,  6.44it/s, loss=0.6532, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  7.09it/s, loss=0.6532, graTraining Epoch 4/5: 100%|#| 11/11 [00:05<00:00,  1.97it/s, loss=0.6532, gra

Epoch 4/5 Complete (6.0s) [LR: 0.000010]
Train - Loss: 0.6256, Acc: 0.7273, Precision: 0.6695, Recall: 0.8977, F1: 0.7670, AUC: 0.8031
------------------------------------------------------------
Training Epoch 5/5:   0%|                           | 0/11 [00:00<?, ?it/s]Training Epoch 5/5:   0%| | 0/11 [00:03<?, ?it/s, loss=0.6294, grad_norm=1.Training Epoch 5/5:   9%| | 1/11 [00:03<00:39,  3.95s/it, loss=0.6294, gradTraining Epoch 5/5:   9%| | 1/11 [00:04<00:39,  3.95s/it, loss=0.5557, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.5557, gradTraining Epoch 5/5:  18%|1| 2/11 [00:04<00:15,  1.69s/it, loss=0.5710, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.5710, gradTraining Epoch 5/5:  27%|2| 3/11 [00:04<00:07,  1.03it/s, loss=0.6192, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.6192, gradTraining Epoch 5/5:  36%|3| 4/11 [00:04<00:04,  1.59it/s, loss=0.5381, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.27it/s, loss=0.5381, gradTraining Epoch 5/5:  45%|4| 5/11 [00:04<00:02,  2.27it/s, loss=0.5706, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  3.05it/s, loss=0.5706, gradTraining Epoch 5/5:  55%|5| 6/11 [00:04<00:01,  3.05it/s, loss=0.5592, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.91it/s, loss=0.5592, gradTraining Epoch 5/5:  64%|6| 7/11 [00:04<00:01,  3.91it/s, loss=0.6540, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.80it/s, loss=0.6540, gradTraining Epoch 5/5:  73%|7| 8/11 [00:04<00:00,  4.80it/s, loss=0.6289, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.66it/s, loss=0.6289, gradTraining Epoch 5/5:  82%|8| 9/11 [00:04<00:00,  5.66it/s, loss=0.6203, gradTraining Epoch 5/5:  91%|9| 10/11 [00:04<00:00,  6.48it/s, loss=0.6203, graTraining Epoch 5/5:  91%|9| 10/11 [00:05<00:00,  6.48it/s, loss=0.5187, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  7.13it/s, loss=0.5187, graTraining Epoch 5/5: 100%|#| 11/11 [00:05<00:00,  1.97it/s, loss=0.5187, gra

Epoch 5/5 Complete (6.0s) [LR: 0.000005]
Train - Loss: 0.5877, Acc: 0.7557, Precision: 0.6923, Recall: 0.9205, F1: 0.7902, AUC: 0.8403
------------------------------------------------------------
Training curves saved to model\chb16_fold9\training_curves.png
============================================================
TRAINING COMPLETED!
Total training time: 0.5 minutes
Models saved in: model\chb16_fold9
============================================================
✅ Fold 9 training completed successfully!

============================================================
✅ BATCH TRAINING COMPLETED!
✅ Trained models for 10 folds for patient chb16
============================================================
============================================================
============================================================
BATCH EVALUATION: ALL FOLDS
BATCH EVALUATION: ALL FOLDS
Evaluating 10 folds for patient chb16
Evaluating 10 folds for patient chb16
============================================================
============================================================
Using CUDA: NVIDIA GeForce RTX 3090 Ti
Using CUDA: NVIDIA GeForce RTX 3090 Ti

============================================================
============================================================

EVALUATING FOLD 0/9
EVALUATING FOLD 0/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb16_fold0
Dataset prefix: chb16_fold0
Using test dataset: preprocessing\data\chb16_fold0\test_dataset.h5
Using test dataset: preprocessing\data\chb16_fold0\test_dataset.h5
Loading test dataset from preprocessing\data\chb16_fold0\test_dataset.h5...
Loading test dataset from preprocessing\data\chb16_fold0\test_dataset.h5...
  - Normalization: z-score, mean=0.4356, std=2.0990
  - Normalization: z-score, mean=0.4356, std=2.0990
Loaded test dataset: 40 samples
Loaded test dataset: 40 samples
  - Spectrogram shape: torch.Size([40, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([40, 30, 18, 50, 10])
  - Value range: [-5.9244, 3.8468]
  - Value range: [-5.9244, 3.8468]
  - Class distribution: tensor([20, 20])
  - Class distribution: tensor([20, 20])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb16_fold0\epoch_005.pth...
Loading model checkpoint from model\chb16_fold0\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:  33%|##########3                    | 1/3 [00:00<00:00,  4.32it/s]Testing:  33%|##########3                    | 1/3 [00:00<00:00,  4.32it/s]Testing: 100%|###############################| 3/3 [00:00<00:00,  9.87it/s]Testing: 100%|###############################| 3/3 [00:00<00:00,  9.87it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5367
Loss:      0.5367
Accuracy:  0.7500 (75.00%)
Accuracy:  0.7500 (75.00%)
Precision: 0.6667
Precision: 0.6667
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.8000
F1 Score:  0.8000
AUC-ROC:   0.9000
AUC-ROC:   0.9000

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal        10        10
Actual Interictal        10        10
       Preictal         0        20
       Preictal         0        20

Class Distribution:
Class Distribution:

True Interictal (0): 20 samples
True Interictal (0): 20 samples
True Preictal (1):   20 samples
True Preictal (1):   20 samples
Pred Interictal (0): 10 samples
Pred Interictal (0): 10 samples
Pred Preictal (1):   30 samples
Pred Preictal (1):   30 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.5000    0.6667        20
    Preictal     0.6667    1.0000    0.8000        20

    accuracy                         0.7500        40
   macro avg     0.8333    0.7500    0.7333        40
weighted avg     0.8333    0.7500    0.7333        40
              precision    recall  f1-score   support

  Interictal     1.0000    0.5000    0.6667        20
    Preictal     0.6667    1.0000    0.8000        20

    accuracy                         0.7500        40
   macro avg     0.8333    0.7500    0.7333        40
weighted avg     0.8333    0.7500    0.7333        40



✅ Results saved to model\chb16_fold0\test_results.json
✅ Results saved to model\chb16_fold0\test_results.json


============================================================
============================================================

EVALUATING FOLD 1/9
EVALUATING FOLD 1/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb16_fold1
Dataset prefix: chb16_fold1
Using test dataset: preprocessing\data\chb16_fold1\test_dataset.h5
Using test dataset: preprocessing\data\chb16_fold1\test_dataset.h5
Loading test dataset from preprocessing\data\chb16_fold1\test_dataset.h5...
Loading test dataset from preprocessing\data\chb16_fold1\test_dataset.h5...
  - Normalization: z-score, mean=0.4847, std=2.0626
  - Normalization: z-score, mean=0.4847, std=2.0626
Loaded test dataset: 42 samples
Loaded test dataset: 42 samples
  - Spectrogram shape: torch.Size([42, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([42, 30, 18, 50, 10])
  - Value range: [-6.0521, 5.0564]
  - Value range: [-6.0521, 5.0564]
  - Class distribution: tensor([21, 21])
  - Class distribution: tensor([21, 21])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb16_fold1\epoch_005.pth...
Loading model checkpoint from model\chb16_fold1\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 31.68it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 31.68it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5756
Loss:      0.5756
Accuracy:  0.7857 (78.57%)
Accuracy:  0.7857 (78.57%)
Precision: 0.7143
Precision: 0.7143
Recall:    0.9524
Recall:    0.9524
F1 Score:  0.8163
F1 Score:  0.8163
AUC-ROC:   0.8209
AUC-ROC:   0.8209

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal        13         8
Actual Interictal        13         8
       Preictal         1        20
       Preictal         1        20

Class Distribution:
Class Distribution:

True Interictal (0): 21 samples
True Interictal (0): 21 samples
True Preictal (1):   21 samples
True Preictal (1):   21 samples
Pred Interictal (0): 14 samples
Pred Interictal (0): 14 samples
Pred Preictal (1):   28 samples
Pred Preictal (1):   28 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     0.9286    0.6190    0.7429        21
    Preictal     0.7143    0.9524    0.8163        21

    accuracy                         0.7857        42
   macro avg     0.8214    0.7857    0.7796        42
weighted avg     0.8214    0.7857    0.7796        42
              precision    recall  f1-score   support

  Interictal     0.9286    0.6190    0.7429        21
    Preictal     0.7143    0.9524    0.8163        21

    accuracy                         0.7857        42
   macro avg     0.8214    0.7857    0.7796        42
weighted avg     0.8214    0.7857    0.7796        42



✅ Results saved to model\chb16_fold1\test_results.json
✅ Results saved to model\chb16_fold1\test_results.json


============================================================
============================================================

EVALUATING FOLD 2/9
EVALUATING FOLD 2/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb16_fold2
Dataset prefix: chb16_fold2
Using test dataset: preprocessing\data\chb16_fold2\test_dataset.h5
Using test dataset: preprocessing\data\chb16_fold2\test_dataset.h5
Loading test dataset from preprocessing\data\chb16_fold2\test_dataset.h5...
Loading test dataset from preprocessing\data\chb16_fold2\test_dataset.h5...
  - Normalization: z-score, mean=0.5071, std=2.0573
  - Normalization: z-score, mean=0.5071, std=2.0573
Loaded test dataset: 42 samples
Loaded test dataset: 42 samples
  - Spectrogram shape: torch.Size([42, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([42, 30, 18, 50, 10])
  - Value range: [-6.0794, 5.1048]
  - Value range: [-6.0794, 5.1048]
  - Class distribution: tensor([21, 21])
  - Class distribution: tensor([21, 21])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb16_fold2\epoch_005.pth...
Loading model checkpoint from model\chb16_fold2\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 33.41it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 33.41it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.8761
Loss:      0.8761
Accuracy:  0.3333 (33.33%)
Accuracy:  0.3333 (33.33%)
Precision: 0.0000
Precision: 0.0000
Recall:    0.0000
Recall:    0.0000
F1 Score:  0.0000
F1 Score:  0.0000
AUC-ROC:   0.4671
AUC-ROC:   0.4671

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal        14         7
Actual Interictal        14         7
       Preictal        21         0
       Preictal        21         0

Class Distribution:
Class Distribution:

True Interictal (0): 21 samples
True Interictal (0): 21 samples
True Preictal (1):   21 samples
True Preictal (1):   21 samples
Pred Interictal (0): 35 samples
Pred Interictal (0): 35 samples
Pred Preictal (1):   7 samples
Pred Preictal (1):   7 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     0.4000    0.6667    0.5000        21
    Preictal     0.0000    0.0000    0.0000        21

    accuracy                         0.3333        42
   macro avg     0.2000    0.3333    0.2500        42
weighted avg     0.2000    0.3333    0.2500        42
              precision    recall  f1-score   support

  Interictal     0.4000    0.6667    0.5000        21
    Preictal     0.0000    0.0000    0.0000        21

    accuracy                         0.3333        42
   macro avg     0.2000    0.3333    0.2500        42
weighted avg     0.2000    0.3333    0.2500        42



✅ Results saved to model\chb16_fold2\test_results.json
✅ Results saved to model\chb16_fold2\test_results.json


============================================================
============================================================

EVALUATING FOLD 3/9
EVALUATING FOLD 3/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb16_fold3
Dataset prefix: chb16_fold3
Using test dataset: preprocessing\data\chb16_fold3\test_dataset.h5
Using test dataset: preprocessing\data\chb16_fold3\test_dataset.h5
Loading test dataset from preprocessing\data\chb16_fold3\test_dataset.h5...
Loading test dataset from preprocessing\data\chb16_fold3\test_dataset.h5...
  - Normalization: z-score, mean=0.3414, std=2.1019
  - Normalization: z-score, mean=0.3414, std=2.1019
Loaded test dataset: 38 samples
Loaded test dataset: 38 samples
  - Spectrogram shape: torch.Size([38, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([38, 30, 18, 50, 10])
  - Value range: [-5.8715, 4.8429]
  - Value range: [-5.8715, 4.8429]
  - Class distribution: tensor([19, 19])
  - Class distribution: tensor([19, 19])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb16_fold3\epoch_005.pth...
Loading model checkpoint from model\chb16_fold3\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 34.54it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 34.54it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5780
Loss:      0.5780
Accuracy:  0.7368 (73.68%)
Accuracy:  0.7368 (73.68%)
Precision: 0.6552
Precision: 0.6552
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.7917
F1 Score:  0.7917
AUC-ROC:   0.8172
AUC-ROC:   0.8172

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal         9        10
Actual Interictal         9        10
       Preictal         0        19
       Preictal         0        19

Class Distribution:
Class Distribution:

True Interictal (0): 19 samples
True Interictal (0): 19 samples
True Preictal (1):   19 samples
True Preictal (1):   19 samples
Pred Interictal (0): 9 samples
Pred Interictal (0): 9 samples
Pred Preictal (1):   29 samples
Pred Preictal (1):   29 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.4737    0.6429        19
    Preictal     0.6552    1.0000    0.7917        19

    accuracy                         0.7368        38
   macro avg     0.8276    0.7368    0.7173        38
weighted avg     0.8276    0.7368    0.7173        38
              precision    recall  f1-score   support

  Interictal     1.0000    0.4737    0.6429        19
    Preictal     0.6552    1.0000    0.7917        19

    accuracy                         0.7368        38
   macro avg     0.8276    0.7368    0.7173        38
weighted avg     0.8276    0.7368    0.7173        38



✅ Results saved to model\chb16_fold3\test_results.json
✅ Results saved to model\chb16_fold3\test_results.json


============================================================
============================================================

EVALUATING FOLD 4/9
EVALUATING FOLD 4/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb16_fold4
Dataset prefix: chb16_fold4
Using test dataset: preprocessing\data\chb16_fold4\test_dataset.h5
Using test dataset: preprocessing\data\chb16_fold4\test_dataset.h5
Loading test dataset from preprocessing\data\chb16_fold4\test_dataset.h5...
Loading test dataset from preprocessing\data\chb16_fold4\test_dataset.h5...
  - Normalization: z-score, mean=0.4321, std=2.0650
  - Normalization: z-score, mean=0.4321, std=2.0650
Loaded test dataset: 30 samples
Loaded test dataset: 30 samples
  - Spectrogram shape: torch.Size([30, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([30, 30, 18, 50, 10])
  - Value range: [-6.0202, 4.9137]
  - Value range: [-6.0202, 4.9137]
  - Class distribution: tensor([15, 15])
  - Class distribution: tensor([15, 15])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb16_fold4\epoch_005.pth...
Loading model checkpoint from model\chb16_fold4\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/2 [00:00<?, ?it/s]Testing:   0%|                                       | 0/2 [00:00<?, ?it/s]Testing: 100%|###############################| 2/2 [00:00<00:00, 29.15it/s]Testing: 100%|###############################| 2/2 [00:00<00:00, 29.15it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5833
Loss:      0.5833
Accuracy:  0.7000 (70.00%)
Accuracy:  0.7000 (70.00%)
Precision: 0.6250
Precision: 0.6250
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.7692
F1 Score:  0.7692
AUC-ROC:   0.7333
AUC-ROC:   0.7333

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal         6         9
Actual Interictal         6         9
       Preictal         0        15
       Preictal         0        15

Class Distribution:
Class Distribution:

True Interictal (0): 15 samples
True Interictal (0): 15 samples
True Preictal (1):   15 samples
True Preictal (1):   15 samples
Pred Interictal (0): 6 samples
Pred Interictal (0): 6 samples
Pred Preictal (1):   24 samples
Pred Preictal (1):   24 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.4000    0.5714        15
    Preictal     0.6250    1.0000    0.7692        15

    accuracy                         0.7000        30
   macro avg     0.8125    0.7000    0.6703        30
weighted avg     0.8125    0.7000    0.6703        30
              precision    recall  f1-score   support

  Interictal     1.0000    0.4000    0.5714        15
    Preictal     0.6250    1.0000    0.7692        15

    accuracy                         0.7000        30
   macro avg     0.8125    0.7000    0.6703        30
weighted avg     0.8125    0.7000    0.6703        30



✅ Results saved to model\chb16_fold4\test_results.json
✅ Results saved to model\chb16_fold4\test_results.json


============================================================
============================================================

EVALUATING FOLD 5/9
EVALUATING FOLD 5/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb16_fold5
Dataset prefix: chb16_fold5
Using test dataset: preprocessing\data\chb16_fold5\test_dataset.h5
Using test dataset: preprocessing\data\chb16_fold5\test_dataset.h5
Loading test dataset from preprocessing\data\chb16_fold5\test_dataset.h5...
Loading test dataset from preprocessing\data\chb16_fold5\test_dataset.h5...
  - Normalization: z-score, mean=0.4588, std=2.0686
  - Normalization: z-score, mean=0.4588, std=2.0686
Loaded test dataset: 44 samples
Loaded test dataset: 44 samples
  - Spectrogram shape: torch.Size([44, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([44, 30, 18, 50, 10])
  - Value range: [-6.0228, 3.9636]
  - Value range: [-6.0228, 3.9636]
  - Class distribution: tensor([22, 22])
  - Class distribution: tensor([22, 22])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb16_fold5\epoch_005.pth...
Loading model checkpoint from model\chb16_fold5\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 30.35it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 30.35it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5386
Loss:      0.5386
Accuracy:  0.7727 (77.27%)
Accuracy:  0.7727 (77.27%)
Precision: 0.6875
Precision: 0.6875
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.8148
F1 Score:  0.8148
AUC-ROC:   1.0000
AUC-ROC:   1.0000

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal        12        10
Actual Interictal        12        10
       Preictal         0        22
       Preictal         0        22

Class Distribution:
Class Distribution:

True Interictal (0): 22 samples
True Interictal (0): 22 samples
True Preictal (1):   22 samples
True Preictal (1):   22 samples
Pred Interictal (0): 12 samples
Pred Interictal (0): 12 samples
Pred Preictal (1):   32 samples
Pred Preictal (1):   32 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.5455    0.7059        22
    Preictal     0.6875    1.0000    0.8148        22

    accuracy                         0.7727        44
   macro avg     0.8438    0.7727    0.7603        44
weighted avg     0.8438    0.7727    0.7603        44
              precision    recall  f1-score   support

  Interictal     1.0000    0.5455    0.7059        22
    Preictal     0.6875    1.0000    0.8148        22

    accuracy                         0.7727        44
   macro avg     0.8438    0.7727    0.7603        44
weighted avg     0.8438    0.7727    0.7603        44



✅ Results saved to model\chb16_fold5\test_results.json
✅ Results saved to model\chb16_fold5\test_results.json


============================================================
============================================================

EVALUATING FOLD 6/9
EVALUATING FOLD 6/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb16_fold6
Dataset prefix: chb16_fold6
Using test dataset: preprocessing\data\chb16_fold6\test_dataset.h5
Using test dataset: preprocessing\data\chb16_fold6\test_dataset.h5
Loading test dataset from preprocessing\data\chb16_fold6\test_dataset.h5...
Loading test dataset from preprocessing\data\chb16_fold6\test_dataset.h5...
  - Normalization: z-score, mean=0.4437, std=2.0921
  - Normalization: z-score, mean=0.4437, std=2.0921
Loaded test dataset: 38 samples
Loaded test dataset: 38 samples
  - Spectrogram shape: torch.Size([38, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([38, 30, 18, 50, 10])
  - Value range: [-5.9479, 5.0852]
  - Value range: [-5.9479, 5.0852]
  - Class distribution: tensor([19, 19])
  - Class distribution: tensor([19, 19])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb16_fold6\epoch_005.pth...
Loading model checkpoint from model\chb16_fold6\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 35.77it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 35.77it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5499
Loss:      0.5499
Accuracy:  0.8158 (81.58%)
Accuracy:  0.8158 (81.58%)
Precision: 0.7308
Precision: 0.7308
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.8444
F1 Score:  0.8444
AUC-ROC:   1.0000
AUC-ROC:   1.0000

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal        12         7
Actual Interictal        12         7
       Preictal         0        19
       Preictal         0        19

Class Distribution:
Class Distribution:

True Interictal (0): 19 samples
True Interictal (0): 19 samples
True Preictal (1):   19 samples
True Preictal (1):   19 samples
Pred Interictal (0): 12 samples
Pred Interictal (0): 12 samples
Pred Preictal (1):   26 samples
Pred Preictal (1):   26 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.6316    0.7742        19
    Preictal     0.7308    1.0000    0.8444        19

    accuracy                         0.8158        38
   macro avg     0.8654    0.8158    0.8093        38
weighted avg     0.8654    0.8158    0.8093        38
              precision    recall  f1-score   support

  Interictal     1.0000    0.6316    0.7742        19
    Preictal     0.7308    1.0000    0.8444        19

    accuracy                         0.8158        38
   macro avg     0.8654    0.8158    0.8093        38
weighted avg     0.8654    0.8158    0.8093        38



✅ Results saved to model\chb16_fold6\test_results.json
✅ Results saved to model\chb16_fold6\test_results.json


============================================================
============================================================

EVALUATING FOLD 7/9
EVALUATING FOLD 7/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb16_fold7
Dataset prefix: chb16_fold7
Using test dataset: preprocessing\data\chb16_fold7\test_dataset.h5
Using test dataset: preprocessing\data\chb16_fold7\test_dataset.h5
Loading test dataset from preprocessing\data\chb16_fold7\test_dataset.h5...
Loading test dataset from preprocessing\data\chb16_fold7\test_dataset.h5...
  - Normalization: z-score, mean=0.4499, std=2.0585
  - Normalization: z-score, mean=0.4499, std=2.0585
Loaded test dataset: 42 samples
Loaded test dataset: 42 samples
  - Spectrogram shape: torch.Size([42, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([42, 30, 18, 50, 10])
  - Value range: [-6.0480, 4.9410]
  - Value range: [-6.0480, 4.9410]
  - Class distribution: tensor([21, 21])
  - Class distribution: tensor([21, 21])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb16_fold7\epoch_005.pth...
Loading model checkpoint from model\chb16_fold7\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 33.05it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 33.05it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5529
Loss:      0.5529
Accuracy:  0.8810 (88.10%)
Accuracy:  0.8810 (88.10%)
Precision: 0.8077
Precision: 0.8077
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.8936
F1 Score:  0.8936
AUC-ROC:   0.9342
AUC-ROC:   0.9342

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal        16         5
Actual Interictal        16         5
       Preictal         0        21
       Preictal         0        21

Class Distribution:
Class Distribution:

True Interictal (0): 21 samples
True Interictal (0): 21 samples
True Preictal (1):   21 samples
True Preictal (1):   21 samples
Pred Interictal (0): 16 samples
Pred Interictal (0): 16 samples
Pred Preictal (1):   26 samples
Pred Preictal (1):   26 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.7619    0.8649        21
    Preictal     0.8077    1.0000    0.8936        21

    accuracy                         0.8810        42
   macro avg     0.9038    0.8810    0.8792        42
weighted avg     0.9038    0.8810    0.8792        42
              precision    recall  f1-score   support

  Interictal     1.0000    0.7619    0.8649        21
    Preictal     0.8077    1.0000    0.8936        21

    accuracy                         0.8810        42
   macro avg     0.9038    0.8810    0.8792        42
weighted avg     0.9038    0.8810    0.8792        42



✅ Results saved to model\chb16_fold7\test_results.json
✅ Results saved to model\chb16_fold7\test_results.json


============================================================
============================================================

EVALUATING FOLD 8/9
EVALUATING FOLD 8/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb16_fold8
Dataset prefix: chb16_fold8
Using test dataset: preprocessing\data\chb16_fold8\test_dataset.h5
Using test dataset: preprocessing\data\chb16_fold8\test_dataset.h5
Loading test dataset from preprocessing\data\chb16_fold8\test_dataset.h5...
Loading test dataset from preprocessing\data\chb16_fold8\test_dataset.h5...
  - Normalization: z-score, mean=0.4353, std=2.1160
  - Normalization: z-score, mean=0.4353, std=2.1160
Loaded test dataset: 40 samples
Loaded test dataset: 40 samples
  - Spectrogram shape: torch.Size([40, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([40, 30, 18, 50, 10])
  - Value range: [-5.8749, 4.6009]
  - Value range: [-5.8749, 4.6009]
  - Class distribution: tensor([20, 20])
  - Class distribution: tensor([20, 20])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb16_fold8\epoch_005.pth...
Loading model checkpoint from model\chb16_fold8\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 33.51it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 33.51it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.6351
Loss:      0.6351
Accuracy:  0.7000 (70.00%)
Accuracy:  0.7000 (70.00%)
Precision: 0.6250
Precision: 0.6250
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.7692
F1 Score:  0.7692
AUC-ROC:   0.7275
AUC-ROC:   0.7275

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal         8        12
Actual Interictal         8        12
       Preictal         0        20
       Preictal         0        20

Class Distribution:
Class Distribution:

True Interictal (0): 20 samples
True Interictal (0): 20 samples
True Preictal (1):   20 samples
True Preictal (1):   20 samples
Pred Interictal (0): 8 samples
Pred Interictal (0): 8 samples
Pred Preictal (1):   32 samples
Pred Preictal (1):   32 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.4000    0.5714        20
    Preictal     0.6250    1.0000    0.7692        20

    accuracy                         0.7000        40
   macro avg     0.8125    0.7000    0.6703        40
weighted avg     0.8125    0.7000    0.6703        40
              precision    recall  f1-score   support

  Interictal     1.0000    0.4000    0.5714        20
    Preictal     0.6250    1.0000    0.7692        20

    accuracy                         0.7000        40
   macro avg     0.8125    0.7000    0.6703        40
weighted avg     0.8125    0.7000    0.6703        40



✅ Results saved to model\chb16_fold8\test_results.json
✅ Results saved to model\chb16_fold8\test_results.json


============================================================
============================================================

EVALUATING FOLD 9/9
EVALUATING FOLD 9/9
============================================================
============================================================
Evaluating model from epoch 5
Evaluating model from epoch 5
Dataset prefix: chb16_fold9
Dataset prefix: chb16_fold9
Using test dataset: preprocessing\data\chb16_fold9\test_dataset.h5
Using test dataset: preprocessing\data\chb16_fold9\test_dataset.h5
Loading test dataset from preprocessing\data\chb16_fold9\test_dataset.h5...
Loading test dataset from preprocessing\data\chb16_fold9\test_dataset.h5...
  - Normalization: z-score, mean=0.4523, std=2.0766
  - Normalization: z-score, mean=0.4523, std=2.0766
Loaded test dataset: 42 samples
Loaded test dataset: 42 samples
  - Spectrogram shape: torch.Size([42, 30, 18, 50, 10])
  - Spectrogram shape: torch.Size([42, 30, 18, 50, 10])
  - Value range: [-5.9966, 5.0992]
  - Value range: [-5.9966, 5.0992]
  - Class distribution: tensor([21, 21])
  - Class distribution: tensor([21, 21])
Initializing Deep CNN-BiLSTM model...
Initializing Deep CNN-BiLSTM model...
Loading model checkpoint from model\chb16_fold9\epoch_005.pth...
Loading model checkpoint from model\chb16_fold9\epoch_005.pth...
Model loaded from epoch 4
Model loaded from epoch 4
Task mode: PREDICTION (preictal vs interictal)
Task mode: PREDICTION (preictal vs interictal)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Architecture: Deep CNN (16 layers, 512 features) + Bi-LSTM (3 layers, 512 hidden)
Total parameters: 41,286,914
Total parameters: 41,286,914

Evaluating on test set...
Evaluating on test set...

Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing:   0%|                                       | 0/3 [00:00<?, ?it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 33.45it/s]Testing: 100%|###############################| 3/3 [00:00<00:00, 33.45it/s]


============================================================
============================================================

FOLD TEST RESULTS
FOLD TEST RESULTS
============================================================
============================================================
Loss:      0.5344
Loss:      0.5344
Accuracy:  0.8095 (80.95%)
Accuracy:  0.8095 (80.95%)
Precision: 0.7241
Precision: 0.7241
Recall:    1.0000
Recall:    1.0000
F1 Score:  0.8400
F1 Score:  0.8400
AUC-ROC:   0.8367
AUC-ROC:   0.8367

Confusion Matrix:
Confusion Matrix:

                Predicted
                Predicted
                Interictal  Preictal
                Interictal  Preictal
Actual Interictal        13         8
Actual Interictal        13         8
       Preictal         0        21
       Preictal         0        21

Class Distribution:
Class Distribution:

True Interictal (0): 21 samples
True Interictal (0): 21 samples
True Preictal (1):   21 samples
True Preictal (1):   21 samples
Pred Interictal (0): 13 samples
Pred Interictal (0): 13 samples
Pred Preictal (1):   29 samples
Pred Preictal (1):   29 samples

Detailed Classification Report:
Detailed Classification Report:

              precision    recall  f1-score   support

  Interictal     1.0000    0.6190    0.7647        21
    Preictal     0.7241    1.0000    0.8400        21

    accuracy                         0.8095        42
   macro avg     0.8621    0.8095    0.8024        42
weighted avg     0.8621    0.8095    0.8024        42
              precision    recall  f1-score   support

  Interictal     1.0000    0.6190    0.7647        21
    Preictal     0.7241    1.0000    0.8400        21

    accuracy                         0.8095        42
   macro avg     0.8621    0.8095    0.8024        42
weighted avg     0.8621    0.8095    0.8024        42



✅ Results saved to model\chb16_fold9\test_results.json
✅ Results saved to model\chb16_fold9\test_results.json


============================================================
============================================================

BATCH EVALUATION SUMMARY
BATCH EVALUATION SUMMARY
============================================================
============================================================
Folds evaluated: 10/10
Folds evaluated: 10/10

Mean metrics (across folds):
Mean metrics (across folds):

  Accuracy:  0.7285 (±0.1418)
  Accuracy:  0.7285 (±0.1418)
  Precision: 0.6236 (±0.2144)
  Precision: 0.6236 (±0.2144)
  Recall:    0.8952 (±0.2988)
  Recall:    0.8952 (±0.2988)
  F1 Score:  0.7339 (±0.2472)
  F1 Score:  0.7339 (±0.2472)
  AUC-ROC:   0.8237 (±0.1500)
  AUC-ROC:   0.8237 (±0.1500)

✅ Batch results saved to model\batch_test_results.json
✅ Batch results saved to model\batch_test_results.json

============================================================
============================================================
